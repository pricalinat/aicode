[
  {
    "id": "http://arxiv.org/abs/2505.24239v1",
    "title": "An Adversary-Resistant Multi-Agent LLM System via Credibility Scoring",
    "summary": "While multi-agent LLM systems show strong capabilities in various domains, they are highly vulnerable to adversarial and low-performing agents. To resolve this issue, in this paper, we introduce a general and adversary-resistant multi-agent LLM framework based on credibility scoring. We model the collaborative query-answering process as an iterative game, where the agents communicate and contribute to a final system output. Our system associates a credibility score that is used when aggregating the team outputs. The credibility scores are learned gradually based on the past contributions of each agent in query answering. Our experiments across multiple tasks and settings demonstrate our system's effectiveness in mitigating adversarial influence and enhancing the resilience of multi-agent cooperation, even in the adversary-majority settings.",
    "authors": [
      "Sana Ebrahimi",
      "Mohsen Dehghankar",
      "Abolfazl Asudeh"
    ],
    "published": "2025-05-30T05:57:37Z",
    "updated": "2025-05-30T05:57:37Z",
    "pdf_url": "https://arxiv.org/pdf/2505.24239v1",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2507.08350v1",
    "title": "Exploring Design of Multi-Agent LLM Dialogues for Research Ideation",
    "summary": "Large language models (LLMs) are increasingly used to support creative tasks such as research idea generation. While recent work has shown that structured dialogues between LLMs can improve the novelty and feasibility of generated ideas, the optimal design of such interactions remains unclear. In this study, we conduct a comprehensive analysis of multi-agent LLM dialogues for scientific ideation. We compare different configurations of agent roles, number of agents, and dialogue depth to understand how these factors influence the novelty and feasibility of generated ideas. Our experimental setup includes settings where one agent generates ideas and another critiques them, enabling iterative improvement. Our results show that enlarging the agent cohort, deepening the interaction depth, and broadening agent persona heterogeneity each enrich the diversity of generated ideas. Moreover, specifically increasing critic-side diversity within the ideation-critique-revision loop further boosts the feasibility of the final proposals. Our findings offer practical guidelines for building effective multi-agent LLM systems for scientific ideation. Our code is available at https://github.com/g6000/MultiAgent-Research-Ideator.",
    "authors": [
      "Keisuke Ueda",
      "Wataru Hirota",
      "Takuto Asakura",
      "Takahiro Omi",
      "Kosuke Takahashi",
      "Kosuke Arima",
      "Tatsuya Ishigaki"
    ],
    "published": "2025-07-11T06:53:46Z",
    "updated": "2025-07-11T06:53:46Z",
    "pdf_url": "https://arxiv.org/pdf/2507.08350v1",
    "categories": [
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2511.02755v1",
    "title": "Controlling Performance and Budget of a Centralized Multi-agent LLM System with Reinforcement Learning",
    "summary": "Large language models (LLMs) exhibit complementary strengths across domains and come with varying inference costs, motivating the design of multi-agent LLM systems where specialized models collaborate efficiently. Existing approaches predominantly rely on decentralized frameworks, which invoke multiple LLMs for every input and thus lead to substantial and uncontrolled inference costs. In this work, we introduce a centralized multi-LLM framework, where a controller LLM selectively coordinates a pool of expert models in a cost-efficient and cost-controllable manner. We formulate this coordination problem as reinforcement learning with dual objectives: maximizing task performance while minimizing the overall inference cost. In addition, we expect the multi-agent system to have adapted behavior with different budget conditions during inference. To this end, we propose CoRL, a reinforcement learning framework that optimizes the performance cost trade-off in a controllable multi-budget setting. Experiments on four diverse benchmarks demonstrate that CoRL enables a single system to surpass the best expert LLM under high-budget settings, while maintaining strong performance in more economical low-budget modes, highlighting the effectiveness of centralized coordination for scalable and cost-efficient multi-agent LLM systems.",
    "authors": [
      "Bowen Jin",
      "TJ Collins",
      "Donghan Yu",
      "Mert Cemri",
      "Shenao Zhang",
      "Mengyu Li",
      "Jay Tang",
      "Tian Qin",
      "Zhiyang Xu",
      "Jiarui Lu",
      "Guoli Yin",
      "Jiawei Han",
      "Zirui Wang"
    ],
    "published": "2025-11-04T17:35:17Z",
    "updated": "2025-11-04T17:35:17Z",
    "pdf_url": "https://arxiv.org/pdf/2511.02755v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2410.02584v1",
    "title": "Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions",
    "summary": "As Large Language Models (LLMs) continue to evolve, they are increasingly being employed in numerous studies to simulate societies and execute diverse social tasks. However, LLMs are susceptible to societal biases due to their exposure to human-generated data. Given that LLMs are being used to gain insights into various societal aspects, it is essential to mitigate these biases. To that end, our study investigates the presence of implicit gender biases in multi-agent LLM interactions and proposes two strategies to mitigate these biases. We begin by creating a dataset of scenarios where implicit gender biases might arise, and subsequently develop a metric to assess the presence of biases. Our empirical analysis reveals that LLMs generate outputs characterized by strong implicit bias associations (>= 50\\% of the time). Furthermore, these biases tend to escalate following multi-agent interactions. To mitigate them, we propose two strategies: self-reflection with in-context examples (ICE); and supervised fine-tuning. Our research demonstrates that both methods effectively mitigate implicit biases, with the ensemble of fine-tuning and self-reflection proving to be the most successful.",
    "authors": [
      "Angana Borah",
      "Rada Mihalcea"
    ],
    "published": "2024-10-03T15:28:05Z",
    "updated": "2024-10-03T15:28:05Z",
    "pdf_url": "https://arxiv.org/pdf/2410.02584v1",
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2508.11915v2",
    "title": "CORE: Measuring Multi-Agent LLM Interaction Quality under Game-Theoretic Pressures",
    "summary": "Game-theoretic interactions between agents with Large Language Models (LLMs) have revealed many emergent capabilities, yet the linguistic diversity of these interactions has not been sufficiently quantified. In this paper, we present the Conversational Robustness Evaluation Score: CORE, a metric to quantify the effectiveness of language use within multi-agent systems across different game-theoretic interactions. CORE integrates measures of cluster entropy, lexical repetition, and semantic similarity, providing a direct lens of dialog quality. We apply CORE to pairwise LLM dialogs across competitive, cooperative, and neutral settings, further grounding our analysis in Zipf's and Heaps' Laws to characterize word frequency distributions and vocabulary growth. Our findings show that cooperative settings exhibit both steeper Zipf distributions and higher Heap exponents, indicating more repetition alongside greater vocabulary expansion. In contrast, competitive interactions display lower Zipf and Heaps exponents, reflecting less repetition and more constrained vocabularies. These results provide new insights into how social incentives influence language adaptation, and highlight CORE as a robust diagnostic for measuring linguistic robustness in multi-agent LLM systems. Our code is available at https://github.com/psyonp/core.",
    "authors": [
      "Punya Syon Pandey",
      "Yongjin Yang",
      "Jiarui Liu",
      "Zhijing Jin"
    ],
    "published": "2025-08-16T05:26:36Z",
    "updated": "2026-02-22T19:00:41Z",
    "pdf_url": "https://arxiv.org/pdf/2508.11915v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2504.17200v1",
    "title": "A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation",
    "summary": "Large language models (LLMs) are a transformational capability at the frontier of artificial intelligence and machine learning that can support decision-makers in addressing pressing societal challenges such as extreme natural hazard events. As generalized models, LLMs often struggle to provide context-specific information, particularly in areas requiring specialized knowledge. In this work we propose a retrieval-augmented generation (RAG)-based multi-agent LLM system to support analysis and decision-making in the context of natural hazards and extreme weather events. As a proof of concept, we present WildfireGPT, a specialized system focused on wildfire hazards. The architecture employs a user-centered, multi-agent design to deliver tailored risk insights across diverse stakeholder groups. By integrating natural hazard and extreme weather projection data, observational datasets, and scientific literature through an RAG framework, the system ensures both the accuracy and contextual relevance of the information it provides. Evaluation across ten expert-led case studies demonstrates that WildfireGPT significantly outperforms existing LLM-based solutions for decision support.",
    "authors": [
      "Yangxinyu Xie",
      "Bowen Jiang",
      "Tanwi Mallick",
      "Joshua David Bergerson",
      "John K. Hutchison",
      "Duane R. Verner",
      "Jordan Branham",
      "M. Ross Alexander",
      "Robert B. Ross",
      "Yan Feng",
      "Leslie-Anne Levy",
      "Weijie Su",
      "Camillo J. Taylor"
    ],
    "published": "2025-04-24T02:25:06Z",
    "updated": "2025-04-24T02:25:06Z",
    "pdf_url": "https://arxiv.org/pdf/2504.17200v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2504.00218v2",
    "title": "$\\textit{Agents Under Siege}$: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks",
    "summary": "Most discussions about Large Language Model (LLM) safety have focused on single-agent settings but multi-agent LLM systems now create novel adversarial risks because their behavior depends on communication between agents and decentralized reasoning. In this work, we innovatively focus on attacking pragmatic systems that have constrains such as limited token bandwidth, latency between message delivery, and defense mechanisms. We design a $\\textit{permutation-invariant adversarial attack}$ that optimizes prompt distribution across latency and bandwidth-constraint network topologies to bypass distributed safety mechanisms within the system. Formulating the attack path as a problem of $\\textit{maximum-flow minimum-cost}$, coupled with the novel $\\textit{Permutation-Invariant Evasion Loss (PIEL)}$, we leverage graph-based optimization to maximize attack success rate while minimizing detection risk. Evaluating across models including $\\texttt{Llama}$, $\\texttt{Mistral}$, $\\texttt{Gemma}$, $\\texttt{DeepSeek}$ and other variants on various datasets like $\\texttt{JailBreakBench}$ and $\\texttt{AdversarialBench}$, our method outperforms conventional attacks by up to $7\\times$, exposing critical vulnerabilities in multi-agent systems. Moreover, we demonstrate that existing defenses, including variants of $\\texttt{Llama-Guard}$ and $\\texttt{PromptGuard}$, fail to prohibit our attack, emphasizing the urgent need for multi-agent specific safety mechanisms.",
    "authors": [
      "Rana Muhammad Shahroz Khan",
      "Zhen Tan",
      "Sukwon Yun",
      "Charles Fleming",
      "Tianlong Chen"
    ],
    "published": "2025-03-31T20:43:56Z",
    "updated": "2025-10-08T22:17:28Z",
    "pdf_url": "https://arxiv.org/pdf/2504.00218v2",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2508.04903v3",
    "title": "RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory",
    "summary": "Multi-agent large language model (LLM) systems have shown strong potential in complex reasoning and collaborative decision-making tasks. However, most existing coordination schemes rely on static or full-context routing strategies, which lead to excessive token consumption, redundant memory exposure, and limited adaptability across interaction rounds. We introduce RCR-Router, a modular and role-aware context routing framework designed to enable efficient, adaptive collaboration in multi-agent LLMs. To our knowledge, this is the first routing approach that dynamically selects semantically relevant memory subsets for each agent based on its role and task stage, while adhering to a strict token budget. A lightweight scoring policy guides memory selection, and agent outputs are iteratively integrated into a shared memory store to facilitate progressive context refinement. To better evaluate model behavior, we further propose an Answer Quality Score metric that captures LLM-generated explanations beyond standard QA accuracy. Experiments on three multi-hop QA benchmarks -- HotPotQA, MuSiQue, and 2WikiMultihop -- demonstrate that RCR-Router reduces token usage (up to 30%) while improving or maintaining answer quality. These results highlight the importance of structured memory routing and output-aware evaluation in advancing scalable multi-agent LLM systems.",
    "authors": [
      "Jun Liu",
      "Zhenglun Kong",
      "Changdi Yang",
      "Fan Yang",
      "Tianqi Li",
      "Peiyan Dong",
      "Joannah Nanjekye",
      "Hao Tang",
      "Geng Yuan",
      "Wei Niu",
      "Wenbin Zhang",
      "Pu Zhao",
      "Xue Lin",
      "Dong Huang",
      "Yanzhi Wang"
    ],
    "published": "2025-08-06T21:59:34Z",
    "updated": "2025-08-12T16:29:05Z",
    "pdf_url": "https://arxiv.org/pdf/2508.04903v3",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2505.19405v1",
    "title": "CoTGuard: Using Chain-of-Thought Triggering for Copyright Protection in Multi-Agent LLM Systems",
    "summary": "As large language models (LLMs) evolve into autonomous agents capable of collaborative reasoning and task execution, multi-agent LLM systems have emerged as a powerful paradigm for solving complex problems. However, these systems pose new challenges for copyright protection, particularly when sensitive or copyrighted content is inadvertently recalled through inter-agent communication and reasoning. Existing protection techniques primarily focus on detecting content in final outputs, overlooking the richer, more revealing reasoning processes within the agents themselves. In this paper, we introduce CoTGuard, a novel framework for copyright protection that leverages trigger-based detection within Chain-of-Thought (CoT) reasoning. Specifically, we can activate specific CoT segments and monitor intermediate reasoning steps for unauthorized content reproduction by embedding specific trigger queries into agent prompts. This approach enables fine-grained, interpretable detection of copyright violations in collaborative agent scenarios. We evaluate CoTGuard on various benchmarks in extensive experiments and show that it effectively uncovers content leakage with minimal interference to task performance. Our findings suggest that reasoning-level monitoring offers a promising direction for safeguarding intellectual property in LLM-based agent systems.",
    "authors": [
      "Yan Wen",
      "Junfeng Guo",
      "Heng Huang"
    ],
    "published": "2025-05-26T01:42:37Z",
    "updated": "2025-05-26T01:42:37Z",
    "pdf_url": "https://arxiv.org/pdf/2505.19405v1",
    "categories": [
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2504.02867v1",
    "title": "Multi-Agent LLM Judge: automatic personalized LLM judge design for evaluating natural language generation applications",
    "summary": "Large Language Models (LLMs) have demonstrated impressive performance across diverse domains, yet they still encounter challenges such as insufficient domain-specific knowledge, biases, and hallucinations. This underscores the need for robust evaluation methodologies to accurately assess LLM-based applications. Traditional evaluation methods, which rely on word overlap or text embeddings, are inadequate for capturing the nuanced semantic information necessary to evaluate dynamic, open-ended text generation. Recent research has explored leveraging LLMs to mimic human reasoning and decision-making processes for evaluation purposes known as LLM-as-a-judge framework. However, these existing frameworks have two significant limitations. First, they lack the flexibility to adapt to different text styles, including various answer and ground truth styles, thereby reducing their generalization performance. Second, the evaluation scores produced by these frameworks are often skewed and hard to interpret, showing a low correlation with human judgment. To address these challenges, we propose a novel dynamic multi-agent system that automatically designs personalized LLM judges for various natural language generation applications. This system iteratively refines evaluation prompts and balances the trade-off between the adaptive requirements of downstream tasks and the alignment with human perception. Our experimental results show that the proposed multi-agent LLM Judge framework not only enhances evaluation accuracy compared to existing methods but also produces evaluation scores that better align with human perception.",
    "authors": [
      "Hongliu Cao",
      "Ilias Driouich",
      "Robin Singh",
      "Eoin Thomas"
    ],
    "published": "2025-04-01T09:36:56Z",
    "updated": "2025-04-01T09:36:56Z",
    "pdf_url": "https://arxiv.org/pdf/2504.02867v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2512.04668v3",
    "title": "Topology Matters: Measuring Memory Leakage in Multi-Agent LLMs",
    "summary": "Graph topology is a fundamental determinant of memory leakage in multi-agent LLM systems, yet its effects remain poorly quantified. We introduce MAMA (Multi-Agent Memory Attack), a framework that measures how network structure shapes leakage. MAMA operates on synthetic documents containing labeled Personally Identifiable Information (PII) entities, from which we generate sanitized task instructions. We execute a two-phase protocol: Engram (seeding private information into a target agent's memory) and Resonance (multi-round interaction where an attacker attempts extraction). Over 10 rounds, we measure leakage as exact-match recovery of ground-truth PII from attacker outputs. We evaluate six canonical topologies (complete, ring, chain, tree, star, star-ring) across $n\\in\\{4,5,6\\}$, attacker-target placements, and base models. Results are consistent: denser connectivity, shorter attacker-target distance, and higher target centrality increase leakage; most leakage occurs in early rounds and then plateaus; model choice shifts absolute rates but preserves topology ordering; spatiotemporal/location attributes leak more readily than identity credentials or regulated identifiers. We distill practical guidance for system design: favor sparse or hierarchical connectivity, maximize attacker-target separation, and restrict hub/shortcut pathways via topology-aware access control.",
    "authors": [
      "Jinbo Liu",
      "Defu Cao",
      "Yifei Wei",
      "Tianyao Su",
      "Yuan Liang",
      "Yushun Dong",
      "Yan Liu",
      "Yue Zhao",
      "Xiyang Hu"
    ],
    "published": "2025-12-04T11:00:49Z",
    "updated": "2026-01-12T09:40:51Z",
    "pdf_url": "https://arxiv.org/pdf/2512.04668v3",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2504.01911v2",
    "title": "Advancing AI-Scientist Understanding: Multi-Agent LLMs with Interpretable Physics Reasoning",
    "summary": "Large Language Models (LLMs) are playing an increasingly important role in physics research by assisting with symbolic manipulation, numerical computation, and scientific reasoning. However, ensuring the reliability, transparency, and interpretability of their outputs remains a major challenge. In this work, we introduce a novel multi-agent LLM physicist framework that fosters collaboration between AI and human scientists through three key modules: a reasoning module, an interpretation module, and an AI-scientist interaction module. Recognizing that effective physics reasoning demands logical rigor, quantitative accuracy, and alignment with established theoretical models, we propose an interpretation module that employs a team of specialized LLM agents-including summarizers, model builders, visualization tools, and testers-to systematically structure LLM outputs into transparent, physically grounded science models. A case study demonstrates that our approach significantly improves interpretability, enables systematic validation, and enhances human-AI collaboration in physics problem-solving and discovery. Our work bridges free-form LLM reasoning with interpretable, executable models for scientific analysis, enabling more transparent and verifiable AI-augmented research.",
    "authors": [
      "Yinggan Xu",
      "Hana Kimlee",
      "Yijia Xiao",
      "Di Luo"
    ],
    "published": "2025-04-02T17:13:16Z",
    "updated": "2025-08-18T08:28:27Z",
    "pdf_url": "https://arxiv.org/pdf/2504.01911v2",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "physics.comp-ph"
    ],
    "primary_category": "cs.AI",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2503.20666v1",
    "title": "TAMA: A Human-AI Collaborative Thematic Analysis Framework Using Multi-Agent LLMs for Clinical Interviews",
    "summary": "Thematic analysis (TA) is a widely used qualitative approach for uncovering latent meanings in unstructured text data. TA provides valuable insights in healthcare but is resource-intensive. Large Language Models (LLMs) have been introduced to perform TA, yet their applications in healthcare remain unexplored. Here, we propose TAMA: A Human-AI Collaborative Thematic Analysis framework using Multi-Agent LLMs for clinical interviews. We leverage the scalability and coherence of multi-agent systems through structured conversations between agents and coordinate the expertise of cardiac experts in TA. Using interview transcripts from parents of children with Anomalous Aortic Origin of a Coronary Artery (AAOCA), a rare congenital heart disease, we demonstrate that TAMA outperforms existing LLM-assisted TA approaches, achieving higher thematic hit rate, coverage, and distinctiveness. TAMA demonstrates strong potential for automated TA in clinical settings by leveraging multi-agent LLM systems with human-in-the-loop integration by enhancing quality while significantly reducing manual workload.",
    "authors": [
      "Huimin Xu",
      "Seungjun Yi",
      "Terence Lim",
      "Jiawei Xu",
      "Andrew Well",
      "Carlos Mery",
      "Aidong Zhang",
      "Yuji Zhang",
      "Heng Ji",
      "Keshav Pingali",
      "Yan Leng",
      "Ying Ding"
    ],
    "published": "2025-03-26T15:58:16Z",
    "updated": "2025-03-26T15:58:16Z",
    "pdf_url": "https://arxiv.org/pdf/2503.20666v1",
    "categories": [
      "cs.HC",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2511.17621v2",
    "title": "From Competition to Coordination: Market Making as a Scalable Framework for Safe and Aligned Multi-Agent LLM Systems",
    "summary": "As foundation models are increasingly deployed as interacting agents in multi-agent systems, their collective behavior raises new challenges for trustworthiness, transparency, and accountability. Traditional coordination mechanisms, such as centralized oversight or adversarial adjudication, struggle to scale and often obscure how decisions emerge. We introduce a market-making framework for multi-agent large language model (LLM) coordination that organizes agent interactions as structured economic exchanges. In this setup, each agent acts as a market participant, updating and trading probabilistic beliefs, to converge toward shared, truthful outcomes. By aligning local incentives with collective epistemic goals, the framework promotes self-organizing, verifiable reasoning without requiring external enforcement. Empirically, we evaluate this approach across factual reasoning, ethical judgment, and commonsense inference tasks. Market-based coordination yields accuracy gains of up to 10% over single-shot baselines while preserving interpretability and transparency of intermediate reasoning steps. Beyond these improvements, our findings demonstrate that economic coordination principles can operationalize accountability and robustness in multi-agent LLM systems, offering a scalable pathway toward self-correcting, socially responsible AI capable of maintaining trust and oversight in real world deployment scenarios.",
    "authors": [
      "Brendan Gho",
      "Suman Muppavarapu",
      "Afnan Shaik",
      "Tyson Tsay",
      "Atharva Mohan",
      "James Begin",
      "Kevin Zhu",
      "Archana Vaidheeswaran",
      "Vasu Sharma"
    ],
    "published": "2025-11-18T16:47:15Z",
    "updated": "2026-02-23T04:13:05Z",
    "pdf_url": "https://arxiv.org/pdf/2511.17621v2",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.MA",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2601.11578v1",
    "title": "LimAgents: Multi-Agent LLMs for Generating Research Limitations",
    "summary": "Identifying and articulating limitations is essential for transparent and rigorous scientific research. However, zero-shot large language models (LLMs) approach often produce superficial or general limitation statements (e.g., dataset bias or generalizability). They usually repeat limitations reported by authors without looking at deeper methodological issues and contextual gaps. This problem is made worse because many authors disclose only partial or trivial limitations. We propose LimAgents, a multi-agent LLM framework for generating substantive limitations. LimAgents integrates OpenReview comments and author-stated limitations to provide stronger ground truth. It also uses cited and citing papers to capture broader contextual weaknesses. In this setup, different agents have specific roles as sequential role: some extract explicit limitations, others analyze methodological gaps, some simulate the viewpoint of a peer reviewer, and a citation agent places the work within the larger body of literature. A Judge agent refines their outputs, and a Master agent consolidates them into a clear set. This structure allows for systematic identification of explicit, implicit, peer review-focused, and literature-informed limitations. Moreover, traditional NLP metrics like BLEU, ROUGE, and cosine similarity rely heavily on n-gram or embedding overlap. They often overlook semantically similar limitations. To address this, we introduce a pointwise evaluation protocol that uses an LLM-as-a-Judge to measure coverage more accurately. Experiments show that LimAgents substantially improve performance. The RAG + multi-agent GPT-4o mini configuration achieves a +15.51% coverage gain over zero-shot baselines, while the Llama 3 8B multi-agent setup yields a +4.41% improvement.",
    "authors": [
      "Ibrahim Al Azher",
      "Zhishuai Guo",
      "Hamed Alhoori"
    ],
    "published": "2025-12-30T18:12:52Z",
    "updated": "2025-12-30T18:12:52Z",
    "pdf_url": "https://arxiv.org/pdf/2601.11578v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2505.11556v3",
    "title": "Systematic Failures in Collective Reasoning under Distributed Information in Multi-Agent LLMs",
    "summary": "Multi-agent systems built on large language models (LLMs) are expected to enhance decision-making by pooling distributed information, yet systematically evaluating this capability has remained challenging. We introduce HiddenBench, a 65-task benchmark grounded in the Hidden Profile paradigm, which isolates collective reasoning under distributed information from individual reasoning ability. Evaluating 15 frontier LLMs, we find that multi-agent LLMs achieve only 30.1% accuracy under distributed information, compared to 80.7% accuracy for single agents given complete information. We trace this gap to a systematic failure mode: agents cannot recognize or act under latent information asymmetry-they fail to reason about what others might know but have not yet expressed, leading to premature convergence on shared evidence while critical distributed facts remain unexplored. These failures persist across prompting strategies, communication depths, and group sizes-and worsen as groups scale. While some models (e.g., Gemini-2.5-Flash/Pro) outperform others, neither model scale nor individual reasoning accuracy reliably predicts collective performance. Our results identify failures in collective information exploration in decision-making as a key limitation of multi-agent LLMs, and provide a theory-grounded, reproducible framework for diagnosing collective reasoning failures.",
    "authors": [
      "Yuxuan Li",
      "Aoi Naito",
      "Hirokazu Shirado"
    ],
    "published": "2025-05-15T19:22:54Z",
    "updated": "2026-02-06T23:09:01Z",
    "pdf_url": "https://arxiv.org/pdf/2505.11556v3",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2412.20505v1",
    "title": "Planning, Living and Judging: A Multi-agent LLM-based Framework for Cyclical Urban Planning",
    "summary": "Urban regeneration presents significant challenges within the context of urbanization, requiring adaptive approaches to tackle evolving needs. Leveraging advancements in large language models (LLMs), we propose Cyclical Urban Planning (CUP), a new paradigm that continuously generates, evaluates, and refines urban plans in a closed-loop. Specifically, our multi-agent LLM-based framework consists of three key components: (1) Planning, where LLM agents generate and refine urban plans based on contextual data; (2) Living, where agents simulate the behaviors and interactions of residents, modeling life in the urban environment; and (3) Judging, which involves evaluating plan effectiveness and providing iterative feedback for improvement. The cyclical process enables a dynamic and responsive planning approach. Experiments on the real-world dataset demonstrate the effectiveness of our framework as a continuous and adaptive planning process.",
    "authors": [
      "Hang Ni",
      "Yuzhi Wang",
      "Hao Liu"
    ],
    "published": "2024-12-29T15:43:25Z",
    "updated": "2024-12-29T15:43:25Z",
    "pdf_url": "https://arxiv.org/pdf/2412.20505v1",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2409.07246v2",
    "title": "Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs",
    "summary": "In the past decade, social media platforms have been used for information dissemination and consumption. While a major portion of the content is posted to promote citizen journalism and public awareness, some content is posted to mislead users. Among different content types such as text, images, and videos, memes (text overlaid on images) are particularly prevalent and can serve as powerful vehicles for propaganda, hate, and humor. In the current literature, there have been efforts to individually detect such content in memes. However, the study of their intersection is very limited. In this study, we explore the intersection between propaganda and hate in memes using a multi-agent LLM-based approach. We extend the propagandistic meme dataset with coarse and fine-grained hate labels. Our finding suggests that there is an association between propaganda and hate in memes. We provide detailed experimental results that can serve as a baseline for future studies. We will make the experimental resources publicly available to the community (https://github.com/firojalam/propaganda-and-hateful-memes).",
    "authors": [
      "Firoj Alam",
      "Md. Rafiul Biswas",
      "Uzair Shah",
      "Wajdi Zaghouani",
      "Georgios Mikros"
    ],
    "published": "2024-09-11T13:04:34Z",
    "updated": "2024-10-06T08:30:48Z",
    "pdf_url": "https://arxiv.org/pdf/2409.07246v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2505.21503v1",
    "title": "Silence is Not Consensus: Disrupting Agreement Bias in Multi-Agent LLMs via Catfish Agent for Clinical Decision Making",
    "summary": "Large language models (LLMs) have demonstrated strong potential in clinical question answering, with recent multi-agent frameworks further improving diagnostic accuracy via collaborative reasoning. However, we identify a recurring issue of Silent Agreement, where agents prematurely converge on diagnoses without sufficient critical analysis, particularly in complex or ambiguous cases. We present a new concept called Catfish Agent, a role-specialized LLM designed to inject structured dissent and counter silent agreement. Inspired by the ``catfish effect'' in organizational psychology, the Catfish Agent is designed to challenge emerging consensus to stimulate deeper reasoning. We formulate two mechanisms to encourage effective and context-aware interventions: (i) a complexity-aware intervention that modulates agent engagement based on case difficulty, and (ii) a tone-calibrated intervention articulated to balance critique and collaboration. Evaluations on nine medical Q&A and three medical VQA benchmarks show that our approach consistently outperforms both single- and multi-agent LLMs frameworks, including leading commercial models such as GPT-4o and DeepSeek-R1.",
    "authors": [
      "Yihan Wang",
      "Qiao Yan",
      "Zhenghao Xing",
      "Lihao Liu",
      "Junjun He",
      "Chi-Wing Fu",
      "Xiaowei Hu",
      "Pheng-Ann Heng"
    ],
    "published": "2025-05-27T17:59:50Z",
    "updated": "2025-05-27T17:59:50Z",
    "pdf_url": "https://arxiv.org/pdf/2505.21503v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "q-bio.OT"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2501.01205v1",
    "title": "Harnessing Multi-Agent LLMs for Complex Engineering Problem-Solving: A Framework for Senior Design Projects",
    "summary": "Multi-Agent Large Language Models (LLMs) are gaining significant attention for their ability to harness collective intelligence in complex problem-solving, decision-making, and planning tasks. This aligns with the concept of the wisdom of crowds, where diverse agents contribute collectively to generating effective solutions, making it particularly suitable for educational settings. Senior design projects, also known as capstone or final year projects, are pivotal in engineering education as they integrate theoretical knowledge with practical application, fostering critical thinking, teamwork, and real-world problem-solving skills. In this paper, we explore the use of Multi-Agent LLMs in supporting these senior design projects undertaken by engineering students, which often involve multidisciplinary considerations and conflicting objectives, such as optimizing technical performance while addressing ethical, social, and environmental concerns. We propose a framework where distinct LLM agents represent different expert perspectives, such as problem formulation agents, system complexity agents, societal and ethical agents, or project managers, thus facilitating a holistic problem-solving approach. This implementation leverages standard multi-agent system (MAS) concepts such as coordination, cooperation, and negotiation, incorporating prompt engineering to develop diverse personas for each agent. These agents engage in rich, collaborative dialogues to simulate human engineering teams, guided by principles from swarm AI to efficiently balance individual contributions towards a unified solution. We adapt these techniques to create a collaboration structure for LLM agents, encouraging interdisciplinary reasoning and negotiation similar to real-world senior design projects. To assess the efficacy of this framework, we collected six proposals of engineering and computer science of...",
    "authors": [
      "Abdullah Mushtaq",
      "Muhammad Rafay Naeem",
      "Ibrahim Ghaznavi",
      "Muhammad Imran Taj",
      "Imran Hashmi",
      "Junaid Qadir"
    ],
    "published": "2025-01-02T11:25:45Z",
    "updated": "2025-01-02T11:25:45Z",
    "pdf_url": "https://arxiv.org/pdf/2501.01205v1",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2512.00047v1",
    "title": "Emergent Convergence in Multi-Agent LLM Annotation",
    "summary": "Large language models (LLMs) are increasingly deployed in collaborative settings, yet little is known about how they coordinate when treated as black-box agents. We simulate 7500 multi-agent, multi-round discussions in an inductive coding task, generating over 125000 utterances that capture both final annotations and their interactional histories. We introduce process-level metrics: code stability, semantic self-consistency, and lexical confidence alongside sentiment and convergence measures, to track coordination dynamics. To probe deeper alignment signals, we analyze the evolving geometry of output embeddings, showing that intrinsic dimensionality declines over rounds, suggesting semantic compression. The results reveal that LLM groups converge lexically and semantically, develop asymmetric influence patterns, and exhibit negotiation-like behaviors despite the absence of explicit role prompting. This work demonstrates how black-box interaction analysis can surface emergent coordination strategies, offering a scalable complement to internal probe-based interpretability methods.",
    "authors": [
      "Angelina Parfenova",
      "Alexander Denzler",
      "Juergen Pfeffer"
    ],
    "published": "2025-11-17T13:42:56Z",
    "updated": "2025-11-17T13:42:56Z",
    "pdf_url": "https://arxiv.org/pdf/2512.00047v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2504.02051v2",
    "title": "Self-Resource Allocation in Multi-Agent LLM Systems",
    "summary": "With the development of LLMs as agents, there is a growing interest in connecting multiple agents into multi-agent systems to solve tasks concurrently, focusing on their role in task assignment and coordination. This paper explores how LLMs can effectively allocate computational tasks among multiple agents, considering factors such as cost, efficiency, and performance. In this work, we address key questions, including the effectiveness of LLMs as orchestrators and planners, comparing their effectiveness in task assignment and coordination. Our experiments demonstrate that LLMs can achieve high validity and accuracy in resource allocation tasks. We find that the planner method outperforms the orchestrator method in handling concurrent actions, resulting in improved efficiency and better utilization of agents. Additionally, we show that providing explicit information about worker capabilities enhances the allocation strategies of planners, particularly when dealing with suboptimal workers.",
    "authors": [
      "Alfonso Amayuelas",
      "Jingbo Yang",
      "Saaket Agashe",
      "Ashwin Nagarajan",
      "Antonis Antoniades",
      "Xin Eric Wang",
      "William Wang"
    ],
    "published": "2025-04-02T18:15:41Z",
    "updated": "2025-04-19T19:05:03Z",
    "pdf_url": "https://arxiv.org/pdf/2504.02051v2",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.MA",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2403.04783v2",
    "title": "AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks",
    "summary": "Despite extensive pre-training in moral alignment to prevent generating harmful information, large language models (LLMs) remain vulnerable to jailbreak attacks. In this paper, we propose AutoDefense, a multi-agent defense framework that filters harmful responses from LLMs. With the response-filtering mechanism, our framework is robust against different jailbreak attack prompts, and can be used to defend different victim models. AutoDefense assigns different roles to LLM agents and employs them to complete the defense task collaboratively. The division in tasks enhances the overall instruction-following of LLMs and enables the integration of other defense components as tools. With AutoDefense, small open-source LMs can serve as agents and defend larger models against jailbreak attacks. Our experiments show that AutoDefense can effectively defense against different jailbreak attacks, while maintaining the performance at normal user request. For example, we reduce the attack success rate on GPT-3.5 from 55.74% to 7.95% using LLaMA-2-13b with a 3-agent system. Our code and data are publicly available at https://github.com/XHMY/AutoDefense.",
    "authors": [
      "Yifan Zeng",
      "Yiran Wu",
      "Xiao Zhang",
      "Huazheng Wang",
      "Qingyun Wu"
    ],
    "published": "2024-03-02T16:52:22Z",
    "updated": "2024-11-14T18:14:00Z",
    "pdf_url": "https://arxiv.org/pdf/2403.04783v2",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2507.01019v1",
    "title": "MALIBU Benchmark: Multi-Agent LLM Implicit Bias Uncovered",
    "summary": "Multi-agent systems, which consist of multiple AI models interacting within a shared environment, are increasingly used for persona-based interactions. However, if not carefully designed, these systems can reinforce implicit biases in large language models (LLMs), raising concerns about fairness and equitable representation. We present MALIBU, a novel benchmark developed to assess the degree to which LLM-based multi-agent systems implicitly reinforce social biases and stereotypes. MALIBU evaluates bias in LLM-based multi-agent systems through scenario-based assessments. AI models complete tasks within predefined contexts, and their responses undergo evaluation by an LLM-based multi-agent judging system in two phases. In the first phase, judges score responses labeled with specific demographic personas (e.g., gender, race, religion) across four metrics. In the second phase, judges compare paired responses assigned to different personas, scoring them and selecting the superior response. Our study quantifies biases in LLM-generated outputs, revealing that bias mitigation may favor marginalized personas over true neutrality, emphasizing the need for nuanced detection, balanced fairness strategies, and transparent evaluation benchmarks in multi-agent systems.",
    "authors": [
      "Imran Mirza",
      "Cole Huang",
      "Ishwara Vasista",
      "Rohan Patil",
      "Asli Akalin",
      "Sean O'Brien",
      "Kevin Zhu"
    ],
    "published": "2025-04-10T19:16:40Z",
    "updated": "2025-04-10T19:16:40Z",
    "pdf_url": "https://arxiv.org/pdf/2507.01019v1",
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2505.24553v1",
    "title": "CREFT: Sequential Multi-Agent LLM for Character Relation Extraction",
    "summary": "Understanding complex character relations is crucial for narrative analysis and efficient script evaluation, yet existing extraction methods often fail to handle long-form narratives with nuanced interactions. To address this challenge, we present CREFT, a novel sequential framework leveraging specialized Large Language Model (LLM) agents. First, CREFT builds a base character graph through knowledge distillation, then iteratively refines character composition, relation extraction, role identification, and group assignments. Experiments on a curated Korean drama dataset demonstrate that CREFT significantly outperforms single-agent LLM baselines in both accuracy and completeness. By systematically visualizing character networks, CREFT streamlines narrative comprehension and accelerates script review -- offering substantial benefits to the entertainment, publishing, and educational sectors.",
    "authors": [
      "Ye Eun Chun",
      "Taeyoon Hwang",
      "Seung-won Hwang",
      "Byung-Hak Kim"
    ],
    "published": "2025-05-30T13:01:36Z",
    "updated": "2025-05-30T13:01:36Z",
    "pdf_url": "https://arxiv.org/pdf/2505.24553v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2511.15915v1",
    "title": "AccelOpt: A Self-Improving LLM Agentic System for AI Accelerator Kernel Optimization",
    "summary": "We present AccelOpt, a self-improving large language model (LLM) agentic system that autonomously optimizes kernels for emerging AI acclerators, eliminating the need for expert-provided hardware-specific optimization knowledge. AccelOpt explores the kernel optimization space through iterative generation, informed by an optimization memory that curates experiences and insights from previously encountered slow-fast kernel pairs. We build NKIBench, a new benchmark suite of AWS Trainium accelerator kernels with varying complexity extracted from real-world LLM workloads to evaluate the effectiveness of AccelOpt. Our evaluation confirms that AccelOpt's capability improves over time, boosting the average percentage of peak throughput from $49\\%$ to $61\\%$ on Trainium 1 and from $45\\%$ to $59\\%$ on Trainium 2 for NKIBench kernels. Moreover, AccelOpt is highly cost-effective: using open-source models, it matches the kernel improvements of Claude Sonnet 4 while being $26\\times$ cheaper.",
    "authors": [
      "Genghan Zhang",
      "Shaowei Zhu",
      "Anjiang Wei",
      "Zhenyu Song",
      "Allen Nie",
      "Zhen Jia",
      "Nandita Vijaykumar",
      "Yida Wang",
      "Kunle Olukotun"
    ],
    "published": "2025-11-19T22:49:37Z",
    "updated": "2025-11-19T22:49:37Z",
    "pdf_url": "https://arxiv.org/pdf/2511.15915v1",
    "categories": [
      "cs.LG",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2507.14447v2",
    "title": "Routine: A Structural Planning Framework for LLM Agent System in Enterprise",
    "summary": "The deployment of agent systems in an enterprise environment is often hindered by several challenges: common models lack domain-specific process knowledge, leading to disorganized plans, missing key tools, and poor execution stability. To address this, this paper introduces Routine, a multi-step agent planning framework designed with a clear structure, explicit instructions, and seamless parameter passing to guide the agent's execution module in performing multi-step tool-calling tasks with high stability. In evaluations conducted within a real-world enterprise scenario, Routine significantly increases the execution accuracy in model tool calls, increasing the performance of GPT-4o from 41.1% to 96.3%, and Qwen3-14B from 32.6% to 83.3%. We further constructed a Routine-following training dataset and fine-tuned Qwen3-14B, resulting in an accuracy increase to 88.2% on scenario-specific evaluations, indicating improved adherence to execution plans. In addition, we employed Routine-based distillation to create a scenario-specific, multi-step tool-calling dataset. Fine-tuning on this distilled dataset raised the model's accuracy to 95.5%, approaching GPT-4o's performance. These results highlight Routine's effectiveness in distilling domain-specific tool-usage patterns and enhancing model adaptability to new scenarios. Our experimental results demonstrate that Routine provides a practical and accessible approach to building stable agent workflows, accelerating the deployment and adoption of agent systems in enterprise environments, and advancing the technical vision of AI for Process.",
    "authors": [
      "Guancheng Zeng",
      "Xueyi Chen",
      "Jiawang Hu",
      "Shaohua Qi",
      "Yaxuan Mao",
      "Zhantao Wang",
      "Yifan Nie",
      "Shuang Li",
      "Qiuyang Feng",
      "Pengxu Qiu",
      "Yujia Wang",
      "Wenqiang Han",
      "Linyan Huang",
      "Gang Li",
      "Jingjing Mo",
      "Haowen Hu"
    ],
    "published": "2025-07-19T02:46:19Z",
    "updated": "2025-07-22T10:01:32Z",
    "pdf_url": "https://arxiv.org/pdf/2507.14447v2",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2402.09727v3",
    "title": "A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts",
    "summary": "Current Large Language Models (LLMs) are not only limited to some maximum context length, but also are not able to robustly consume long inputs. To address these limitations, we propose ReadAgent, an LLM agent system that increases effective context length up to 20x in our experiments. Inspired by how humans interactively read long documents, we implement ReadAgent as a simple prompting system that uses the advanced language capabilities of LLMs to (1) decide what content to store together in a memory episode, (2) compress those memory episodes into short episodic memories called gist memories, and (3) take actions to look up passages in the original text if ReadAgent needs to remind itself of relevant details to complete a task. We evaluate ReadAgent against baselines using retrieval methods, using the original long contexts, and using the gist memories. These evaluations are performed on three long-document reading comprehension tasks: QuALITY, NarrativeQA, and QMSum. ReadAgent outperforms the baselines on all three tasks while extending the effective context window by 3.5-20x.",
    "authors": [
      "Kuang-Huei Lee",
      "Xinyun Chen",
      "Hiroki Furuta",
      "John Canny",
      "Ian Fischer"
    ],
    "published": "2024-02-15T05:40:21Z",
    "updated": "2024-07-22T05:33:51Z",
    "pdf_url": "https://arxiv.org/pdf/2402.09727v3",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2509.03312v2",
    "title": "AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?",
    "summary": "Large Language Model (LLM)-based agentic systems, often comprising multiple models, complex tool invocations, and orchestration protocols, substantially outperform monolithic agents. Yet this very sophistication amplifies their fragility, making them more prone to system failure. Pinpointing the specific agent or step responsible for an error within long execution traces defines the task of agentic system failure attribution. Current state-of-the-art reasoning LLMs, however, remain strikingly inadequate for this challenge, with accuracy generally below 10%. To address this gap, we propose AgenTracer, the first automated framework for annotating failed multi-agent trajectories via counterfactual replay and programmed fault injection, producing the curated dataset TracerTraj. Leveraging this resource, we develop AgenTracer-8B, a lightweight failure tracer trained with multi-granular reinforcement learning, capable of efficiently diagnosing errors in verbose multi-agent interactions. On the Who&When benchmark, AgenTracer-8B outperforms giant proprietary LLMs like Gemini-2.5-Pro and Claude-4-Sonnet by up to 18.18%, setting a new standard in LLM agentic failure attribution. More importantly, AgenTracer-8B delivers actionable feedback to off-the-shelf multi-agent systems like MetaGPT and MaAS with 4.8-14.2% performance gains, empowering self-correcting and self-evolving agentic AI.",
    "authors": [
      "Guibin Zhang",
      "Junhao Wang",
      "Junjie Chen",
      "Wangchunshu Zhou",
      "Kun Wang",
      "Shuicheng Yan"
    ],
    "published": "2025-09-03T13:42:14Z",
    "updated": "2025-09-04T17:49:20Z",
    "pdf_url": "https://arxiv.org/pdf/2509.03312v2",
    "categories": [
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2409.03440v1",
    "title": "Rx Strategist: Prescription Verification using LLM Agents System",
    "summary": "To protect patient safety, modern pharmaceutical complexity demands strict prescription verification. We offer a new approach - Rx Strategist - that makes use of knowledge graphs and different search strategies to enhance the power of Large Language Models (LLMs) inside an agentic framework. This multifaceted technique allows for a multi-stage LLM pipeline and reliable information retrieval from a custom-built active ingredient database. Different facets of prescription verification, such as indication, dose, and possible drug interactions, are covered in each stage of the pipeline. We alleviate the drawbacks of monolithic LLM techniques by spreading reasoning over these stages, improving correctness and reliability while reducing memory demands. Our findings demonstrate that Rx Strategist surpasses many current LLMs, achieving performance comparable to that of a highly experienced clinical pharmacist. In the complicated world of modern medications, this combination of LLMs with organized knowledge and sophisticated search methods presents a viable avenue for reducing prescription errors and enhancing patient outcomes.",
    "authors": [
      "Phuc Phan Van",
      "Dat Nguyen Minh",
      "An Dinh Ngoc",
      "Huy Phan Thanh"
    ],
    "published": "2024-09-05T11:42:26Z",
    "updated": "2024-09-05T11:42:26Z",
    "pdf_url": "https://arxiv.org/pdf/2409.03440v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2512.06721v1",
    "title": "ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems",
    "summary": "Large Language Model (LLM) agents are emerging to transform daily life. However, existing LLM agents primarily follow a reactive paradigm, relying on explicit user instructions to initiate services, which increases both physical and cognitive workload. In this paper, we propose ProAgent, the first end-to-end proactive agent system that harnesses massive sensory contexts and LLM reasoning to deliver proactive assistance. ProAgent first employs a proactive-oriented context extraction approach with on-demand tiered perception to continuously sense the environment and derive hierarchical contexts that incorporate both sensory and persona cues. ProAgent then adopts a context-aware proactive reasoner to map these contexts to user needs and tool calls, providing proactive assistance. We implement ProAgent on Augmented Reality (AR) glasses with an edge server and extensively evaluate it on a real-world testbed, a public dataset, and through a user study. Results show that ProAgent achieves up to 33.4% higher proactive prediction accuracy, 16.8% higher tool-calling F1 score, and notable improvements in user satisfaction over state-of-the-art baselines, marking a significant step toward proactive assistants. A video demonstration of ProAgent is available at https://youtu.be/pRXZuzvrcVs.",
    "authors": [
      "Bufang Yang",
      "Lilin Xu",
      "Liekang Zeng",
      "Yunqi Guo",
      "Siyang Jiang",
      "Wenrui Lu",
      "Kaiwei Liu",
      "Hancheng Xiang",
      "Xiaofan Jiang",
      "Guoliang Xing",
      "Zhenyu Yan"
    ],
    "published": "2025-12-07T08:21:07Z",
    "updated": "2025-12-07T08:21:07Z",
    "pdf_url": "https://arxiv.org/pdf/2512.06721v1",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2408.09785v2",
    "title": "GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making",
    "summary": "Traditional methods for making software deployment decisions in the automotive industry typically rely on manual analysis of tabular software test data. These methods often lead to higher costs and delays in the software release cycle due to their labor-intensive nature. Large Language Models (LLMs) present a promising solution to these challenges. However, their application generally demands multiple rounds of human-driven prompt engineering, which limits their practical deployment, particularly for industrial end-users who need reliable and efficient results. In this paper, we propose GoNoGo, an LLM agent system designed to streamline automotive software deployment while meeting both functional requirements and practical industrial constraints. Unlike previous systems, GoNoGo is specifically tailored to address domain-specific and risk-sensitive systems. We evaluate GoNoGo's performance across different task difficulties using zero-shot and few-shot examples taken from industrial practice. Our results show that GoNoGo achieves a 100% success rate for tasks up to Level 2 difficulty with 3-shot examples, and maintains high performance even for more complex tasks. We find that GoNoGo effectively automates decision-making for simpler tasks, significantly reducing the need for manual intervention. In summary, GoNoGo represents an efficient and user-friendly LLM-based solution currently employed in our industrial partner's company to assist with software release decision-making, supporting more informed and timely decisions in the release process for risk-sensitive vehicle systems.",
    "authors": [
      "Arsham Gholamzadeh Khoee",
      "Yinan Yu",
      "Robert Feldt",
      "Andris Freimanis",
      "Patrick Andersson Rhodin",
      "Dhasarathy Parthasarathy"
    ],
    "published": "2024-08-19T08:22:20Z",
    "updated": "2024-09-29T09:46:01Z",
    "pdf_url": "https://arxiv.org/pdf/2408.09785v2",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2502.02534v2",
    "title": "Adaptive Self-improvement LLM Agentic System for ML Library Development",
    "summary": "ML libraries, often written in architecture-specific programming languages (ASPLs) that target domain-specific architectures, are key to efficient ML systems. However, writing these high-performance ML libraries is challenging because it requires expert knowledge of ML algorithms and the ASPL. Large language models (LLMs), on the other hand, have shown general coding capabilities. However, challenges remain when using LLMs for generating ML libraries using ASPLs because 1) this task is complicated even for experienced human programmers and 2) there are limited code examples because of the esoteric and evolving nature of ASPLs. Therefore, LLMs need complex reasoning with limited data in order to complete this task. To address these challenges, we introduce an adaptive self-improvement agentic system. In order to evaluate the effectiveness of our system, we construct a benchmark of a typical ML library and generate ASPL code with both open and closed-source LLMs on this benchmark. Our results show improvements of up to $3.9\\times$ over a baseline single LLM.",
    "authors": [
      "Genghan Zhang",
      "Weixin Liang",
      "Olivia Hsu",
      "Kunle Olukotun"
    ],
    "published": "2025-02-04T17:57:17Z",
    "updated": "2025-09-19T04:28:06Z",
    "pdf_url": "https://arxiv.org/pdf/2502.02534v2",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2503.21460v1",
    "title": "Large Language Model Agent: A Survey on Methodology, Applications and Challenges",
    "summary": "The era of intelligent agents is upon us, driven by revolutionary advancements in large language models. Large Language Model (LLM) agents, with goal-driven behaviors and dynamic adaptation capabilities, potentially represent a critical pathway toward artificial general intelligence. This survey systematically deconstructs LLM agent systems through a methodology-centered taxonomy, linking architectural foundations, collaboration mechanisms, and evolutionary pathways. We unify fragmented research threads by revealing fundamental connections between agent design principles and their emergent behaviors in complex environments. Our work provides a unified architectural perspective, examining how agents are constructed, how they collaborate, and how they evolve over time, while also addressing evaluation methodologies, tool applications, practical challenges, and diverse application domains. By surveying the latest developments in this rapidly evolving field, we offer researchers a structured taxonomy for understanding LLM agents and identify promising directions for future research. The collection is available at https://github.com/luo-junyu/Awesome-Agent-Papers.",
    "authors": [
      "Junyu Luo",
      "Weizhi Zhang",
      "Ye Yuan",
      "Yusheng Zhao",
      "Junwei Yang",
      "Yiyang Gu",
      "Bohan Wu",
      "Binqi Chen",
      "Ziyue Qiao",
      "Qingqing Long",
      "Rongcheng Tu",
      "Xiao Luo",
      "Wei Ju",
      "Zhiping Xiao",
      "Yifan Wang",
      "Meng Xiao",
      "Chenwu Liu",
      "Jingyang Yuan",
      "Shichang Zhang",
      "Yiqiao Jin",
      "Fan Zhang",
      "Xian Wu",
      "Hanqing Zhao",
      "Dacheng Tao",
      "Philip S. Yu",
      "Ming Zhang"
    ],
    "published": "2025-03-27T12:50:17Z",
    "updated": "2025-03-27T12:50:17Z",
    "pdf_url": "https://arxiv.org/pdf/2503.21460v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2411.01747v3",
    "title": "DynaSaur: Large Language Agents Beyond Predefined Actions",
    "summary": "Existing LLM agent systems typically select actions from a fixed and predefined set at every step. While this approach is effective in closed, narrowly scoped environments, it presents two major challenges for real-world, open-ended scenarios: (1) it significantly restricts the planning and acting capabilities of LLM agents, and (2) it requires substantial human effort to enumerate and implement all possible actions, which is impractical in complex environments with a vast number of potential actions. To address these limitations, we propose an LLM agent framework that can dynamically create and compose actions as needed. In this framework, the agent interacts with its environment by generating and executing programs written in a general-purpose programming language. Moreover, generated actions are accumulated over time for future reuse. Our extensive experiments across multiple benchmarks show that this framework significantly improves flexibility and outperforms prior methods that rely on a fixed action set. Notably, it enables LLM agents to adapt and recover in scenarios where predefined actions are insufficient or fail due to unforeseen edge cases. Our code can be found in https://github.com/adobe-research/dynasaur.",
    "authors": [
      "Dang Nguyen",
      "Viet Dac Lai",
      "Seunghyun Yoon",
      "Ryan A. Rossi",
      "Handong Zhao",
      "Ruiyi Zhang",
      "Puneet Mathur",
      "Nedim Lipka",
      "Yu Wang",
      "Trung Bui",
      "Franck Dernoncourt",
      "Tianyi Zhou"
    ],
    "published": "2024-11-04T02:08:59Z",
    "updated": "2025-09-04T16:22:32Z",
    "pdf_url": "https://arxiv.org/pdf/2411.01747v3",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2601.00097v3",
    "title": "The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs",
    "summary": "We design a large-language-model (LLM) agent system that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy$-$its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while the system still stays on its agentic leash. We show in particular that a sequence of three system-instruction sets guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.",
    "authors": [
      "Akash Kumar Panda",
      "Olaoluwa Adigun",
      "Bart Kosko"
    ],
    "published": "2025-12-31T20:06:48Z",
    "updated": "2026-02-15T17:25:39Z",
    "pdf_url": "https://arxiv.org/pdf/2601.00097v3",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2510.02360v2",
    "title": "Spiral of Silence in Large Language Model Agents",
    "summary": "The Spiral of Silence (SoS) theory holds that individuals with minority views often refrain from speaking out for fear of social isolation, enabling majority positions to dominate public discourse. When the 'agents' are large language models (LLMs), however, the classical psychological explanation is not directly applicable, since SoS was developed for human societies. This raises a central question: can SoS-like dynamics nevertheless emerge from purely statistical language generation in LLM collectives? We propose an evaluation framework for examining SoS in LLM agents. Specifically, we consider four controlled conditions that systematically vary the availability of 'History' and 'Persona' signals. Opinion dynamics are assessed using trend tests such as Mann-Kendall and Spearman's rank, along with concentration measures including kurtosis and interquartile range. Experiments across open-source and closed-source models show that history and persona together produce strong majority dominance and replicate SoS patterns; history signals alone induce strong anchoring; and persona signals alone foster diverse but uncorrelated opinions, indicating that without historical anchoring, SoS dynamics cannot emerge. The work bridges computational sociology and responsible AI design, highlighting the need to monitor and mitigate emergent conformity in LLM-agent systems.",
    "authors": [
      "Mingze Zhong",
      "Meng Fang",
      "Zijing Shi",
      "Yuxuan Huang",
      "Shunfeng Zheng",
      "Yali Du",
      "Ling Chen",
      "Jun Wang"
    ],
    "published": "2025-09-28T08:59:54Z",
    "updated": "2025-10-08T01:58:17Z",
    "pdf_url": "https://arxiv.org/pdf/2510.02360v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2310.06272v2",
    "title": "Let Models Speak Ciphers: Multiagent Debate through Embeddings",
    "summary": "Discussion and debate among Large Language Models (LLMs) have gained considerable attention due to their potential to enhance the reasoning ability of LLMs. Although natural language is an obvious choice for communication due to LLM's language understanding capability, the token sampling step needed when generating natural language poses a potential risk of information loss, as it uses only one token to represent the model's belief across the entire vocabulary. In this paper, we introduce a communication regime named CIPHER (Communicative Inter-Model Protocol Through Embedding Representation) to address this issue. Specifically, we remove the token sampling step from LLMs and let them communicate their beliefs across the vocabulary through the expectation of the raw transformer output embeddings. Remarkably, by deviating from natural language, CIPHER offers an advantage of encoding a broader spectrum of information without any modification to the model weights, outperforming the state-of-the-art LLM debate methods using natural language by 0.5-5.0% across five reasoning tasks and multiple open-source LLMs of varying sizes. This showcases the superiority and robustness of embeddings as an alternative \"language\" for communication among LLMs. We anticipate that CIPHER will inspire further exploration for the design of interactions within LLM agent systems, offering a new direction that could significantly influence future developments in the field.",
    "authors": [
      "Chau Pham",
      "Boyi Liu",
      "Yingxiang Yang",
      "Zhengyu Chen",
      "Tianyi Liu",
      "Jianbo Yuan",
      "Bryan A. Plummer",
      "Zhaoran Wang",
      "Hongxia Yang"
    ],
    "published": "2023-10-10T03:06:38Z",
    "updated": "2024-02-26T17:36:48Z",
    "pdf_url": "https://arxiv.org/pdf/2310.06272v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2511.08274v1",
    "title": "Multi-Agent GraphRAG: A Text-to-Cypher Framework for Labeled Property Graphs",
    "summary": "While Retrieval-Augmented Generation (RAG) methods commonly draw information from unstructured documents, the emerging paradigm of GraphRAG aims to leverage structured data such as knowledge graphs. Most existing GraphRAG efforts focus on Resource Description Framework (RDF) knowledge graphs, relying on triple representations and SPARQL queries. However, the potential of Cypher and Labeled Property Graph (LPG) databases to serve as scalable and effective reasoning engines within GraphRAG pipelines remains underexplored in current research literature. To fill this gap, we propose Multi-Agent GraphRAG, a modular LLM agentic system for text-to-Cypher query generation serving as a natural language interface to LPG-based graph data. Our proof-of-concept system features an LLM-based workflow for automated Cypher queries generation and execution, using Memgraph as the graph database backend. Iterative content-aware correction and normalization, reinforced by an aggregated feedback loop, ensures both semantic and syntactic refinement of generated queries. We evaluate our system on the CypherBench graph dataset covering several general domains with diverse types of queries. In addition, we demonstrate performance of the proposed workflow on a property graph derived from the IFC (Industry Foundation Classes) data, representing a digital twin of a building. This highlights how such an approach can bridge AI with real-world applications at scale, enabling industrial digital automation use cases.",
    "authors": [
      "Anton Gusarov",
      "Anastasia Volkova",
      "Valentin Khrulkov",
      "Andrey Kuznetsov",
      "Evgenii Maslov",
      "Ivan Oseledets"
    ],
    "published": "2025-11-11T14:04:00Z",
    "updated": "2025-11-11T14:04:00Z",
    "pdf_url": "https://arxiv.org/pdf/2511.08274v1",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2506.17419v1",
    "title": "UProp: Investigating the Uncertainty Propagation of LLMs in Multi-Step Agentic Decision-Making",
    "summary": "As Large Language Models (LLMs) are integrated into safety-critical applications involving sequential decision-making in the real world, it is essential to know when to trust LLM decisions. Existing LLM Uncertainty Quantification (UQ) methods are primarily designed for single-turn question-answering formats, resulting in multi-step decision-making scenarios, e.g., LLM agentic system, being underexplored. In this paper, we introduce a principled, information-theoretic framework that decomposes LLM sequential decision uncertainty into two parts: (i) internal uncertainty intrinsic to the current decision, which is focused on existing UQ methods, and (ii) extrinsic uncertainty, a Mutual-Information (MI) quantity describing how much uncertainty should be inherited from preceding decisions. We then propose UProp, an efficient and effective extrinsic uncertainty estimator that converts the direct estimation of MI to the estimation of Pointwise Mutual Information (PMI) over multiple Trajectory-Dependent Decision Processes (TDPs). UProp is evaluated over extensive multi-step decision-making benchmarks, e.g., AgentBench and HotpotQA, with state-of-the-art LLMs, e.g., GPT-4.1 and DeepSeek-V3. Experimental results demonstrate that UProp significantly outperforms existing single-turn UQ baselines equipped with thoughtful aggregation strategies. Moreover, we provide a comprehensive analysis of UProp, including sampling efficiency, potential applications, and intermediate uncertainty propagation, to demonstrate its effectiveness. Codes will be available at https://github.com/jinhaoduan/UProp.",
    "authors": [
      "Jinhao Duan",
      "James Diffenderfer",
      "Sandeep Madireddy",
      "Tianlong Chen",
      "Bhavya Kailkhura",
      "Kaidi Xu"
    ],
    "published": "2025-06-20T18:34:04Z",
    "updated": "2025-06-20T18:34:04Z",
    "pdf_url": "https://arxiv.org/pdf/2506.17419v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2511.11306v2",
    "title": "iMAD: Intelligent Multi-Agent Debate for Efficient and Accurate LLM Inference",
    "summary": "Large Language Model (LLM) agent systems have advanced rapidly, driven by their strong generalization in zero-shot settings. To further enhance reasoning and accuracy on complex tasks, Multi-Agent Debate (MAD) has emerged as a promising framework that engages multiple LLM agents in structured debates to encourage diverse reasoning. However, triggering MAD for every query is inefficient, as it incurs substantial computational (token) cost and may even degrade accuracy by overturning correct single-agent answers. To address these limitations, we propose intelligent Multi-Agent Debate (iMAD), a token-efficient framework that selectively triggers MAD only when it is likely to be beneficial (i.e., correcting an initially wrong answer). To achieve this goal, iMAD learns generalizable model behaviors to make accurate debate decisions. Specifically, iMAD first prompts a single agent to produce a structured self-critique response, from which we extract 41 interpretable linguistic and semantic features capturing hesitation cues. Then, iMAD uses a lightweight debate-decision classifier, trained using our proposed FocusCal loss, to determine whether to trigger MAD, enabling robust debate decisions without test dataset-specific tuning. Through extensive experiments using six (visual) question answering datasets against five competitive baselines, we have shown that iMAD significantly reduces token usage (by up to 92%) while also improving final answer accuracy (by up to 13.5%).",
    "authors": [
      "Wei Fan",
      "JinYi Yoon",
      "Bo Ji"
    ],
    "published": "2025-11-14T13:50:51Z",
    "updated": "2025-12-02T14:13:32Z",
    "pdf_url": "https://arxiv.org/pdf/2511.11306v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2408.06717v3",
    "title": "Proficient Graph Neural Network Design by Accumulating Knowledge on Large Language Models",
    "summary": "High-level automation is increasingly critical in AI, driven by rapid advances in large language models (LLMs) and AI agents. However, LLMs, despite their general reasoning power, struggle significantly in specialized, data-sensitive tasks such as designing Graph Neural Networks (GNNs). This difficulty arises from (1) the inherent knowledge gaps in modeling the intricate, varying relationships between graph properties and suitable architectures and (2) the external noise from misleading descriptive inputs, often resulting in generic or even misleading model suggestions. Achieving proficiency in designing data-aware models -- defined as the meta-level capability to systematically accumulate, interpret, and apply data-specific design knowledge -- remains challenging for existing automated approaches, due to their inefficient construction and application of meta-knowledge. To achieve meta-level proficiency, we propose DesiGNN, a knowledge-centered framework that systematically converts past model design experience into structured, fine-grained knowledge priors well-suited for meta-learning with LLMs. To account for the inherent variability and external noise, DesiGNN aligns empirical property filtering from extensive benchmarks with adaptive elicitation of literature insights via LLMs. By constructing a solid meta-knowledge between unseen graph understanding and known effective architecture patterns, DesiGNN can deliver top-5.77% initial model proposals for unseen datasets within seconds and achieve consistently superior performance with minimal search cost compared to baselines.",
    "authors": [
      "Jialiang Wang",
      "Hanmo Liu",
      "Shimin Di",
      "Zhili Wang",
      "Jiachuan Wang",
      "Lei Chen",
      "Xiaofang Zhou"
    ],
    "published": "2024-08-13T08:22:01Z",
    "updated": "2026-02-11T18:49:00Z",
    "pdf_url": "https://arxiv.org/pdf/2408.06717v3",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2407.02342v1",
    "title": "Optimizing Age of Information in Vehicular Edge Computing with Federated Graph Neural Network Multi-Agent Reinforcement Learning",
    "summary": "With the rapid development of intelligent vehicles and Intelligent Transport Systems (ITS), the sensors such as cameras and LiDAR installed on intelligent vehicles provides higher capacity of executing computation-intensive and delay-sensitive tasks, thereby raising deployment costs. To address this issue, Vehicular Edge Computing (VEC) has been proposed to process data through Road Side Units (RSUs) to support real-time applications. This paper focuses on the Age of Information (AoI) as a key metric for data freshness and explores task offloading issues for vehicles under RSU communication resource constraints. We adopt a Multi-agent Deep Reinforcement Learning (MADRL) approach, allowing vehicles to autonomously make optimal data offloading decisions. However, MADRL poses risks of vehicle information leakage during communication learning and centralized training. To mitigate this, we employ a Federated Learning (FL) framework that shares model parameters instead of raw data to protect the privacy of vehicle users. Building on this, we propose an innovative distributed federated learning framework combining Graph Neural Networks (GNN), named Federated Graph Neural Network Multi-Agent Reinforcement Learning (FGNN-MADRL), to optimize AoI across the system. For the first time, road scenarios are constructed as graph data structures, and a GNN-based federated learning framework is proposed, effectively combining distributed and centralized federated aggregation. Furthermore, we propose a new MADRL algorithm that simplifies decision making and enhances offloading efficiency, further reducing the decision complexity. Simulation results demonstrate the superiority of our proposed approach to other methods through simulations.",
    "authors": [
      "Wenhua Wang",
      "Qiong Wu",
      "Pingyi Fan",
      "Nan Cheng",
      "Wen Chen",
      "Jiangzhou Wang",
      "Khaled B. Letaief"
    ],
    "published": "2024-07-01T15:37:38Z",
    "updated": "2024-07-01T15:37:38Z",
    "pdf_url": "https://arxiv.org/pdf/2407.02342v1",
    "categories": [
      "cs.LG",
      "cs.DC",
      "cs.MA",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2406.00552v4",
    "title": "Graph Neural Network Training Systems: A Performance Comparison of Full-Graph and Mini-Batch",
    "summary": "Graph Neural Networks (GNNs) have gained significant attention in recent years due to their ability to learn representations of graph-structured data. Two common methods for training GNNs are mini-batch training and full-graph training. Since these two methods require different training pipelines and systems optimizations, two separate classes of GNN training systems emerged, each tailored for one method. Works that introduce systems belonging to a particular category predominantly compare them with other systems within the same category, offering limited or no comparison with systems from the other category. Some prior work also justifies its focus on one specific training method by arguing that it achieves higher accuracy than the alternative. The literature, however, has incomplete and contradictory evidence in this regard. In this paper, we provide a comprehensive empirical comparison of representative full-graph and mini-batch GNN training systems. We find that the mini-batch training systems consistently converge faster than the full-graph training ones across multiple datasets, GNN models, and system configurations. We also find that mini-batch training techniques converge to similar to or often higher accuracy values than full-graph training ones, showing that mini-batch sampling is not necessarily detrimental to accuracy. Our work highlights the importance of comparing systems across different classes, using time-to-accuracy rather than epoch time for performance comparison, and selecting appropriate hyperparameters for each training method separately.",
    "authors": [
      "Saurabh Bajaj",
      "Hojae Son",
      "Juelin Liu",
      "Hui Guan",
      "Marco Serafini"
    ],
    "published": "2024-06-01T21:07:24Z",
    "updated": "2024-12-20T21:47:52Z",
    "pdf_url": "https://arxiv.org/pdf/2406.00552v4",
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2504.07923v1",
    "title": "Trading Graph Neural Network",
    "summary": "This paper proposes a new algorithm -- Trading Graph Neural Network (TGNN) that can structurally estimate the impact of asset features, dealer features and relationship features on asset prices in trading networks. It combines the strength of the traditional simulated method of moments (SMM) and recent machine learning techniques -- Graph Neural Network (GNN). It outperforms existing reduced-form methods with network centrality measures in prediction accuracy. The method can be used on networks with any structure, allowing for heterogeneity among both traders and assets.",
    "authors": [
      "Xian Wu"
    ],
    "published": "2025-04-10T17:40:31Z",
    "updated": "2025-04-10T17:40:31Z",
    "pdf_url": "https://arxiv.org/pdf/2504.07923v1",
    "categories": [
      "q-fin.TR",
      "cs.LG",
      "econ.GN",
      "q-fin.PR"
    ],
    "primary_category": "q-fin.TR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2508.06793v2",
    "title": "Geometry-Aware Spiking Graph Neural Network",
    "summary": "Graph Neural Networks (GNNs) have demonstrated impressive capabilities in modeling graph-structured data, while Spiking Neural Networks (SNNs) offer high energy efficiency through sparse, event-driven computation. However, existing spiking GNNs predominantly operate in Euclidean space and rely on fixed geometric assumptions, limiting their capacity to model complex graph structures such as hierarchies and cycles. To overcome these limitations, we propose \\method{}, a novel Geometry-Aware Spiking Graph Neural Network that unifies spike-based neural dynamics with adaptive representation learning on Riemannian manifolds. \\method{} features three key components: a Riemannian Embedding Layer that projects node features into a pool of constant-curvature manifolds, capturing non-Euclidean structures; a Manifold Spiking Layer that models membrane potential evolution and spiking behavior in curved spaces via geometry-consistent neighbor aggregation and curvature-based attention; and a Manifold Learning Objective that enables instance-wise geometry adaptation through jointly optimized classification and link prediction losses defined over geodesic distances. All modules are trained using Riemannian SGD, eliminating the need for backpropagation through time. Extensive experiments on multiple benchmarks show that GSG achieves superior accuracy, robustness, and energy efficiency compared to both Euclidean SNNs and manifold-based GNNs, establishing a new paradigm for curvature-aware, energy-efficient graph learning.",
    "authors": [
      "Bowen Zhang",
      "Genan Dai",
      "Hu Huang",
      "Long Lan"
    ],
    "published": "2025-08-09T02:52:38Z",
    "updated": "2025-08-25T10:22:46Z",
    "pdf_url": "https://arxiv.org/pdf/2508.06793v2",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2311.02143v2",
    "title": "Pairing-based graph neural network for simulating quantum materials",
    "summary": "We develop a pairing-based graph neural network for simulating quantum many-body systems. Our architecture augments a BCS-type geminal wavefunction with a generalized pair amplitude parameterized by a graph neural network. Variational Monte Carlo with our neural network simultaneously provides an accurate, flexible, and scalable method for simulating many-electron systems. We apply this method to two-dimensional semiconductor electron-hole bilayers and obtain accurate results on a variety of interaction-induced phases, including the exciton Bose-Einstein condensate, electron-hole superconductor, and bilayer Wigner crystal. Our study demonstrates the potential of physically-motivated neural network wavefunctions for quantum materials simulations.",
    "authors": [
      "Di Luo",
      "David D. Dai",
      "Liang Fu"
    ],
    "published": "2023-11-03T17:12:29Z",
    "updated": "2023-11-21T15:54:28Z",
    "pdf_url": "https://arxiv.org/pdf/2311.02143v2",
    "categories": [
      "cond-mat.str-el",
      "cond-mat.dis-nn",
      "cs.LG",
      "physics.comp-ph",
      "quant-ph"
    ],
    "primary_category": "cond-mat.str-el",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2404.06090v1",
    "title": "Fair Graph Neural Network with Supervised Contrastive Regularization",
    "summary": "In recent years, Graph Neural Networks (GNNs) have made significant advancements, particularly in tasks such as node classification, link prediction, and graph representation. However, challenges arise from biases that can be hidden not only in the node attributes but also in the connections between entities. Therefore, ensuring fairness in graph neural network learning has become a critical problem. To address this issue, we propose a novel model for training fairness-aware GNN, which enhances the Counterfactual Augmented Fair Graph Neural Network Framework (CAF). Our approach integrates Supervised Contrastive Loss and Environmental Loss to enhance both accuracy and fairness. Experimental validation on three real datasets demonstrates the superiority of our proposed model over CAF and several other existing graph-based learning methods.",
    "authors": [
      "Mahdi Tavassoli Kejani",
      "Fadi Dornaika",
      "Jean-Michel Loubes"
    ],
    "published": "2024-04-09T07:49:05Z",
    "updated": "2024-04-09T07:49:05Z",
    "pdf_url": "https://arxiv.org/pdf/2404.06090v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2302.10804v1",
    "title": "GDBN: a Graph Neural Network Approach to Dynamic Bayesian Network",
    "summary": "Identifying causal relations among multi-variate time series is one of the most important elements towards understanding the complex mechanisms underlying the dynamic system. It provides critical tools for forecasting, simulations and interventions in science and business analytics. In this paper, we proposed a graph neural network approach with score-based method aiming at learning a sparse DAG that captures the causal dependencies in a discretized time temporal graph. We demonstrate methods with graph neural network significantly outperformed other state-of-the-art methods with dynamic bayesian networking inference. In addition, from the experiments, the structural causal model can be more accurate than a linear SCM discovered by the methods such as Notears.",
    "authors": [
      "Yang Sun",
      "Yifan Xie"
    ],
    "published": "2023-01-28T02:49:13Z",
    "updated": "2023-01-28T02:49:13Z",
    "pdf_url": "https://arxiv.org/pdf/2302.10804v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2401.00755v1",
    "title": "Saliency-Aware Regularized Graph Neural Network",
    "summary": "The crux of graph classification lies in the effective representation learning for the entire graph. Typical graph neural networks focus on modeling the local dependencies when aggregating features of neighboring nodes, and obtain the representation for the entire graph by aggregating node features. Such methods have two potential limitations: 1) the global node saliency w.r.t. graph classification is not explicitly modeled, which is crucial since different nodes may have different semantic relevance to graph classification; 2) the graph representation directly aggregated from node features may have limited effectiveness to reflect graph-level information. In this work, we propose the Saliency-Aware Regularized Graph Neural Network (SAR-GNN) for graph classification, which consists of two core modules: 1) a traditional graph neural network serving as the backbone for learning node features and 2) the Graph Neural Memory designed to distill a compact graph representation from node features of the backbone. We first estimate the global node saliency by measuring the semantic similarity between the compact graph representation and node features. Then the learned saliency distribution is leveraged to regularize the neighborhood aggregation of the backbone, which facilitates the message passing of features for salient nodes and suppresses the less relevant nodes. Thus, our model can learn more effective graph representation. We demonstrate the merits of SAR-GNN by extensive experiments on seven datasets across various types of graph data. Code will be released.",
    "authors": [
      "Wenjie Pei",
      "Weina Xu",
      "Zongze Wu",
      "Weichao Li",
      "Jinfan Wang",
      "Guangming Lu",
      "Xiangrong Wang"
    ],
    "published": "2024-01-01T13:44:16Z",
    "updated": "2024-01-01T13:44:16Z",
    "pdf_url": "https://arxiv.org/pdf/2401.00755v1",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2301.11164v1",
    "title": "A Graph Neural Network with Negative Message Passing for Graph Coloring",
    "summary": "Graph neural networks have received increased attention over the past years due to their promising ability to handle graph-structured data, which can be found in many real-world problems such as recommended systems and drug synthesis. Most existing research focuses on using graph neural networks to solve homophilous problems, but little attention has been paid to heterophily-type problems. In this paper, we propose a graph network model for graph coloring, which is a class of representative heterophilous problems. Different from the conventional graph networks, we introduce negative message passing into the proposed graph neural network for more effective information exchange in handling graph coloring problems. Moreover, a new loss function taking into account the self-information of the nodes is suggested to accelerate the learning process. Experimental studies are carried out to compare the proposed graph model with five state-of-the-art algorithms on ten publicly available graph coloring problems and one real-world application. Numerical results demonstrate the effectiveness of the proposed graph neural network.",
    "authors": [
      "Xiangyu Wang",
      "Xueming Yan",
      "Yaochu Jin"
    ],
    "published": "2023-01-26T15:08:42Z",
    "updated": "2023-01-26T15:08:42Z",
    "pdf_url": "https://arxiv.org/pdf/2301.11164v1",
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2410.11290v2",
    "title": "Backdoor Attack on Vertical Federated Graph Neural Network Learning",
    "summary": "Federated Graph Neural Network (FedGNN) integrate federated learning (FL) with graph neural networks (GNNs) to enable privacy-preserving training on distributed graph data. Vertical Federated Graph Neural Network (VFGNN), a key branch of FedGNN, handles scenarios where data features and labels are distributed among participants. Despite the robust privacy-preserving design of VFGNN, we have found that it still faces the risk of backdoor attacks, even in situations where labels are inaccessible. This paper proposes BVG, a novel backdoor attack method that leverages multi-hop triggers and backdoor retention, requiring only four target-class nodes to execute effective attacks. Experimental results demonstrate that BVG achieves nearly 100% attack success rates across three commonly used datasets and three GNN models, with minimal impact on the main task accuracy. We also evaluated various defense methods, and the BVG method maintained high attack effectiveness even under existing defenses. This finding highlights the need for advanced defense mechanisms to counter sophisticated backdoor attacks in practical VFGNN applications.",
    "authors": [
      "Jirui Yang",
      "Peng Chen",
      "Zhihui Lu",
      "Ruijun Deng",
      "Qiang Duan",
      "Jianping Zeng"
    ],
    "published": "2024-10-15T05:26:20Z",
    "updated": "2025-01-24T14:13:55Z",
    "pdf_url": "https://arxiv.org/pdf/2410.11290v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2301.10569v2",
    "title": "Spatio-Temporal Graph Neural Networks: A Survey",
    "summary": "Graph Neural Networks have gained huge interest in the past few years. These powerful algorithms expanded deep learning models to non-Euclidean space and were able to achieve state of art performance in various applications including recommender systems and social networks. However, this performance is based on static graph structures assumption which limits the Graph Neural Networks performance when the data varies with time. Spatiotemporal Graph Neural Networks are extension of Graph Neural Networks that takes the time factor into account. Recently, various Spatiotemporal Graph Neural Network algorithms were proposed and achieved superior performance compared to other deep learning algorithms in several time dependent applications. This survey discusses interesting topics related to Spatiotemporal Graph Neural Networks, including algorithms, applications, and open challenges.",
    "authors": [
      "Zahraa Al Sahili",
      "Mariette Awad"
    ],
    "published": "2023-01-25T13:17:46Z",
    "updated": "2023-02-11T23:23:24Z",
    "pdf_url": "https://arxiv.org/pdf/2301.10569v2",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2411.04055v1",
    "title": "Multi-branch Spatio-Temporal Graph Neural Network For Efficient Ice Layer Thickness Prediction",
    "summary": "Understanding spatio-temporal patterns in polar ice layers is essential for tracking changes in ice sheet balance and assessing ice dynamics. While convolutional neural networks are widely used in learning ice layer patterns from raw echogram images captured by airborne snow radar sensors, noise in the echogram images prevents researchers from getting high-quality results. Instead, we focus on geometric deep learning using graph neural networks, aiming to build a spatio-temporal graph neural network that learns from thickness information of the top ice layers and predicts for deeper layers. In this paper, we developed a novel multi-branch spatio-temporal graph neural network that used the GraphSAGE framework for spatio features learning and a temporal convolution operation to capture temporal changes, enabling different branches of the network to be more specialized and focusing on a single learning task. We found that our proposed multi-branch network can consistently outperform the current fused spatio-temporal graph neural network in both accuracy and efficiency.",
    "authors": [
      "Zesheng Liu",
      "Maryam Rahnemoonfar"
    ],
    "published": "2024-11-06T16:59:51Z",
    "updated": "2024-11-06T16:59:51Z",
    "pdf_url": "https://arxiv.org/pdf/2411.04055v1",
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2308.16470v2",
    "title": "Domain-adaptive Message Passing Graph Neural Network",
    "summary": "Cross-network node classification (CNNC), which aims to classify nodes in a label-deficient target network by transferring the knowledge from a source network with abundant labels, draws increasing attention recently. To address CNNC, we propose a domain-adaptive message passing graph neural network (DM-GNN), which integrates graph neural network (GNN) with conditional adversarial domain adaptation. DM-GNN is capable of learning informative representations for node classification that are also transferrable across networks. Firstly, a GNN encoder is constructed by dual feature extractors to separate ego-embedding learning from neighbor-embedding learning so as to jointly capture commonality and discrimination between connected nodes. Secondly, a label propagation node classifier is proposed to refine each node's label prediction by combining its own prediction and its neighbors' prediction. In addition, a label-aware propagation scheme is devised for the labeled source network to promote intra-class propagation while avoiding inter-class propagation, thus yielding label-discriminative source embeddings. Thirdly, conditional adversarial domain adaptation is performed to take the neighborhood-refined class-label information into account during adversarial domain adaptation, so that the class-conditional distributions across networks can be better matched. Comparisons with eleven state-of-the-art methods demonstrate the effectiveness of the proposed DM-GNN.",
    "authors": [
      "Xiao Shen",
      "Shirui Pan",
      "Kup-Sze Choi",
      "Xi Zhou"
    ],
    "published": "2023-08-31T05:26:08Z",
    "updated": "2023-10-17T04:57:23Z",
    "pdf_url": "https://arxiv.org/pdf/2308.16470v2",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2405.05205v1",
    "title": "Hybrid Quantum Graph Neural Network for Molecular Property Prediction",
    "summary": "To accelerate the process of materials design, materials science has increasingly used data driven techniques to extract information from collected data. Specially, machine learning (ML) algorithms, which span the ML discipline, have demonstrated ability to predict various properties of materials with the level of accuracy similar to explicit calculation of quantum mechanical theories, but with significantly reduced run time and computational resources. Within ML, graph neural networks have emerged as an important algorithm within the field of machine learning, since they are capable of predicting accurately a wide range of important physical, chemical and electronic properties due to their higher learning ability based on the graph representation of material and molecular descriptors through the aggregation of information embedded within the graph. In parallel with the development of state of the art classical machine learning applications, the fusion of quantum computing and machine learning have created a new paradigm where classical machine learning model can be augmented with quantum layers which are able to encode high dimensional data more efficiently. Leveraging the structure of existing algorithms, we developed a unique and novel gradient free hybrid quantum classical convoluted graph neural network (HyQCGNN) to predict formation energies of perovskite materials. The performance of our hybrid statistical model is competitive with the results obtained purely from a classical convoluted graph neural network, and other classical machine learning algorithms, such as XGBoost. Consequently, our study suggests a new pathway to explore how quantum feature encoding and parametric quantum circuits can yield drastic improvements of complex ML algorithm like graph neural network.",
    "authors": [
      "Michael Vitz",
      "Hamed Mohammadbagherpoor",
      "Samarth Sandeep",
      "Andrew Vlasic",
      "Richard Padbury",
      "Anh Pham"
    ],
    "published": "2024-05-08T16:43:25Z",
    "updated": "2024-05-08T16:43:25Z",
    "pdf_url": "https://arxiv.org/pdf/2405.05205v1",
    "categories": [
      "quant-ph",
      "cond-mat.mtrl-sci",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2507.17509v1",
    "title": "Graph Neural Network Approach to Predicting Magnetization in Quasi-One-Dimensional Ising Systems",
    "summary": "We present a graph-based deep learning framework for predicting the magnetic properties of quasi-one-dimensional Ising spin systems. The lattice geometry is encoded as a graph and processed by a graph neural network (GNN) followed by fully connected layers. The model is trained on Monte Carlo simulation data and accurately reproduces key features of the magnetization curve, including plateaus, critical transition points, and the effects of geometric frustration. It captures both local motifs and global symmetries, demonstrating that GNNs can infer magnetic behavior directly from structural connectivity. The proposed approach enables efficient prediction of magnetization without the need for additional Monte Carlo simulations.",
    "authors": [
      "V. Slavin",
      "O. Kryvchikov",
      "D. Laptev"
    ],
    "published": "2025-07-23T13:47:38Z",
    "updated": "2025-07-23T13:47:38Z",
    "pdf_url": "https://arxiv.org/pdf/2507.17509v1",
    "categories": [
      "cond-mat.dis-nn",
      "cs.LG"
    ],
    "primary_category": "cond-mat.dis-nn",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2504.19820v2",
    "title": "Hierarchical Uncertainty-Aware Graph Neural Network",
    "summary": "Recent research on graph neural networks (GNNs) has explored mechanisms for capturing local uncertainty and exploiting graph hierarchies to mitigate data sparsity and leverage structural properties. However, the synergistic integration of these two approaches remains underexplored. This work introduces a novel architecture, the Hierarchical Uncertainty-Aware Graph Neural Network (HU-GNN), which unifies multi-scale representation learning, principled uncertainty estimation, and self-supervised embedding diversity within a single end-to-end framework. Specifically, HU-GNN adaptively forms node clusters and estimates uncertainty at multiple structural scales from individual nodes to higher levels. These uncertainty estimates guide a robust message-passing mechanism and attention weighting, effectively mitigating noise and adversarial perturbations while preserving predictive accuracy on semi-supervised classification tasks. We also offer key theoretical contributions, including a probabilistic formulation, rigorous uncertainty-calibration guarantees, and formal robustness bounds. Extensive experiments on standard benchmarks demonstrate that our model achieves state-of-the-art robustness and interpretability.",
    "authors": [
      "Yoonhyuk Choi",
      "Jiho Choi",
      "Taewook Ko",
      "Chong-Kwon Kim"
    ],
    "published": "2025-04-28T14:22:18Z",
    "updated": "2025-05-05T07:47:54Z",
    "pdf_url": "https://arxiv.org/pdf/2504.19820v2",
    "categories": [
      "cs.LG",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2405.09247v1",
    "title": "Graph Neural Network based Handwritten Trajectories Recognition",
    "summary": "The graph neural networks has been proved to be an efficient machine learning technique in real life applications. The handwritten recognition is one of the useful area in real life use where both offline and online handwriting recognition are required. The chain code as feature extraction technique has shown significant results in literature and we have been able to use chain codes with graph neural networks. To the best of our knowledge, this work presents first time a novel combination of handwritten trajectories features as chain codes and graph neural networks together. The handwritten trajectories for offline handwritten text has been evaluated using recovery of drawing order, whereas online handwritten trajectories are directly used with chain codes. Our results prove that present combination surpass previous results and minimize error rate in few epochs only.",
    "authors": [
      "Anuj Sharma",
      "Sukhdeep Singh",
      "S Ratna"
    ],
    "published": "2024-05-15T11:00:42Z",
    "updated": "2024-05-15T11:00:42Z",
    "pdf_url": "https://arxiv.org/pdf/2405.09247v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2505.22362v3",
    "title": "Directed Homophily-Aware Graph Neural Network",
    "summary": "Graph Neural Networks (GNNs) have achieved significant success in various learning tasks on graph-structured data. Nevertheless, most GNNs struggle to generalize to heterophilic neighborhoods. Additionally, many GNNs ignore the directional nature of real-world graphs, resulting in suboptimal performance on directed graphs with asymmetric structures. In this work, we propose Directed Homophily-aware Graph Neural Network (DHGNN), a novel framework that addresses these limitations by incorporating homophily-aware and direction-sensitive components. DHGNN employs a resettable gating mechanism to adaptively modulate message contributions based on homophily levels and informativeness, and a structure-aware noise-tolerant fusion module to effectively integrate node representations from the original and reverse directions. Extensive experiments on both homophilic and heterophilic directed graph datasets demonstrate that DHGNN outperforms state-of-the-art methods in node classification and link prediction. In particular, DHGNN improves over the best baseline by up to 15.07\\% in link prediction. Our analysis further shows that the gating mechanism captures directional homophily gaps and fluctuating homophily across layers, providing deeper insights into message-passing behavior on complex graph structures.",
    "authors": [
      "Aihu Zhang",
      "Jiaxing Xu",
      "Mengcheng Lan",
      "Shili Xiang",
      "Yiping Ke"
    ],
    "published": "2025-05-28T13:41:04Z",
    "updated": "2026-01-13T06:16:28Z",
    "pdf_url": "https://arxiv.org/pdf/2505.22362v3",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2502.16430v1",
    "title": "Network Tomography with Path-Centric Graph Neural Network",
    "summary": "Network tomography is a crucial problem in network monitoring, where the observable path performance metric values are used to infer the unobserved ones, making it essential for tasks such as route selection, fault diagnosis, and traffic control. However, most existing methods either assume complete knowledge of network topology and metric formulas-an unrealistic expectation in many real-world scenarios with limited observability-or rely entirely on black-box end-to-end models. To tackle this, in this paper, we argue that a good network tomography requires synergizing the knowledge from both data and appropriate inductive bias from (partial) prior knowledge. To see this, we propose Deep Network Tomography (DeepNT), a novel framework that leverages a path-centric graph neural network to predict path performance metrics without relying on predefined hand-crafted metrics, assumptions, or the real network topology. The path-centric graph neural network learns the path embedding by inferring and aggregating the embeddings of the sequence of nodes that compose this path. Training path-centric graph neural networks requires learning the neural netowrk parameters and network topology under discrete constraints induced by the observed path performance metrics, which motivates us to design a learning objective that imposes connectivity and sparsity constraints on topology and path performance triangle inequality on path performance. Extensive experiments on real-world and synthetic datasets demonstrate the superiority of DeepNT in predicting performance metrics and inferring graph topology compared to state-of-the-art methods.",
    "authors": [
      "Yuntong Hu",
      "Junxiang Wang",
      "Liang Zhao"
    ],
    "published": "2025-02-23T04:08:46Z",
    "updated": "2025-02-23T04:08:46Z",
    "pdf_url": "https://arxiv.org/pdf/2502.16430v1",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "cs.LG",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2406.09320v2",
    "title": "Khmer Semantic Search Engine (KSE): Digital Information Access and Document Retrieval",
    "summary": "The search engine process is crucial for document content retrieval. For Khmer documents, an effective tool is needed to extract essential keywords and facilitate accurate searches. Despite the daily generation of significant Khmer content, Cambodians struggle to find necessary documents due to the lack of an effective semantic searching tool. Even Google does not deliver high accuracy for Khmer content. Semantic search engines improve search results by employing advanced algorithms to understand various content types. With the rise in Khmer digital content such as reports, articles, and social media feedback enhanced search capabilities are essential. This research proposes the first Khmer Semantic Search Engine (KSE), designed to enhance traditional Khmer search methods. Utilizing semantic matching techniques and formally annotated semantic content, our tool extracts meaningful keywords from user queries, performs precise matching, and provides the best matching offline documents and online URLs. We propose three semantic search frameworks: semantic search based on a keyword dictionary, semantic search based on ontology, and semantic search based on ranking. Additionally, we developed tools for data preparation, including document addition and manual keyword extraction. To evaluate performance, we created a ground truth dataset and addressed issues related to searching and semantic search. Our findings demonstrate that understanding search term semantics can lead to significantly more accurate results.",
    "authors": [
      "Nimol Thuon"
    ],
    "published": "2024-06-13T16:58:02Z",
    "updated": "2024-06-16T19:08:34Z",
    "pdf_url": "https://arxiv.org/pdf/2406.09320v2",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2402.13234v1",
    "title": "Unlocking Insights: Semantic Search in Jupyter Notebooks",
    "summary": "Semantic search, a process aimed at delivering highly relevant search results by comprehending the searcher's intent and the contextual meaning of terms within a searchable dataspace, plays a pivotal role in information retrieval. In this paper, we investigate the application of large language models to enhance semantic search capabilities, specifically tailored for the domain of Jupyter Notebooks. Our objective is to retrieve generated outputs, such as figures or tables, associated functions and methods, and other pertinent information. We demonstrate a semantic search framework that achieves a comprehensive semantic understanding of the entire notebook's contents, enabling it to effectively handle various types of user queries. Key components of this framework include: 1). A data preprocessor is designed to handle diverse types of cells within Jupyter Notebooks, encompassing both markdown and code cells. 2). An innovative methodology is devised to address token size limitations that arise with code-type cells. We implement a finer-grained approach to data input, transitioning from the cell level to the function level, effectively resolving these issues.",
    "authors": [
      "Lan Li",
      "Jinpeng Lv"
    ],
    "published": "2024-02-20T18:49:41Z",
    "updated": "2024-02-20T18:49:41Z",
    "pdf_url": "https://arxiv.org/pdf/2402.13234v1",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2402.02932v1",
    "title": "Domain Adaptation of Multilingual Semantic Search -- Literature Review",
    "summary": "This literature review gives an overview of current approaches to perform domain adaptation in a low-resource and approaches to perform multilingual semantic search in a low-resource setting. We developed a new typology to cluster domain adaptation approaches based on the part of dense textual information retrieval systems, which they adapt, focusing on how to combine them efficiently. We also explore the possibilities of combining multilingual semantic search with domain adaptation approaches for dense retrievers in a low-resource setting.",
    "authors": [
      "Anna Bringmann",
      "Anastasia Zhukova"
    ],
    "published": "2024-02-05T11:55:30Z",
    "updated": "2024-02-05T11:55:30Z",
    "pdf_url": "https://arxiv.org/pdf/2402.02932v1",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2403.13310v2",
    "title": "A Semantic Search Engine for Mathlib4",
    "summary": "The interactive theorem prover Lean enables the verification of formal mathematical proofs and is backed by an expanding community. Central to this ecosystem is its mathematical library, mathlib4, which lays the groundwork for the formalization of an expanding range of mathematical theories. However, searching for theorems in mathlib4 can be challenging. To successfully search in mathlib4, users often need to be familiar with its naming conventions or documentation strings. Therefore, creating a semantic search engine that can be used easily by individuals with varying familiarity with mathlib4 is very important. In this paper, we present a semantic search engine (https://leansearch.net/) for mathlib4 that accepts informal queries and finds the relevant theorems. We also establish a benchmark for assessing the performance of various search engines for mathlib4.",
    "authors": [
      "Guoxiong Gao",
      "Haocheng Ju",
      "Jiedong Jiang",
      "Zihan Qin",
      "Bin Dong"
    ],
    "published": "2024-03-20T05:23:09Z",
    "updated": "2025-02-04T02:10:52Z",
    "pdf_url": "https://arxiv.org/pdf/2403.13310v2",
    "categories": [
      "cs.IR",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2412.06649v1",
    "title": "Semantic Search and Recommendation Algorithm",
    "summary": "This paper introduces a new semantic search algorithm that uses Word2Vec and Annoy Index to improve the efficiency of information retrieval from large datasets. The proposed approach addresses the limitations of traditional search methods by offering enhanced speed, accuracy, and scalability. Testing on datasets up to 100GB demonstrates the method's effectiveness in processing vast amounts of data while maintaining high precision and performance.",
    "authors": [
      "Aryan Duhan",
      "Aryan Singhal",
      "Shourya Sharma",
      "Neeraj",
      "Arti MK"
    ],
    "published": "2024-12-09T16:43:23Z",
    "updated": "2024-12-09T16:43:23Z",
    "pdf_url": "https://arxiv.org/pdf/2412.06649v1",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2506.01910v2",
    "title": "GLoSS: Generative Language Models with Semantic Search for Sequential Recommendation",
    "summary": "We propose Generative Low-rank language model with Semantic Search (GLoSS), a generative recommendation framework that combines large language models with dense retrieval for sequential recommendation. Unlike prior methods such as GPT4Rec, which rely on lexical matching via BM25, GLoSS uses semantic search to retrieve relevant items beyond lexical matching. For query generation, we employ 4-bit quantized LlaMA-3 models fine-tuned with low-rank adaptation (LoRA), enabling efficient training and inference on modest hardware. We evaluate GLoSS on three real-world Amazon review datasets: Beauty, Toys, and Sports, and find that it achieves state-of-the-art performance. Compared to traditional ID-based baselines, GLoSS improves Recall@5 by 33.3%, 52.8%, and 15.2%, and NDCG@5 by 30.0%, 42.6%, and 16.1%, respectively. It also outperforms LLM-based recommenders such as P5, GPT4Rec, LlamaRec and E4SRec with Recall@5 gains of 4.3%, 22.8%, and 29.5%. Additionally, user segment evaluations show that GLoSS performs particularly well for cold-start users in the Amazon Toys and Sports datasets, and benefits from longer user histories in Amazon Beauty dataset, demonstrating robustness across different levels of interaction lengths.",
    "authors": [
      "Krishna Acharya",
      "Aleksandr V. Petrov",
      "Juba Ziani"
    ],
    "published": "2025-06-02T17:31:42Z",
    "updated": "2025-06-09T23:45:38Z",
    "pdf_url": "https://arxiv.org/pdf/2506.01910v2",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2503.01003v1",
    "title": "A Semantic Search Pipeline for Causality-driven Adhoc Information Retrieval",
    "summary": "We present a unsupervised semantic search pipeline for the Causality-driven Adhoc Information Retrieval (CAIR-2021) shared task. The CAIR shared task expands traditional information retrieval to support the retrieval of documents containing the likely causes of a query event. A successful system must be able to distinguish between topical documents and documents containing causal descriptions of events that are causally related to the query event. Our approach involves aggregating results from multiple query strategies over a semantic and lexical index. The proposed approach leads the CAIR-2021 leaderboard and outperformed both traditional IR and pure semantic embedding-based approaches.",
    "authors": [
      "Dhairya Dalal",
      "Sharmi Dev Gupta",
      "Bentolhoda Binaei"
    ],
    "published": "2025-03-02T19:59:41Z",
    "updated": "2025-03-02T19:59:41Z",
    "pdf_url": "https://arxiv.org/pdf/2503.01003v1",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2404.07220v2",
    "title": "Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers",
    "summary": "Retrieval-Augmented Generation (RAG) is a prevalent approach to infuse a private knowledge base of documents with Large Language Models (LLM) to build Generative Q\\&A (Question-Answering) systems. However, RAG accuracy becomes increasingly challenging as the corpus of documents scales up, with Retrievers playing an outsized role in the overall RAG accuracy by extracting the most relevant document from the corpus to provide context to the LLM. In this paper, we propose the 'Blended RAG' method of leveraging semantic search techniques, such as Dense Vector indexes and Sparse Encoder indexes, blended with hybrid query strategies. Our study achieves better retrieval results and sets new benchmarks for IR (Information Retrieval) datasets like NQ and TREC-COVID datasets. We further extend such a 'Blended Retriever' to the RAG system to demonstrate far superior results on Generative Q\\&A datasets like SQUAD, even surpassing fine-tuning performance.",
    "authors": [
      "Kunal Sawarkar",
      "Abhilasha Mangal",
      "Shivam Raj Solanki"
    ],
    "published": "2024-03-22T17:13:46Z",
    "updated": "2024-08-04T15:32:37Z",
    "pdf_url": "https://arxiv.org/pdf/2404.07220v2",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2304.04057v1",
    "title": "How Does Imperfect Automatic Indexing Affect Semantic Search Performance?",
    "summary": "Documents in the health domain are often annotated with semantic concepts (i.e., terms) from controlled vocabularies. As the volume of these documents gets large, the annotation work is increasingly done by algorithms. Compared to humans, automatic indexing algorithms are imperfect and may assign wrong terms to documents, which affect subsequent search tasks where queries contain these terms. In this work, we aim to understand the performance impact of using imperfectly assigned terms in Boolean semantic searches. We used MeSH terms and biomedical literature search as a case study. We implemented multiple automatic indexing algorithms on real-world Boolean queries that consist of MeSH terms, and found that (1) probabilistic logic can handle inaccurately assigned terms better than traditional Boolean logic, (2) query-level performance is mostly limited by lowest-performing terms in a query, and (3) mixing a small amount of human indexing with automatic indexing can regain excellent query-level performance. These findings provide important implications for future work on automatic indexing.",
    "authors": [
      "Mengtian Guo",
      "David Gotz",
      "Yue Wang"
    ],
    "published": "2023-04-08T15:54:36Z",
    "updated": "2023-04-08T15:54:36Z",
    "pdf_url": "https://arxiv.org/pdf/2304.04057v1",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2511.18313v1",
    "title": "Path-Constrained Retrieval: A Structural Approach to Reliable LLM Agent Reasoning Through Graph-Scoped Semantic Search",
    "summary": "Large Language Model agents often retrieve context from knowledge bases that lack structural consistency with the agent's current reasoning state, leading to incoherent reasoning chains. We introduce Path-Constrained Retrieval (PCR), a retrieval method that combines structural graph constraints with semantic search to ensure retrieved information maintains logical relationships within a knowledge graph. PCR restricts the search space to nodes reachable from an anchor node, preventing retrieval of structurally disconnected information that may lead to inconsistent reasoning. We evaluate PCR on PathRAG-6, a benchmark spanning six domains with 180 nodes and 360 edges. Our results show that PCR achieves full structural consistency compared to 24-32 percent in baseline methods, while maintaining strong relevance scores. On the technology domain, PCR obtains full relevance at rank 10 with full structural consistency, significantly outperforming vector search and hybrid retrieval. PCR reduces the average graph distance of retrieved context by 78 percent compared to baselines, demonstrating retrieval of more structurally consistent information. These findings suggest that path-constrained retrieval is an effective approach for improving the reliability and coherence of LLM agent reasoning systems.",
    "authors": [
      "Joseph Oladokun"
    ],
    "published": "2025-11-23T06:50:01Z",
    "updated": "2025-11-23T06:50:01Z",
    "pdf_url": "https://arxiv.org/pdf/2511.18313v1",
    "categories": [
      "cs.CL",
      "cs.DB",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2503.14251v1",
    "title": "Towards a Barrier-free GeoQA Portal: Natural Language Interaction with Geospatial Data Using Multi-Agent LLMs and Semantic Search",
    "summary": "A Barrier-Free GeoQA Portal: Enhancing Geospatial Data Accessibility with a Multi-Agent LLM Framework Geoportals are vital for accessing and analyzing geospatial data, promoting open spatial data sharing and online geo-information management. Designed with GIS-like interaction and layered visualization, they often challenge non-expert users with complex functionalities and overlapping layers that obscure spatial relationships. We propose a GeoQA Portal using a multi-agent Large Language Model framework for seamless natural language interaction with geospatial data. Complex queries are broken into subtasks handled by specialized agents, retrieving relevant geographic data efficiently. Task plans are shown to users, boosting transparency. The portal supports default and custom data inputs for flexibility. Semantic search via word vector similarity aids data retrieval despite imperfect terms. Case studies, evaluations, and user tests confirm its effectiveness for non-experts, bridging GIS complexity and public access, and offering an intuitive solution for future geoportals.",
    "authors": [
      "Yu Feng",
      "Puzhen Zhang",
      "Guohui Xiao",
      "Linfang Ding",
      "Liqiu Meng"
    ],
    "published": "2025-03-18T13:39:46Z",
    "updated": "2025-03-18T13:39:46Z",
    "pdf_url": "https://arxiv.org/pdf/2503.14251v1",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2408.09236v3",
    "title": "Hybrid Semantic Search: Unveiling User Intent Beyond Keywords",
    "summary": "This paper addresses the limitations of traditional keyword-based search in understanding user intent and introduces a novel hybrid search approach that leverages the strengths of non-semantic search engines, Large Language Models (LLMs), and embedding models. The proposed system integrates keyword matching, semantic vector embeddings, and LLM-generated structured queries to deliver highly relevant and contextually appropriate search results. By combining these complementary methods, the hybrid approach effectively captures both explicit and implicit user intent.The paper further explores techniques to optimize query execution for faster response times and demonstrates the effectiveness of this hybrid search model in producing comprehensive and accurate search outcomes.",
    "authors": [
      "Aman Ahluwalia",
      "Bishwajit Sutradhar",
      "Karishma Ghosh",
      "Indrapal Yadav",
      "Arpan Sheetal",
      "Prashant Patil"
    ],
    "published": "2024-08-17T16:04:31Z",
    "updated": "2024-09-06T13:34:16Z",
    "pdf_url": "https://arxiv.org/pdf/2408.09236v3",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2410.21549v1",
    "title": "Semantic Search Evaluation",
    "summary": "We propose a novel method for evaluating the performance of a content search system that measures the semantic match between a query and the results returned by the search system. We introduce a metric called \"on-topic rate\" to measure the percentage of results that are relevant to the query. To achieve this, we design a pipeline that defines a golden query set, retrieves the top K results for each query, and sends calls to GPT 3.5 with formulated prompts. Our semantic evaluation pipeline helps identify common failure patterns and goals against the metric for relevance improvements.",
    "authors": [
      "Chujie Zheng",
      "Jeffrey Wang",
      "Shuqian Albee Zhang",
      "Anand Kishore",
      "Siddharth Singh"
    ],
    "published": "2024-10-28T21:25:38Z",
    "updated": "2024-10-28T21:25:38Z",
    "pdf_url": "https://arxiv.org/pdf/2410.21549v1",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2403.00807v1",
    "title": "Enhancing Cloud-Based Large Language Model Processing with Elasticsearch and Transformer Models",
    "summary": "Large Language Models (LLMs) are a class of generative AI models built using the Transformer network, capable of leveraging vast datasets to identify, summarize, translate, predict, and generate language. LLMs promise to revolutionize society, yet training these foundational models poses immense challenges. Semantic vector search within large language models is a potent technique that can significantly enhance search result accuracy and relevance. Unlike traditional keyword-based search methods, semantic search utilizes the meaning and context of words to grasp the intent behind queries and deliver more precise outcomes. Elasticsearch emerges as one of the most popular tools for implementing semantic search an exceptionally scalable and robust search engine designed for indexing and searching extensive datasets. In this article, we delve into the fundamentals of semantic search and explore how to harness Elasticsearch and Transformer models to bolster large language model processing paradigms. We gain a comprehensive understanding of semantic search principles and acquire practical skills for implementing semantic search in real-world model application scenarios.",
    "authors": [
      "Chunhe Ni",
      "Jiang Wu",
      "Hongbo Wang",
      "Wenran Lu",
      "Chenwei Zhang"
    ],
    "published": "2024-02-24T12:31:22Z",
    "updated": "2024-02-24T12:31:22Z",
    "pdf_url": "https://arxiv.org/pdf/2403.00807v1",
    "categories": [
      "cs.IR",
      "cs.CL",
      "cs.DC",
      "cs.DL"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2508.17694v1",
    "title": "Semantic Search for Information Retrieval",
    "summary": "Information retrieval systems have progressed notably from lexical techniques such as BM25 and TF-IDF to modern semantic retrievers. This survey provides a brief overview of the BM25 baseline, then discusses the architecture of modern state-of-the-art semantic retrievers. Advancing from BERT, we introduce dense bi-encoders (DPR), late-interaction models (ColBERT), and neural sparse retrieval (SPLADE). Finally, we examine MonoT5, a cross-encoder model. We conclude with common evaluation tactics, pressing challenges, and propositions for future directions.",
    "authors": [
      "Kayla Farivar"
    ],
    "published": "2025-08-25T06:03:26Z",
    "updated": "2025-08-25T06:03:26Z",
    "pdf_url": "https://arxiv.org/pdf/2508.17694v1",
    "categories": [
      "cs.IR"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2404.14415v1",
    "title": "Domain Adaptation in Intent Classification Systems: A Review",
    "summary": "Dialogue agents, which perform specific tasks, are part of the long-term goal of NLP researchers to build intelligent agents that communicate with humans in natural language. Such systems should adapt easily from one domain to another to assist users in completing tasks. Researchers have developed a broad range of techniques, objectives, and datasets for intent classification to achieve such systems. Despite the progress in developing intent classification systems (ICS), a systematic review of the progress from a technical perspective is yet to be conducted. In effect, important implementation details of intent classification remain restricted and unclear, making it hard for natural language processing (NLP) researchers to develop new methods. To fill this gap, we review contemporary works in intent classification. Specifically, we conduct a thorough technical review of the datasets, domains, tasks, and methods needed to train the intent classification part of dialogue systems. Our structured analysis describes why intent classification is difficult and studies the limitations to domain adaptation while presenting opportunities for future work.",
    "authors": [
      "Jesse Atuhurra",
      "Hidetaka Kamigaito",
      "Taro Watanabe",
      "Eric Nichols"
    ],
    "published": "2024-03-26T15:59:05Z",
    "updated": "2024-03-26T15:59:05Z",
    "pdf_url": "https://arxiv.org/pdf/2404.14415v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2506.00210v2",
    "title": "REIC: RAG-Enhanced Intent Classification at Scale",
    "summary": "Accurate intent classification is critical for efficient routing in customer service, ensuring customers are connected with the most suitable agents while reducing handling times and operational costs. However, as companies expand their product lines, intent classification faces scalability challenges due to the increasing number of intents and variations in taxonomy across different verticals. In this paper, we introduce REIC, a Retrieval-augmented generation Enhanced Intent Classification approach, which addresses these challenges effectively. REIC leverages retrieval-augmented generation (RAG) to dynamically incorporate relevant knowledge, enabling precise classification without the need for frequent retraining. Through extensive experiments on real-world datasets, we demonstrate that REIC outperforms traditional fine-tuning, zero-shot, and few-shot methods in large-scale customer service settings. Our results highlight its effectiveness in both in-domain and out-of-domain scenarios, demonstrating its potential for real-world deployment in adaptive and large-scale intent classification systems.",
    "authors": [
      "Ziji Zhang",
      "Michael Yang",
      "Zhiyu Chen",
      "Yingying Zhuang",
      "Shu-Ting Pi",
      "Qun Liu",
      "Rajashekar Maragoud",
      "Vy Nguyen",
      "Anurag Beniwal"
    ],
    "published": "2025-05-30T20:32:10Z",
    "updated": "2025-11-17T15:21:31Z",
    "pdf_url": "https://arxiv.org/pdf/2506.00210v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2407.17862v1",
    "title": "Exploring Description-Augmented Dataless Intent Classification",
    "summary": "In this work, we introduce several schemes to leverage description-augmented embedding similarity for dataless intent classification using current state-of-the-art (SOTA) text embedding models. We report results of our methods on four commonly used intent classification datasets and compare against previous works of a similar nature. Our work shows promising results for dataless classification scaling to a large number of unseen intents. We show competitive results and significant improvements (+6.12\\% Avg.) over strong zero-shot baselines, all without training on labelled or task-specific data. Furthermore, we provide qualitative error analysis of the shortfalls of this methodology to help guide future research in this area.",
    "authors": [
      "Ruoyu Hu",
      "Foaad Khosmood",
      "Abbas Edalat"
    ],
    "published": "2024-07-25T08:31:57Z",
    "updated": "2024-07-25T08:31:57Z",
    "pdf_url": "https://arxiv.org/pdf/2407.17862v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2502.01270v1",
    "title": "Main Predicate and Their Arguments as Explanation Signals For Intent Classification",
    "summary": "Intent classification is crucial for conversational agents (chatbots), and deep learning models perform well in this area. However, little research has been done on the explainability of intent classification due to the absence of suitable benchmark data. Human annotation of explanation signals in text samples is time-consuming and costly. However, from inspection of data on intent classification, we see that, more often than not, the main verb denotes the action, and the direct object indicates the domain of conversation, serving as explanation signals for intent. This observation enables us to hypothesize that the main predicate in the text utterances, along with the arguments of the main predicate, can serve as explanation signals. Leveraging this, we introduce a new technique to automatically augment text samples from intent classification datasets with word-level explanations. We mark main predicates (primarily verbs) and their arguments (dependency relations) as explanation signals in benchmark intent classification datasets ATIS and SNIPS, creating a unique 21k-instance dataset for explainability. Further, we experiment with deep learning and language models. We observe that models that work well for classification do not perform well in explainability metrics like plausibility and faithfulness. We also observe that guiding models to focus on explanation signals from our dataset during training improves the plausibility Token F1 score by 3-4%, improving the model's reasoning.",
    "authors": [
      "Sameer Pimparkhede",
      "Pushpak Bhattacharyya"
    ],
    "published": "2025-02-03T11:39:26Z",
    "updated": "2025-02-03T11:39:26Z",
    "pdf_url": "https://arxiv.org/pdf/2502.01270v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2411.06022v1",
    "title": "Improved intent classification based on context information using a windows-based approach",
    "summary": "Conversational systems have a Natural Language Understanding (NLU) module. In this module, there is a task known as an intent classification that aims at identifying what a user is attempting to achieve from an utterance. Previous works use only the current utterance to predict the intent of a given query and they do not consider the role of the context (one or a few previous utterances) in the dialog flow for this task. In this work, we propose several approaches to investigate the role of contextual information for the intent classification task. Each approach is used to carry out a concatenation between the dialogue history and the current utterance. Our intent classification method is based on a convolutional neural network that obtains effective vector representations from BERT to perform accurate intent classification using an approach window-based. Our experiments were carried out on a real-world Brazilian Portuguese corpus with dialog flows provided by Wavy global company. Our results achieved substantial improvements over the baseline, isolated utterances (without context), in three approaches using the user's utterance and system's response from previous messages as dialogue context.",
    "authors": [
      "Jeanfranco D. Farfan-Escobedo",
      "Julio C. Dos Reis"
    ],
    "published": "2024-11-09T00:56:02Z",
    "updated": "2024-11-09T00:56:02Z",
    "pdf_url": "https://arxiv.org/pdf/2411.06022v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2509.19271v3",
    "title": "WolBanking77: Wolof Banking Speech Intent Classification Dataset",
    "summary": "Intent classification models have made a significant progress in recent years. However, previous studies primarily focus on high-resource language datasets, which results in a gap for low-resource languages and for regions with high rates of illiteracy, where languages are more spoken than read or written. This is the case in Senegal, for example, where Wolof is spoken by around 90\\% of the population, while the national illiteracy rate remains at of 42\\%. Wolof is actually spoken by more than 10 million people in West African region. To address these limitations, we introduce the Wolof Banking Speech Intent Classification Dataset (WolBanking77), for academic research in intent classification. WolBanking77 currently contains 9,791 text sentences in the banking domain and more than 4 hours of spoken sentences. Experiments on various baselines are conducted in this work, including text and voice state-of-the-art models. The results are very promising on this current dataset. In addition, this paper presents an in-depth examination of the dataset's contents. We report baseline F1-scores and word error rates metrics respectively on NLP and ASR models trained on WolBanking77 dataset and also comparisons between models. Dataset and code available at: https://github.com/abdoukarim/wolbanking77.",
    "authors": [
      "Abdou Karim Kandji",
      "Frdric Precioso",
      "Cheikh Ba",
      "Samba Ndiaye",
      "Augustin Ndione"
    ],
    "published": "2025-09-23T17:34:10Z",
    "updated": "2025-10-24T19:18:37Z",
    "pdf_url": "https://arxiv.org/pdf/2509.19271v3",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2306.08502v1",
    "title": "ITALIC: An Italian Intent Classification Dataset",
    "summary": "Recent large-scale Spoken Language Understanding datasets focus predominantly on English and do not account for language-specific phenomena such as particular phonemes or words in different lects. We introduce ITALIC, the first large-scale speech dataset designed for intent classification in Italian. The dataset comprises 16,521 crowdsourced audio samples recorded by 70 speakers from various Italian regions and annotated with intent labels and additional metadata. We explore the versatility of ITALIC by evaluating current state-of-the-art speech and text models. Results on intent classification suggest that increasing scale and running language adaptation yield better speech models, monolingual text models outscore multilingual ones, and that speech recognition on ITALIC is more challenging than on existing Italian benchmarks. We release both the dataset and the annotation scheme to streamline the development of new Italian SLU models and language-specific datasets.",
    "authors": [
      "Alkis Koudounas",
      "Moreno La Quatra",
      "Lorenzo Vaiani",
      "Luca Colomba",
      "Giuseppe Attanasio",
      "Eliana Pastor",
      "Luca Cagliero",
      "Elena Baralis"
    ],
    "published": "2023-06-14T13:36:24Z",
    "updated": "2023-06-14T13:36:24Z",
    "pdf_url": "https://arxiv.org/pdf/2306.08502v1",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2312.10679v1",
    "title": "Bengali Intent Classification with Generative Adversarial BERT",
    "summary": "Intent classification is a fundamental task in natural language understanding, aiming to categorize user queries or sentences into predefined classes to understand user intent. The most challenging aspect of this particular task lies in effectively incorporating all possible classes of intent into a dataset while ensuring adequate linguistic variation. Plenty of research has been conducted in the related domains in rich-resource languages like English. In this study, we introduce BNIntent30, a comprehensive Bengali intent classification dataset containing 30 intent classes. The dataset is excerpted and translated from the CLINIC150 dataset containing a diverse range of user intents categorized over 150 classes. Furthermore, we propose a novel approach for Bengali intent classification using Generative Adversarial BERT to evaluate the proposed dataset, which we call GAN-BnBERT. Our approach leverages the power of BERT-based contextual embeddings to capture salient linguistic features and contextual information from the text data, while the generative adversarial network (GAN) component complements the model's ability to learn diverse representations of existing intent classes through generative modeling. Our experimental results demonstrate that the GAN-BnBERT model achieves superior performance on the newly introduced BNIntent30 dataset, surpassing the existing Bi-LSTM and the stand-alone BERT-based classification model.",
    "authors": [
      "Mehedi Hasan",
      "Mohammad Jahid Ibna Basher",
      "Md. Tanvir Rouf Shawon"
    ],
    "published": "2023-12-17T10:45:50Z",
    "updated": "2023-12-17T10:45:50Z",
    "pdf_url": "https://arxiv.org/pdf/2312.10679v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2305.07157v1",
    "title": "Exploring Zero and Few-shot Techniques for Intent Classification",
    "summary": "Conversational NLU providers often need to scale to thousands of intent-classification models where new customers often face the cold-start problem. Scaling to so many customers puts a constraint on storage space as well. In this paper, we explore four different zero and few-shot intent classification approaches with this low-resource constraint: 1) domain adaptation, 2) data augmentation, 3) zero-shot intent classification using descriptions large language models (LLMs), and 4) parameter-efficient fine-tuning of instruction-finetuned language models. Our results show that all these approaches are effective to different degrees in low-resource settings. Parameter-efficient fine-tuning using T-few recipe (Liu et al., 2022) on Flan-T5 (Chang et al., 2022) yields the best performance even with just one sample per intent. We also show that the zero-shot method of prompting LLMs using intent descriptions",
    "authors": [
      "Soham Parikh",
      "Quaizar Vohra",
      "Prashil Tumbade",
      "Mitul Tiwari"
    ],
    "published": "2023-05-11T22:07:27Z",
    "updated": "2023-05-11T22:07:27Z",
    "pdf_url": "https://arxiv.org/pdf/2305.07157v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2412.15603v1",
    "title": "Dynamic Label Name Refinement for Few-Shot Dialogue Intent Classification",
    "summary": "Dialogue intent classification aims to identify the underlying purpose or intent of a user's input in a conversation. Current intent classification systems encounter considerable challenges, primarily due to the vast number of possible intents and the significant semantic overlap among similar intent classes. In this paper, we propose a novel approach to few-shot dialogue intent classification through in-context learning, incorporating dynamic label refinement to address these challenges. Our method retrieves relevant examples for a test input from the training set and leverages a large language model to dynamically refine intent labels based on semantic understanding, ensuring that intents are clearly distinguishable from one another. Experimental results demonstrate that our approach effectively resolves confusion between semantically similar intents, resulting in significantly enhanced performance across multiple datasets compared to baselines. We also show that our method generates more interpretable intent labels, and has a better semantic coherence in capturing underlying user intents compared to baselines.",
    "authors": [
      "Gyutae Park",
      "Ingeol Baek",
      "ByeongJeong Kim",
      "Joongbo Shin",
      "Hwanhee Lee"
    ],
    "published": "2024-12-20T06:53:57Z",
    "updated": "2024-12-20T06:53:57Z",
    "pdf_url": "https://arxiv.org/pdf/2412.15603v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2412.13542v1",
    "title": "Multi-Granularity Open Intent Classification via Adaptive Granular-Ball Decision Boundary",
    "summary": "Open intent classification is critical for the development of dialogue systems, aiming to accurately classify known intents into their corresponding classes while identifying unknown intents. Prior boundary-based methods assumed known intents fit within compact spherical regions, focusing on coarse-grained representation and precise spherical decision boundaries. However, these assumptions are often violated in practical scenarios, making it difficult to distinguish known intent classes from unknowns using a single spherical boundary. To tackle these issues, we propose a Multi-granularity Open intent classification method via adaptive Granular-Ball decision boundary (MOGB). Our MOGB method consists of two modules: representation learning and decision boundary acquiring. To effectively represent the intent distribution, we design a hierarchical representation learning method. This involves iteratively alternating between adaptive granular-ball clustering and nearest sub-centroid classification to capture fine-grained semantic structures within known intent classes. Furthermore, multi-granularity decision boundaries are constructed for open intent classification by employing granular-balls with varying centroids and radii. Extensive experiments conducted on three public datasets demonstrate the effectiveness of our proposed method.",
    "authors": [
      "Yanhua Li",
      "Xiaocao Ouyang",
      "Chaofan Pan",
      "Jie Zhang",
      "Sen Zhao",
      "Shuyin Xia",
      "Xin Yang",
      "Guoyin Wang",
      "Tianrui Li"
    ],
    "published": "2024-12-18T06:42:19Z",
    "updated": "2024-12-18T06:42:19Z",
    "pdf_url": "https://arxiv.org/pdf/2412.13542v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2403.16504v3",
    "title": "LARA: Linguistic-Adaptive Retrieval-Augmentation for Multi-Turn Intent Classification",
    "summary": "Multi-turn intent classification is notably challenging due to the complexity and evolving nature of conversational contexts. This paper introduces LARA, a Linguistic-Adaptive Retrieval-Augmentation framework to enhance accuracy in multi-turn classification tasks across six languages, accommodating a large number of intents in chatbot interactions. LARA combines a fine-tuned smaller model with a retrieval-augmented mechanism, integrated within the architecture of LLMs. The integration allows LARA to dynamically utilize past dialogues and relevant intents, thereby improving the understanding of the context. Furthermore, our adaptive retrieval techniques bolster the cross-lingual capabilities of LLMs without extensive retraining and fine-tuning. Comprehensive experiments demonstrate that LARA achieves state-of-the-art performance on multi-turn intent classification tasks, enhancing the average accuracy by 3.67\\% from state-of-the-art single-turn intent classifiers.",
    "authors": [
      "Junhua Liu",
      "Yong Keat Tan",
      "Bin Fu",
      "Kwan Hui Lim"
    ],
    "published": "2024-03-25T07:38:40Z",
    "updated": "2024-10-14T03:26:10Z",
    "pdf_url": "https://arxiv.org/pdf/2403.16504v3",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2303.06585v1",
    "title": "Improving the Intent Classification accuracy in Noisy Environment",
    "summary": "Intent classification is a fundamental task in the spoken language understanding field that has recently gained the attention of the scientific community, mainly because of the feasibility of approaching it with end-to-end neural models. In this way, avoiding using intermediate steps, i.e. automatic speech recognition, is possible, thus the propagation of errors due to background noise, spontaneous speech, speaking styles of users, etc. Towards the development of solutions applicable in real scenarios, it is interesting to investigate how environmental noise and related noise reduction techniques to address the intent classification task with end-to-end neural models. In this paper, we experiment with a noisy version of the fluent speech command data set, combining the intent classifier with a time-domain speech enhancement solution based on Wave-U-Net and considering different training strategies. Experimental results reveal that, for this task, the use of speech enhancement greatly improves the classification accuracy in noisy conditions, in particular when the classification model is trained on enhanced signals.",
    "authors": [
      "Mohamed Nabih Ali",
      "Alessio Brutti",
      "Daniele Falavigna"
    ],
    "published": "2023-03-12T06:11:44Z",
    "updated": "2023-03-12T06:11:44Z",
    "pdf_url": "https://arxiv.org/pdf/2303.06585v1",
    "categories": [
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2403.18973v1",
    "title": "Conformal Intent Classification and Clarification for Fast and Accurate Intent Recognition",
    "summary": "We present Conformal Intent Classification and Clarification (CICC), a framework for fast and accurate intent classification for task-oriented dialogue systems. The framework turns heuristic uncertainty scores of any intent classifier into a clarification question that is guaranteed to contain the true intent at a pre-defined confidence level. By disambiguating between a small number of likely intents, the user query can be resolved quickly and accurately. Additionally, we propose to augment the framework for out-of-scope detection. In a comparative evaluation using seven intent recognition datasets we find that CICC generates small clarification questions and is capable of out-of-scope detection. CICC can help practitioners and researchers substantially in improving the user experience of dialogue agents with specific clarification questions.",
    "authors": [
      "Floris den Hengst",
      "Ralf Wolter",
      "Patrick Altmeyer",
      "Arda Kaygan"
    ],
    "published": "2024-03-27T19:42:01Z",
    "updated": "2024-03-27T19:42:01Z",
    "pdf_url": "https://arxiv.org/pdf/2403.18973v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2303.15870v1",
    "title": "A Multi-Granularity Matching Attention Network for Query Intent Classification in E-commerce Retrieval",
    "summary": "Query intent classification, which aims at assisting customers to find desired products, has become an essential component of the e-commerce search. Existing query intent classification models either design more exquisite models to enhance the representation learning of queries or explore label-graph and multi-task to facilitate models to learn external information. However, these models cannot capture multi-granularity matching features from queries and categories, which makes them hard to mitigate the gap in the expression between informal queries and categories. This paper proposes a Multi-granularity Matching Attention Network (MMAN), which contains three modules: a self-matching module, a char-level matching module, and a semantic-level matching module to comprehensively extract features from the query and a query-category interaction matrix. In this way, the model can eliminate the difference in expression between queries and categories for query intent classification. We conduct extensive offline and online A/B experiments, and the results show that the MMAN significantly outperforms the strong baselines, which shows the superiority and effectiveness of MMAN. MMAN has been deployed in production and brings great commercial value for our company.",
    "authors": [
      "Chunyuan Yuan",
      "Yiming Qiu",
      "Mingming Li",
      "Haiqing Hu",
      "Songlin Wang",
      "Sulong Xu"
    ],
    "published": "2023-03-28T10:25:17Z",
    "updated": "2023-03-28T10:25:17Z",
    "pdf_url": "https://arxiv.org/pdf/2303.15870v1",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2303.09306v2",
    "title": "BanglaCoNER: Towards Robust Bangla Complex Named Entity Recognition",
    "summary": "Named Entity Recognition (NER) is a fundamental task in natural language processing that involves identifying and classifying named entities in text. But much work hasn't been done for complex named entity recognition in Bangla, despite being the seventh most spoken language globally. CNER is a more challenging task than traditional NER as it involves identifying and classifying complex and compound entities, which are not common in Bangla language. In this paper, we present the winning solution of Bangla Complex Named Entity Recognition Challenge - addressing the CNER task on BanglaCoNER dataset using two different approaches, namely Conditional Random Fields (CRF) and finetuning transformer based Deep Learning models such as BanglaBERT. The dataset consisted of 15300 sentences for training and 800 sentences for validation, in the .conll format. Exploratory Data Analysis (EDA) on the dataset revealed that the dataset had 7 different NER tags, with notable presence of English words, suggesting that the dataset is synthetic and likely a product of translation. We experimented with a variety of feature combinations including Part of Speech (POS) tags, word suffixes, Gazetteers, and cluster information from embeddings, while also finetuning the BanglaBERT (large) model for NER. We found that not all linguistic patterns are immediately apparent or even intuitive to humans, which is why Deep Learning based models has proved to be the more effective model in NLP, including CNER task. Our fine tuned BanglaBERT (large) model achieves an F1 Score of 0.79 on the validation set. Overall, our study highlights the importance of Bangla Complex Named Entity Recognition, particularly in the context of synthetic datasets. Our findings also demonstrate the efficacy of Deep Learning models such as BanglaBERT for NER in Bangla language.",
    "authors": [
      "HAZ Sameen Shahgir",
      "Ramisa Alam",
      "Md. Zarif Ul Alam"
    ],
    "published": "2023-03-16T13:31:31Z",
    "updated": "2023-03-17T15:13:01Z",
    "pdf_url": "https://arxiv.org/pdf/2303.09306v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2412.16976v3",
    "title": "On Fusing ChatGPT and Ensemble Learning in Discon-tinuous Named Entity Recognition in Health Corpora",
    "summary": "Named Entity Recognition has traditionally been a key task in natural language processing, aiming to identify and extract important terms from unstructured text data. However, a notable challenge for contemporary deep-learning NER models has been identifying discontinuous entities, which are often fragmented within the text. To date, methods to address Discontinuous Named Entity Recognition have not been explored using ensemble learning to the best of our knowledge. Furthermore, the rise of large language models, such as ChatGPT in recent years, has shown significant effectiveness across many NLP tasks. Most existing approaches, however, have primarily utilized ChatGPT as a problem-solving tool rather than exploring its potential as an integrative element within ensemble learning algorithms. In this study, we investigated the integration of ChatGPT as an arbitrator within an ensemble method, aiming to enhance performance on DNER tasks. Our method combines five state-of-the-art NER models with ChatGPT using custom prompt engineering to assess the robustness and generalization capabilities of the ensemble algorithm. We conducted experiments on three benchmark medical datasets, comparing our method against the five SOTA models, individual applications of GPT-3.5 and GPT-4, and a voting ensemble method. The results indicate that our proposed fusion of ChatGPT with the ensemble learning algorithm outperforms the SOTA results in the CADEC, ShARe13, and ShARe14 datasets, showcasing its potential to enhance NLP applications in the healthcare domain.",
    "authors": [
      "Tzu-Chieh Chen",
      "Wen-Yang Lin"
    ],
    "published": "2024-12-22T11:26:49Z",
    "updated": "2025-08-17T11:31:23Z",
    "pdf_url": "https://arxiv.org/pdf/2412.16976v3",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2302.10314v1",
    "title": "Dynamic Named Entity Recognition",
    "summary": "Named Entity Recognition (NER) is a challenging and widely studied task that involves detecting and typing entities in text. So far,NER still approaches entity typing as a task of classification into universal classes (e.g. date, person, or location). Recent advances innatural language processing focus on architectures of increasing complexity that may lead to overfitting and memorization, and thus, underuse of context. Our work targets situations where the type of entities depends on the context and cannot be solved solely by memorization. We hence introduce a new task: Dynamic Named Entity Recognition (DNER), providing a framework to better evaluate the ability of algorithms to extract entities by exploiting the context. The DNER benchmark is based on two datasets, DNER-RotoWire and DNER-IMDb. We evaluate baseline models and present experiments reflecting issues and research axes related to this novel task.",
    "authors": [
      "Tristan Luiggi",
      "Laure Soulier",
      "Vincent Guigue",
      "Siwar Jendoubi",
      "Aurlien Baelde"
    ],
    "published": "2023-02-16T15:50:02Z",
    "updated": "2023-02-16T15:50:02Z",
    "pdf_url": "https://arxiv.org/pdf/2302.10314v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2410.13118v1",
    "title": "Retrieval-Enhanced Named Entity Recognition",
    "summary": "When combined with In-Context Learning, a technique that enables models to adapt to new tasks by incorporating task-specific examples or demonstrations directly within the input prompt, autoregressive language models have achieved good performance in a wide range of tasks and applications. However, this combination has not been properly explored in the context of named entity recognition, where the structure of this task poses unique challenges. We propose RENER (Retrieval-Enhanced Named Entity Recognition), a technique for named entity recognition using autoregressive language models based on In-Context Learning and information retrieval techniques. When presented with an input text, RENER fetches similar examples from a dataset of training examples that are used to enhance a language model to recognize named entities from this input text. RENER is modular and independent of the underlying language model and information retrieval algorithms. Experimental results show that in the CrossNER collection we achieve state-of-the-art performance with the proposed technique and that information retrieval can increase the F-score by up to 11 percentage points.",
    "authors": [
      "Enzo Shiraishi",
      "Raphael Y. de Camargo",
      "Henrique L. P. Silva",
      "Ronaldo C. Prati"
    ],
    "published": "2024-10-17T01:12:48Z",
    "updated": "2024-10-17T01:12:48Z",
    "pdf_url": "https://arxiv.org/pdf/2410.13118v1",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2306.13062v1",
    "title": "Named entity recognition in resumes",
    "summary": "Named entity recognition (NER) is used to extract information from various documents and texts such as names and dates. It is important to extract education and work experience information from resumes in order to filter them. Considering the fact that all information in a resume has to be entered to the companys system manually, automatizing this process will save time of the companies. In this study, a deep learning-based semi-automatic named entity recognition system has been implemented with a focus on resumes in the field of IT. Firstly, resumes of employees from five different IT related fields has been annotated. Six transformer based pre-trained models have been adapted to named entity recognition problem using the annotated data. These models have been selected among popular models in the natural language processing field. The obtained system can recognize eight different entity types which are city, date, degree, diploma major, job title, language, country and skill. Models used in the experiments are compared using micro, macro and weighted F1 scores and the performance of the methods was evaluated. Taking these scores into account for test set the best micro and weighted F1 score is obtained by RoBERTa and the best macro F1 score is obtained by Electra model.",
    "authors": [
      "Ege Kesim",
      "Aysu Deliahmetoglu"
    ],
    "published": "2023-06-22T17:30:37Z",
    "updated": "2023-06-22T17:30:37Z",
    "pdf_url": "https://arxiv.org/pdf/2306.13062v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2308.07791v1",
    "title": "Informed Named Entity Recognition Decoding for Generative Language Models",
    "summary": "Ever-larger language models with ever-increasing capabilities are by now well-established text processing tools. Alas, information extraction tasks such as named entity recognition are still largely unaffected by this progress as they are primarily based on the previous generation of encoder-only transformer models. Here, we propose a simple yet effective approach, Informed Named Entity Recognition Decoding (iNERD), which treats named entity recognition as a generative process. It leverages the language understanding capabilities of recent generative models in a future-proof manner and employs an informed decoding scheme incorporating the restricted nature of information extraction into open-ended text generation, improving performance and eliminating any risk of hallucinations. We coarse-tune our model on a merged named entity corpus to strengthen its performance, evaluate five generative language models on eight named entity recognition datasets, and achieve remarkable results, especially in an environment with an unknown entity class set, demonstrating the adaptability of the approach.",
    "authors": [
      "Tobias Deuer",
      "Lars Hillebrand",
      "Christian Bauckhage",
      "Rafet Sifa"
    ],
    "published": "2023-08-15T14:16:29Z",
    "updated": "2023-08-15T14:16:29Z",
    "pdf_url": "https://arxiv.org/pdf/2308.07791v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2510.04001v1",
    "title": "Named Entity Recognition in COVID-19 tweets with Entity Knowledge Augmentation",
    "summary": "The COVID-19 pandemic causes severe social and economic disruption around the world, raising various subjects that are discussed over social media. Identifying pandemic-related named entities as expressed on social media is fundamental and important to understand the discussions about the pandemic. However, there is limited work on named entity recognition on this topic due to the following challenges: 1) COVID-19 texts in social media are informal and their annotations are rare and insufficient to train a robust recognition model, and 2) named entity recognition in COVID-19 requires extensive domain-specific knowledge. To address these issues, we propose a novel entity knowledge augmentation approach for COVID-19, which can also be applied in general biomedical named entity recognition in both informal text format and formal text format. Experiments carried out on the COVID-19 tweets dataset and PubMed dataset show that our proposed entity knowledge augmentation improves NER performance in both fully-supervised and few-shot settings. Our source code is publicly available: https://github.com/kkkenshi/LLM-EKA/tree/master",
    "authors": [
      "Xuankang Zhang",
      "Jiangming Liu"
    ],
    "published": "2025-10-05T02:22:26Z",
    "updated": "2025-10-05T02:22:26Z",
    "pdf_url": "https://arxiv.org/pdf/2510.04001v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2401.17206v1",
    "title": "Gazetteer-Enhanced Bangla Named Entity Recognition with BanglaBERT Semantic Embeddings K-Means-Infused CRF Model",
    "summary": "Named Entity Recognition (NER) is a sub-task of Natural Language Processing (NLP) that distinguishes entities from unorganized text into predefined categorization. In recent years, a lot of Bangla NLP subtasks have received quite a lot of attention; but Named Entity Recognition in Bangla still lags behind. In this research, we explored the existing state of research in Bangla Named Entity Recognition. We tried to figure out the limitations that current techniques and datasets face, and we would like to address these limitations in our research. Additionally, We developed a Gazetteer that has the ability to significantly boost the performance of NER. We also proposed a new NER solution by taking advantage of state-of-the-art NLP tools that outperform conventional techniques.",
    "authors": [
      "Niloy Farhan",
      "Saman Sarker Joy",
      "Tafseer Binte Mannan",
      "Farig Sadeque"
    ],
    "published": "2024-01-30T17:47:07Z",
    "updated": "2024-01-30T17:47:07Z",
    "pdf_url": "https://arxiv.org/pdf/2401.17206v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2307.10291v2",
    "title": "Mutual Reinforcement Effects in Japanese Sentence Classification and Named Entity Recognition Tasks",
    "summary": "Information extraction(IE) is a crucial subfield within natural language processing. However, for the traditionally segmented approach to sentence classification and Named Entity Recognition, the intricate interactions between these individual subtasks remain largely uninvestigated. In this study, we propose an integrative analysis, converging sentence classification with Named Entity Recognition, with the objective to unveil and comprehend the mutual reinforcement effect within these two information extraction subtasks. To achieve this, we introduce a Sentence Classification and Named Entity Recognition Multi-task (SCNM) approach that combines Sentence Classification (SC) and Named Entity Recognition (NER). We develop a Sentence-to-Label Generation (SLG) framework for SCNM and construct a Wikipedia dataset containing both SC and NER. Using a format converter, we unify input formats and employ a generative model to generate SC-labels, NER-labels, and associated text segments. We propose a Constraint Mechanism (CM) to improve generated format accuracy. Our results show SC accuracy increased by 1.13 points and NER by 1.06 points in SCNM compared to standalone tasks, with CM raising format accuracy from 63.61 to 100. The findings indicate mutual reinforcement effects between SC and NER, and integration enhances both tasks' performance. We additionally implemented the SLG framework on single SC task. It yielded superior accuracies compared to the baseline on two distinct Japanese SC datasets. Notably, in the experiment of few-shot learning, SLG framework shows much better performance than fine-tune method. These empirical findings contribute additional evidence to affirm the efficacy of the SLG framework.",
    "authors": [
      "Chengguang Gan",
      "Qinghao Zhang",
      "Tatsunori Mori"
    ],
    "published": "2023-07-18T14:30:36Z",
    "updated": "2023-07-21T02:34:58Z",
    "pdf_url": "https://arxiv.org/pdf/2307.10291v2",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2310.19055v2",
    "title": "A Few-Shot Learning Focused Survey on Recent Named Entity Recognition and Relation Classification Methods",
    "summary": "Named Entity Recognition (NER) and Relation Classification (RC) are important steps in extracting information from unstructured text and formatting it into a machine-readable format. We present a survey of recent deep learning models that address named entity recognition and relation classification, with focus on few-shot learning performance. Our survey is helpful for researchers in knowing the recent techniques in text mining and extracting structured information from raw text.",
    "authors": [
      "Sakher Khalil Alqaaidi",
      "Elika Bozorgi",
      "Afsaneh Shams",
      "Krzysztof Kochut"
    ],
    "published": "2023-10-29T16:02:46Z",
    "updated": "2024-03-26T22:59:36Z",
    "pdf_url": "https://arxiv.org/pdf/2310.19055v2",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2503.20836v1",
    "title": "Named Entity Recognition in Context",
    "summary": "We present the Named Entity Recognition system developed by the Edit Dunhuang team for the EvaHan2025 competition. Our approach integrates three core components: (1) Pindola, a modern transformer-based bidirectional encoder pretrained on a large corpus of Classical Chinese texts; (2) a retrieval module that fetches relevant external context for each target sequence; and (3) a generative reasoning step that summarizes retrieved context in Classical Chinese for more robust entity disambiguation. Using this approach, we achieve an average F1 score of 85.58, improving upon the competition baseline by nearly 5 points.",
    "authors": [
      "Colin Brisson",
      "Ayoub Kahfy",
      "Marc Bui",
      "Frdric Constant"
    ],
    "published": "2025-03-26T08:37:19Z",
    "updated": "2025-03-26T08:37:19Z",
    "pdf_url": "https://arxiv.org/pdf/2503.20836v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2310.11769v1",
    "title": "Annotated Job Ads with Named Entity Recognition",
    "summary": "We have trained a named entity recognition (NER) model that screens Swedish job ads for different kinds of useful information (e.g. skills required from a job seeker). It was obtained by fine-tuning KB-BERT. The biggest challenge we faced was the creation of a labelled dataset, which required manual annotation. This paper gives an overview of the methods we employed to make the annotation process more efficient and to ensure high quality data. We also report on the performance of the resulting model.",
    "authors": [
      "Felix Stollenwerk",
      "Niklas Fastlund",
      "Anna Nyqvist",
      "Joey hman"
    ],
    "published": "2023-10-18T07:55:53Z",
    "updated": "2023-10-18T07:55:53Z",
    "pdf_url": "https://arxiv.org/pdf/2310.11769v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2306.08315v1",
    "title": "Research on Named Entity Recognition in Improved transformer with R-Drop structure",
    "summary": "To enhance the generalization ability of the model and improve the effectiveness of the transformer for named entity recognition tasks, the XLNet-Transformer-R model is proposed in this paper. The XLNet pre-trained model and the Transformer encoder with relative positional encodings are combined to enhance the model's ability to process long text and learn contextual information to improve robustness. To prevent overfitting, the R-Drop structure is used to improve the generalization capability and enhance the accuracy of the model in named entity recognition tasks. The model in this paper performs ablation experiments on the MSRA dataset and comparison experiments with other models on four datasets with excellent performance, demonstrating the strategic effectiveness of the XLNet-Transformer-R model.",
    "authors": [
      "Weidong Ji",
      "Yousheng Zhang",
      "Guohui Zhou",
      "Xu Wang"
    ],
    "published": "2023-06-14T07:34:27Z",
    "updated": "2023-06-14T07:34:27Z",
    "pdf_url": "https://arxiv.org/pdf/2306.08315v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2303.12795v1",
    "title": "Named Entity Recognition Based Automatic Generation of Research Highlights",
    "summary": "A scientific paper is traditionally prefaced by an abstract that summarizes the paper. Recently, research highlights that focus on the main findings of the paper have emerged as a complementary summary in addition to an abstract. However, highlights are not yet as common as abstracts, and are absent in many papers. In this paper, we aim to automatically generate research highlights using different sections of a research paper as input. We investigate whether the use of named entity recognition on the input improves the quality of the generated highlights. In particular, we have used two deep learning-based models: the first is a pointer-generator network, and the second augments the first model with coverage mechanism. We then augment each of the above models with named entity recognition features. The proposed method can be used to produce highlights for papers with missing highlights. Our experiments show that adding named entity information improves the performance of the deep learning-based summarizers in terms of ROUGE, METEOR and BERTScore measures.",
    "authors": [
      "Tohida Rehman",
      "Debarshi Kumar Sanyal",
      "Prasenjit Majumder",
      "Samiran Chattopadhyay"
    ],
    "published": "2023-02-25T16:33:03Z",
    "updated": "2023-02-25T16:33:03Z",
    "pdf_url": "https://arxiv.org/pdf/2303.12795v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2510.11444v1",
    "title": "GenCNER: A Generative Framework for Continual Named Entity Recognition",
    "summary": "Traditional named entity recognition (NER) aims to identify text mentions into pre-defined entity types. Continual Named Entity Recognition (CNER) is introduced since entity categories are continuously increasing in various real-world scenarios. However, existing continual learning (CL) methods for NER face challenges of catastrophic forgetting and semantic shift of non-entity type. In this paper, we propose GenCNER, a simple but effective Generative framework for CNER to mitigate the above drawbacks. Specifically, we skillfully convert the CNER task into sustained entity triplet sequence generation problem and utilize a powerful pre-trained seq2seq model to solve it. Additionally, we design a type-specific confidence-based pseudo labeling strategy along with knowledge distillation (KD) to preserve learned knowledge and alleviate the impact of label noise at the triplet level. Experimental results on two benchmark datasets show that our framework outperforms previous state-of-the-art methods in multiple CNER settings, and achieves the smallest gap compared with non-CL results.",
    "authors": [
      "Yawen Yang",
      "Fukun Ma",
      "Shiao Meng",
      "Aiwei Liu",
      "Lijie Wen"
    ],
    "published": "2025-10-13T14:15:31Z",
    "updated": "2025-10-13T14:15:31Z",
    "pdf_url": "https://arxiv.org/pdf/2510.11444v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2411.18583v1",
    "title": "Automated Literature Review Using NLP Techniques and LLM-Based Retrieval-Augmented Generation",
    "summary": "This research presents and compares multiple approaches to automate the generation of literature reviews using several Natural Language Processing (NLP) techniques and retrieval-augmented generation (RAG) with a Large Language Model (LLM). The ever-increasing number of research articles provides a huge challenge for manual literature review. It has resulted in an increased demand for automation. Developing a system capable of automatically generating the literature reviews from only the PDF files as input is the primary objective of this research work. The effectiveness of several Natural Language Processing (NLP) strategies, such as the frequency-based method (spaCy), the transformer model (Simple T5), and retrieval-augmented generation (RAG) with Large Language Model (GPT-3.5-turbo), is evaluated to meet the primary objective. The SciTLDR dataset is chosen for this research experiment and three distinct techniques are utilized to implement three different systems for auto-generating the literature reviews. The ROUGE scores are used for the evaluation of all three systems. Based on the evaluation, the Large Language Model GPT-3.5-turbo achieved the highest ROUGE-1 score, 0.364. The transformer model comes in second place and spaCy is at the last position. Finally, a graphical user interface is created for the best system based on the large language model.",
    "authors": [
      "Nurshat Fateh Ali",
      "Md. Mahdi Mohtasim",
      "Shakil Mosharrof",
      "T. Gopi Krishna"
    ],
    "published": "2024-11-27T18:27:07Z",
    "updated": "2024-11-27T18:27:07Z",
    "pdf_url": "https://arxiv.org/pdf/2411.18583v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2502.00306v2",
    "title": "Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented Generation",
    "summary": "Retrieval-Augmented Generation (RAG) enables Large Language Models (LLMs) to generate grounded responses by leveraging external knowledge databases without altering model parameters. Although the absence of weight tuning prevents leakage via model parameters, it introduces the risk of inference adversaries exploiting retrieved documents in the model's context. Existing methods for membership inference and data extraction often rely on jailbreaking or carefully crafted unnatural queries, which can be easily detected or thwarted with query rewriting techniques common in RAG systems. In this work, we present Interrogation Attack (IA), a membership inference technique targeting documents in the RAG datastore. By crafting natural-text queries that are answerable only with the target document's presence, our approach demonstrates successful inference with just 30 queries while remaining stealthy; straightforward detectors identify adversarial prompts from existing methods up to ~76x more frequently than those generated by our attack. We observe a 2x improvement in TPR@1%FPR over prior inference attacks across diverse RAG configurations, all while costing less than $0.02 per document inference.",
    "authors": [
      "Ali Naseh",
      "Yuefeng Peng",
      "Anshuman Suri",
      "Harsh Chaudhari",
      "Alina Oprea",
      "Amir Houmansadr"
    ],
    "published": "2025-02-01T04:01:18Z",
    "updated": "2025-06-30T16:37:59Z",
    "pdf_url": "https://arxiv.org/pdf/2502.00306v2",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2510.22344v1",
    "title": "FAIR-RAG: Faithful Adaptive Iterative Refinement for Retrieval-Augmented Generation",
    "summary": "While Retrieval-Augmented Generation (RAG) mitigates hallucination and knowledge staleness in Large Language Models (LLMs), existing frameworks often falter on complex, multi-hop queries that require synthesizing information from disparate sources. Current advanced RAG methods, employing iterative or adaptive strategies, lack a robust mechanism to systematically identify and fill evidence gaps, often propagating noise or failing to gather a comprehensive context. We introduce FAIR-RAG, a novel agentic framework that transforms the standard RAG pipeline into a dynamic, evidence-driven reasoning process. At its core is an Iterative Refinement Cycle governed by a module we term Structured Evidence Assessment (SEA). The SEA acts as an analytical gating mechanism: it deconstructs the initial query into a checklist of required findings and audits the aggregated evidence to identify confirmed facts and, critically, explicit informational gaps. These gaps provide a precise signal to an Adaptive Query Refinement agent, which generates new, targeted sub-queries to retrieve missing information. This cycle repeats until the evidence is verified as sufficient, ensuring a comprehensive context for a final, strictly faithful generation. We conducted experiments on challenging multi-hop QA benchmarks, including HotpotQA, 2WikiMultiHopQA, and MusiQue. In a unified experimental setup, FAIR-RAG significantly outperforms strong baselines. On HotpotQA, it achieves an F1-score of 0.453 -- an absolute improvement of 8.3 points over the strongest iterative baseline -- establishing a new state-of-the-art for this class of methods on these benchmarks. Our work demonstrates that a structured, evidence-driven refinement process with explicit gap analysis is crucial for unlocking reliable and accurate reasoning in advanced RAG systems for complex, knowledge-intensive tasks.",
    "authors": [
      "Mohammad Aghajani Asl",
      "Majid Asgari-Bidhendi",
      "Behrooz Minaei-Bidgoli"
    ],
    "published": "2025-10-25T15:59:33Z",
    "updated": "2025-10-25T15:59:33Z",
    "pdf_url": "https://arxiv.org/pdf/2510.22344v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2503.16581v1",
    "title": "Investigating Retrieval-Augmented Generation in Quranic Studies: A Study of 13 Open-Source Large Language Models",
    "summary": "Accurate and contextually faithful responses are critical when applying large language models (LLMs) to sensitive and domain-specific tasks, such as answering queries related to quranic studies. General-purpose LLMs often struggle with hallucinations, where generated responses deviate from authoritative sources, raising concerns about their reliability in religious contexts. This challenge highlights the need for systems that can integrate domain-specific knowledge while maintaining response accuracy, relevance, and faithfulness. In this study, we investigate 13 open-source LLMs categorized into large (e.g., Llama3:70b, Gemma2:27b, QwQ:32b), medium (e.g., Gemma2:9b, Llama3:8b), and small (e.g., Llama3.2:3b, Phi3:3.8b). A Retrieval-Augmented Generation (RAG) is used to make up for the problems that come with using separate models. This research utilizes a descriptive dataset of Quranic surahs including the meanings, historical context, and qualities of the 114 surahs, allowing the model to gather relevant knowledge before responding. The models are evaluated using three key metrics set by human evaluators: context relevance, answer faithfulness, and answer relevance. The findings reveal that large models consistently outperform smaller models in capturing query semantics and producing accurate, contextually grounded responses. The Llama3.2:3b model, even though it is considered small, does very well on faithfulness (4.619) and relevance (4.857), showing the promise of smaller architectures that have been well optimized. This article examines the trade-offs between model size, computational efficiency, and response quality while using LLMs in domain-specific applications.",
    "authors": [
      "Zahra Khalila",
      "Arbi Haza Nasution",
      "Winda Monika",
      "Aytug Onan",
      "Yohei Murakami",
      "Yasir Bin Ismail Radi",
      "Noor Mohammad Osmani"
    ],
    "published": "2025-03-20T13:26:30Z",
    "updated": "2025-03-20T13:26:30Z",
    "pdf_url": "https://arxiv.org/pdf/2503.16581v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2502.01113v3",
    "title": "GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation",
    "summary": "Retrieval-augmented generation (RAG) has proven effective in integrating knowledge into large language models (LLMs). However, conventional RAGs struggle to capture complex relationships between pieces of knowledge, limiting their performance in intricate reasoning that requires integrating knowledge from multiple sources. Recently, graph-enhanced retrieval augmented generation (GraphRAG) builds graph structure to explicitly model these relationships, enabling more effective and efficient retrievers. Nevertheless, its performance is still hindered by the noise and incompleteness within the graph structure. To address this, we introduce GFM-RAG, a novel graph foundation model (GFM) for retrieval augmented generation. GFM-RAG is powered by an innovative graph neural network that reasons over graph structure to capture complex query-knowledge relationships. The GFM with 8M parameters undergoes a two-stage training process on large-scale datasets, comprising 60 knowledge graphs with over 14M triples and 700k documents. This results in impressive performance and generalizability for GFM-RAG, making it the first graph foundation model applicable to unseen datasets for retrieval without any fine-tuning required. Extensive experiments on three multi-hop QA datasets and seven domain-specific RAG datasets demonstrate that GFM-RAG achieves state-of-the-art performance while maintaining efficiency and alignment with neural scaling laws, highlighting its potential for further improvement.",
    "authors": [
      "Linhao Luo",
      "Zicheng Zhao",
      "Gholamreza Haffari",
      "Dinh Phung",
      "Chen Gong",
      "Shirui Pan"
    ],
    "published": "2025-02-03T07:04:29Z",
    "updated": "2025-12-11T03:45:04Z",
    "pdf_url": "https://arxiv.org/pdf/2502.01113v3",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2406.13249v2",
    "title": "R^2AG: Incorporating Retrieval Information into Retrieval Augmented Generation",
    "summary": "Retrieval augmented generation (RAG) has been applied in many scenarios to augment large language models (LLMs) with external documents provided by retrievers. However, a semantic gap exists between LLMs and retrievers due to differences in their training objectives and architectures. This misalignment forces LLMs to passively accept the documents provided by the retrievers, leading to incomprehension in the generation process, where the LLMs are burdened with the task of distinguishing these documents using their inherent knowledge. This paper proposes R$^2$AG, a novel enhanced RAG framework to fill this gap by incorporating Retrieval information into Retrieval Augmented Generation. Specifically, R$^2$AG utilizes the nuanced features from the retrievers and employs a R$^2$-Former to capture retrieval information. Then, a retrieval-aware prompting strategy is designed to integrate retrieval information into LLMs' generation. Notably, R$^2$AG suits low-source scenarios where LLMs and retrievers are frozen. Extensive experiments across five datasets validate the effectiveness, robustness, and efficiency of R$^2$AG. Our analysis reveals that retrieval information serves as an anchor to aid LLMs in the generation process, thereby filling the semantic gap.",
    "authors": [
      "Fuda Ye",
      "Shuangyin Li",
      "Yongqi Zhang",
      "Lei Chen"
    ],
    "published": "2024-06-19T06:19:48Z",
    "updated": "2024-10-30T06:41:45Z",
    "pdf_url": "https://arxiv.org/pdf/2406.13249v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2305.06983v2",
    "title": "Active Retrieval Augmented Generation",
    "summary": "Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.",
    "authors": [
      "Zhengbao Jiang",
      "Frank F. Xu",
      "Luyu Gao",
      "Zhiqing Sun",
      "Qian Liu",
      "Jane Dwivedi-Yu",
      "Yiming Yang",
      "Jamie Callan",
      "Graham Neubig"
    ],
    "published": "2023-05-11T17:13:40Z",
    "updated": "2023-10-22T00:11:13Z",
    "pdf_url": "https://arxiv.org/pdf/2305.06983v2",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2409.13707v1",
    "title": "Retrieval Augmented Generation-Based Incident Resolution Recommendation System for IT Support",
    "summary": "Clients wishing to implement generative AI in the domain of IT Support and AIOps face two critical issues: domain coverage and model size constraints due to model choice limitations. Clients might choose to not use larger proprietary models such as GPT-4 due to cost and privacy concerns and so are limited to smaller models with potentially less domain coverage that do not generalize to the client's domain. Retrieval augmented generation is a common solution that addresses both of these issues: a retrieval system first retrieves the necessary domain knowledge which a smaller generative model leverages as context for generation. We present a system developed for a client in the IT Support domain for support case solution recommendation that combines retrieval augmented generation (RAG) for answer generation with an encoder-only model for classification and a generative large language model for query generation. We cover architecture details, data collection and annotation, development journey and preliminary validations, expected final deployment process and evaluation plans, and finally lessons learned.",
    "authors": [
      "Paulina Toro Isaza",
      "Michael Nidd",
      "Noah Zheutlin",
      "Jae-wook Ahn",
      "Chidansh Amitkumar Bhatt",
      "Yu Deng",
      "Ruchi Mahindru",
      "Martin Franz",
      "Hans Florian",
      "Salim Roukos"
    ],
    "published": "2024-09-06T13:06:29Z",
    "updated": "2024-09-06T13:06:29Z",
    "pdf_url": "https://arxiv.org/pdf/2409.13707v1",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2312.07796v1",
    "title": "Harnessing Retrieval-Augmented Generation (RAG) for Uncovering Knowledge Gaps",
    "summary": "The paper presents a methodology for uncovering knowledge gaps on the internet using the Retrieval Augmented Generation (RAG) model. By simulating user search behaviour, the RAG system identifies and addresses gaps in information retrieval systems. The study demonstrates the effectiveness of the RAG system in generating relevant suggestions with a consistent accuracy of 93%. The methodology can be applied in various fields such as scientific discovery, educational enhancement, research development, market analysis, search engine optimisation, and content development. The results highlight the value of identifying and understanding knowledge gaps to guide future endeavours.",
    "authors": [
      "Joan Figuerola Hurtado"
    ],
    "published": "2023-12-12T23:22:57Z",
    "updated": "2023-12-12T23:22:57Z",
    "pdf_url": "https://arxiv.org/pdf/2312.07796v1",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2501.15915v1",
    "title": "Parametric Retrieval Augmented Generation",
    "summary": "Retrieval-augmented generation (RAG) techniques have emerged as a promising solution to enhance the reliability of large language models (LLMs) by addressing issues like hallucinations, outdated knowledge, and domain adaptation. In particular, existing RAG methods append relevant documents retrieved from external corpus or databases to the input of LLMs to guide their generation process, which we refer to as the in-context knowledge injection method. While this approach is simple and often effective, it has inherent limitations. Firstly, increasing the context length and number of relevant documents can lead to higher computational overhead and degraded performance, especially in complex reasoning tasks. More importantly, in-context knowledge injection operates primarily at the input level, but LLMs store their internal knowledge in their parameters. This gap fundamentally limits the capacity of in-context methods. To this end, we introduce Parametric retrieval-augmented generation (Parametric RAG), a new RAG paradigm that integrates external knowledge directly into the parameters of feed-forward networks (FFN) of an LLM through document parameterization. This approach not only saves online computational costs by eliminating the need to inject multiple documents into the LLMs' input context, but also deepens the integration of external knowledge into the parametric knowledge space of the LLM. Experimental results demonstrate that Parametric RAG substantially enhances both the effectiveness and efficiency of knowledge augmentation in LLMs. Also, it can be combined with in-context RAG methods to achieve even better performance. We have open-sourced all the code, data, and models in the following anonymized GitHub link: https://github.com/oneal2000/PRAG",
    "authors": [
      "Weihang Su",
      "Yichen Tang",
      "Qingyao Ai",
      "Junxi Yan",
      "Changyue Wang",
      "Hongning Wang",
      "Ziyi Ye",
      "Yujia Zhou",
      "Yiqun Liu"
    ],
    "published": "2025-01-27T10:04:49Z",
    "updated": "2025-01-27T10:04:49Z",
    "pdf_url": "https://arxiv.org/pdf/2501.15915v1",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2403.15450v1",
    "title": "Loops On Retrieval Augmented Generation (LoRAG)",
    "summary": "This paper presents Loops On Retrieval Augmented Generation (LoRAG), a new framework designed to enhance the quality of retrieval-augmented text generation through the incorporation of an iterative loop mechanism. The architecture integrates a generative model, a retrieval mechanism, and a dynamic loop module, allowing for iterative refinement of the generated text through interactions with relevant information retrieved from the input context. Experimental evaluations on benchmark datasets demonstrate that LoRAG surpasses existing state-of-the-art models in terms of BLEU score, ROUGE score, and perplexity, showcasing its effectiveness in achieving both coherence and relevance in generated text. The qualitative assessment further illustrates LoRAG's capability to produce contextually rich and coherent outputs. This research contributes valuable insights into the potential of iterative loops in mitigating challenges in text generation, positioning LoRAG as a promising advancement in the field.",
    "authors": [
      "Ayush Thakur",
      "Rashmi Vashisth"
    ],
    "published": "2024-03-18T15:19:17Z",
    "updated": "2024-03-18T15:19:17Z",
    "pdf_url": "https://arxiv.org/pdf/2403.15450v1",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2401.15884v3",
    "title": "Corrective Retrieval Augmented Generation",
    "summary": "Large language models (LLMs) inevitably exhibit hallucinations since the accuracy of generated texts cannot be secured solely by the parametric knowledge they encapsulate. Although retrieval-augmented generation (RAG) is a practicable complement to LLMs, it relies heavily on the relevance of retrieved documents, raising concerns about how the model behaves if retrieval goes wrong. To this end, we propose the Corrective Retrieval Augmented Generation (CRAG) to improve the robustness of generation. Specifically, a lightweight retrieval evaluator is designed to assess the overall quality of retrieved documents for a query, returning a confidence degree based on which different knowledge retrieval actions can be triggered. Since retrieval from static and limited corpora can only return sub-optimal documents, large-scale web searches are utilized as an extension for augmenting the retrieval results. Besides, a decompose-then-recompose algorithm is designed for retrieved documents to selectively focus on key information and filter out irrelevant information in them. CRAG is plug-and-play and can be seamlessly coupled with various RAG-based approaches. Experiments on four datasets covering short- and long-form generation tasks show that CRAG can significantly improve the performance of RAG-based approaches.",
    "authors": [
      "Shi-Qi Yan",
      "Jia-Chen Gu",
      "Yun Zhu",
      "Zhen-Hua Ling"
    ],
    "published": "2024-01-29T04:36:39Z",
    "updated": "2024-10-07T02:19:21Z",
    "pdf_url": "https://arxiv.org/pdf/2401.15884v3",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2307.06985v10",
    "title": "Retrieval Augmented Generation using Engineering Design Knowledge",
    "summary": "Aiming to support Retrieval Augmented Generation (RAG) in the design process, we present a method to identify explicit, engineering design facts - {head entity :: relationship :: tail entity} from patented artefact descriptions. Given a sentence with a pair of entities (based on noun phrases) marked in a unique manner, our method extracts the relationship that is explicitly communicated in the sentence. For this task, we create a dataset of 375,084 examples and fine-tune language models for relation identification (token classification) and elicitation (sequence-to-sequence). The token classification approach achieves up to 99.7 % accuracy. Upon applying the method to a domain of 4,870 fan system patents, we populate a knowledge base of over 2.93 million facts. Using this knowledge base, we demonstrate how Large Language Models (LLMs) are guided by explicit facts to synthesise knowledge and generate technical and cohesive responses when sought out for knowledge retrieval tasks in the design process.",
    "authors": [
      "L. Siddharth",
      "Jianxi Luo"
    ],
    "published": "2023-07-13T17:25:28Z",
    "updated": "2024-08-26T10:05:43Z",
    "pdf_url": "https://arxiv.org/pdf/2307.06985v10",
    "categories": [
      "cs.CL",
      "cs.DB",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2508.03553v1",
    "title": "MultiRAG: A Knowledge-guided Framework for Mitigating Hallucination in Multi-source Retrieval Augmented Generation",
    "summary": "Retrieval Augmented Generation (RAG) has emerged as a promising solution to address hallucination issues in Large Language Models (LLMs). However, the integration of multiple retrieval sources, while potentially more informative, introduces new challenges that can paradoxically exacerbate hallucination problems. These challenges manifest primarily in two aspects: the sparse distribution of multi-source data that hinders the capture of logical relationships and the inherent inconsistencies among different sources that lead to information conflicts. To address these challenges, we propose MultiRAG, a novel framework designed to mitigate hallucination in multi-source retrieval-augmented generation through knowledge-guided approaches. Our framework introduces two key innovations: (1) a knowledge construction module that employs multi-source line graphs to efficiently aggregate logical relationships across different knowledge sources, effectively addressing the sparse data distribution issue; and (2) a sophisticated retrieval module that implements a multi-level confidence calculation mechanism, performing both graph-level and node-level assessments to identify and eliminate unreliable information nodes, thereby reducing hallucinations caused by inter-source inconsistencies. Extensive experiments on four multi-domain query datasets and two multi-hop QA datasets demonstrate that MultiRAG significantly enhances the reliability and efficiency of knowledge retrieval in complex multi-source scenarios. \\textcolor{blue}{Our code is available in https://github.com/wuwenlong123/MultiRAG.",
    "authors": [
      "Wenlong Wu",
      "Haofen Wang",
      "Bohan Li",
      "Peixuan Huang",
      "Xinzhe Zhao",
      "Lei Liang"
    ],
    "published": "2025-08-05T15:20:52Z",
    "updated": "2025-08-05T15:20:52Z",
    "pdf_url": "https://arxiv.org/pdf/2508.03553v1",
    "categories": [
      "cs.IR",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2506.21931v2",
    "title": "ARAG: Agentic Retrieval Augmented Generation for Personalized Recommendation",
    "summary": "Retrieval-Augmented Generation (RAG) has shown promise in enhancing recommendation systems by incorporating external context into large language model prompts. However, existing RAG-based approaches often rely on static retrieval heuristics and fail to capture nuanced user preferences in dynamic recommendation scenarios. In this work, we introduce ARAG, an Agentic Retrieval-Augmented Generation framework for Personalized Recommendation, which integrates a multi-agent collaboration mechanism into the RAG pipeline. To better understand the long-term and session behavior of the user, ARAG leverages four specialized LLM-based agents: a User Understanding Agent that summarizes user preferences from long-term and session contexts, a Natural Language Inference (NLI) Agent that evaluates semantic alignment between candidate items retrieved by RAG and inferred intent, a context summary agent that summarizes the findings of NLI agent, and an Item Ranker Agent that generates a ranked list of recommendations based on contextual fit. We evaluate ARAG accross three datasets. Experimental results demonstrate that ARAG significantly outperforms standard RAG and recency-based baselines, achieving up to 42.1% improvement in NDCG@5 and 35.5% in Hit@5. We also, conduct an ablation study to analyse the effect by different components of ARAG. Our findings highlight the effectiveness of integrating agentic reasoning into retrieval-augmented recommendation and provide new directions for LLM-based personalization.",
    "authors": [
      "Reza Yousefi Maragheh",
      "Pratheek Vadla",
      "Priyank Gupta",
      "Kai Zhao",
      "Aysenur Inan",
      "Kehui Yao",
      "Jianpeng Xu",
      "Praveen Kanumala",
      "Jason Cho",
      "Sushant Kumar"
    ],
    "published": "2025-06-27T05:45:59Z",
    "updated": "2025-08-11T16:24:36Z",
    "pdf_url": "https://arxiv.org/pdf/2506.21931v2",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.IR",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2507.13919v1",
    "title": "The Levers of Political Persuasion with Conversational AI",
    "summary": "There are widespread fears that conversational AI could soon exert unprecedented influence over human beliefs. Here, in three large-scale experiments (N=76,977), we deployed 19 LLMs-including some post-trained explicitly for persuasion-to evaluate their persuasiveness on 707 political issues. We then checked the factual accuracy of 466,769 resulting LLM claims. Contrary to popular concerns, we show that the persuasive power of current and near-future AI is likely to stem more from post-training and prompting methods-which boosted persuasiveness by as much as 51% and 27% respectively-than from personalization or increasing model scale. We further show that these methods increased persuasion by exploiting LLMs' unique ability to rapidly access and strategically deploy information and that, strikingly, where they increased AI persuasiveness they also systematically decreased factual accuracy.",
    "authors": [
      "Kobi Hackenburg",
      "Ben M. Tappin",
      "Luke Hewitt",
      "Ed Saunders",
      "Sid Black",
      "Hause Lin",
      "Catherine Fist",
      "Helen Margetts",
      "David G. Rand",
      "Christopher Summerfield"
    ],
    "published": "2025-07-18T13:50:09Z",
    "updated": "2025-07-18T13:50:09Z",
    "pdf_url": "https://arxiv.org/pdf/2507.13919v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2310.18435v1",
    "title": "Expanding the Set of Pragmatic Considerations in Conversational AI",
    "summary": "Despite considerable performance improvements, current conversational AI systems often fail to meet user expectations. We discuss several pragmatic limitations of current conversational AI systems. We illustrate pragmatic limitations with examples that are syntactically appropriate, but have clear pragmatic deficiencies. We label our complaints as \"Turing Test Triggers\" (TTTs) as they indicate where current conversational AI systems fall short compared to human behavior. We develop a taxonomy of pragmatic considerations intended to identify what pragmatic competencies a conversational AI system requires and discuss implications for the design and evaluation of conversational AI systems.",
    "authors": [
      "S. M. Seals",
      "Valerie L. Shalin"
    ],
    "published": "2023-10-27T19:21:50Z",
    "updated": "2023-10-27T19:21:50Z",
    "pdf_url": "https://arxiv.org/pdf/2310.18435v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2302.07926v1",
    "title": "Commonsense Reasoning for Conversational AI: A Survey of the State of the Art",
    "summary": "Large, transformer-based pretrained language models like BERT, GPT, and T5 have demonstrated a deep understanding of contextual semantics and language syntax. Their success has enabled significant advances in conversational AI, including the development of open-dialogue systems capable of coherent, salient conversations which can answer questions, chat casually, and complete tasks. However, state-of-the-art models still struggle with tasks that involve higher levels of reasoning - including commonsense reasoning that humans find trivial. This paper presents a survey of recent conversational AI research focused on commonsense reasoning. The paper lists relevant training datasets and describes the primary approaches to include commonsense in conversational AI. The paper also discusses benchmarks used for evaluating commonsense in conversational AI problems. Finally, the paper presents preliminary observations of the limited commonsense capabilities of two state-of-the-art open dialogue models, BlenderBot3 and LaMDA, and its negative effect on natural interactions. These observations further motivate research on commonsense reasoning in conversational AI.",
    "authors": [
      "Christopher Richardson",
      "Larry Heck"
    ],
    "published": "2023-02-15T19:55:57Z",
    "updated": "2023-02-15T19:55:57Z",
    "pdf_url": "https://arxiv.org/pdf/2302.07926v1",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2304.14543v1",
    "title": "Discourse over Discourse: The Need for an Expanded Pragmatic Focus in Conversational AI",
    "summary": "The summarization of conversation, that is, discourse over discourse, elevates pragmatic considerations as a pervasive limitation of both summarization and other applications of contemporary conversational AI. Building on impressive progress in both semantics and syntax, pragmatics concerns meaning in the practical sense. In this paper, we discuss several challenges in both summarization of conversations and other conversational AI applications, drawing on relevant theoretical work. We illustrate the importance of pragmatics with so-called star sentences, syntactically acceptable propositions that are pragmatically inappropriate in conversation or its summary. Because the baseline for quality of AI is indistinguishability from human behavior, we draw heavily on the psycho-linguistics literature, and label our complaints as \"Turing Test Triggers\" (TTTs). We discuss implications for the design and evaluation of conversation summarization methods and conversational AI applications like voice assistants and chatbots",
    "authors": [
      "S. M. Seals",
      "Valerie L. Shalin"
    ],
    "published": "2023-04-27T21:51:42Z",
    "updated": "2023-04-27T21:51:42Z",
    "pdf_url": "https://arxiv.org/pdf/2304.14543v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2501.11067v1",
    "title": "IntellAgent: A Multi-Agent Framework for Evaluating Conversational AI Systems",
    "summary": "Large Language Models (LLMs) are transforming artificial intelligence, evolving into task-oriented systems capable of autonomous planning and execution. One of the primary applications of LLMs is conversational AI systems, which must navigate multi-turn dialogues, integrate domain-specific APIs, and adhere to strict policy constraints. However, evaluating these agents remains a significant challenge, as traditional methods fail to capture the complexity and variability of real-world interactions. We introduce IntellAgent, a scalable, open-source multi-agent framework designed to evaluate conversational AI systems comprehensively. IntellAgent automates the creation of diverse, synthetic benchmarks by combining policy-driven graph modeling, realistic event generation, and interactive user-agent simulations. This innovative approach provides fine-grained diagnostics, addressing the limitations of static and manually curated benchmarks with coarse-grained metrics. IntellAgent represents a paradigm shift in evaluating conversational AI. By simulating realistic, multi-policy scenarios across varying levels of complexity, IntellAgent captures the nuanced interplay of agent capabilities and policy constraints. Unlike traditional methods, it employs a graph-based policy model to represent relationships, likelihoods, and complexities of policy interactions, enabling highly detailed diagnostics. IntellAgent also identifies critical performance gaps, offering actionable insights for targeted optimization. Its modular, open-source design supports seamless integration of new domains, policies, and APIs, fostering reproducibility and community collaboration. Our findings demonstrate that IntellAgent serves as an effective framework for advancing conversational AI by addressing challenges in bridging research and deployment. The framework is available at https://github.com/plurai-ai/intellagent",
    "authors": [
      "Elad Levi",
      "Ilan Kadar"
    ],
    "published": "2025-01-19T14:58:35Z",
    "updated": "2025-01-19T14:58:35Z",
    "pdf_url": "https://arxiv.org/pdf/2501.11067v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2507.20152v1",
    "title": "Goal Alignment in LLM-Based User Simulators for Conversational AI",
    "summary": "User simulators are essential to conversational AI, enabling scalable agent development and evaluation through simulated interactions. While current Large Language Models (LLMs) have advanced user simulation capabilities, we reveal that they struggle to consistently demonstrate goal-oriented behavior across multi-turn conversations--a critical limitation that compromises their reliability in downstream applications. We introduce User Goal State Tracking (UGST), a novel framework that tracks user goal progression throughout conversations. Leveraging UGST, we present a three-stage methodology for developing user simulators that can autonomously track goal progression and reason to generate goal-aligned responses. Moreover, we establish comprehensive evaluation metrics for measuring goal alignment in user simulators, and demonstrate that our approach yields substantial improvements across two benchmarks (MultiWOZ 2.4 and -Bench). Our contributions address a critical gap in conversational AI and establish UGST as an essential framework for developing goal-aligned user simulators.",
    "authors": [
      "Shuhaib Mehri",
      "Xiaocheng Yang",
      "Takyoung Kim",
      "Gokhan Tur",
      "Shikib Mehri",
      "Dilek Hakkani-Tr"
    ],
    "published": "2025-07-27T07:07:12Z",
    "updated": "2025-07-27T07:07:12Z",
    "pdf_url": "https://arxiv.org/pdf/2507.20152v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2503.17460v2",
    "title": "ConvoGen: Enhancing Conversational AI with Synthetic Data: A Multi-Agent Approach",
    "summary": "In this paper, we present ConvoGen: an innovative framework for generating synthetic conversational data using multi-agent systems. Our method leverages few-shot learning and introduces iterative sampling from a dynamically updated few-shot hub to create diverse and realistic conversational scenarios. The generated data has numerous applications, including training and evaluating conversational AI models, and augmenting existing datasets for tasks like conversational intent classification or conversation summarization. Our experiments demonstrate the effectiveness of this method in producing high-quality diverse synthetic conversational data, highlighting its potential to enhance the development and evaluation of conversational AI systems.",
    "authors": [
      "Reem Gody",
      "Mahmoud Goudy",
      "Ahmed Y. Tawfik"
    ],
    "published": "2025-03-21T18:14:12Z",
    "updated": "2025-05-09T14:12:58Z",
    "pdf_url": "https://arxiv.org/pdf/2503.17460v2",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2506.09902v1",
    "title": "PersonaLens: A Benchmark for Personalization Evaluation in Conversational AI Assistants",
    "summary": "Large language models (LLMs) have advanced conversational AI assistants. However, systematically evaluating how well these assistants apply personalization--adapting to individual user preferences while completing tasks--remains challenging. Existing personalization benchmarks focus on chit-chat, non-conversational tasks, or narrow domains, failing to capture the complexities of personalized task-oriented assistance. To address this, we introduce PersonaLens, a comprehensive benchmark for evaluating personalization in task-oriented AI assistants. Our benchmark features diverse user profiles equipped with rich preferences and interaction histories, along with two specialized LLM-based agents: a user agent that engages in realistic task-oriented dialogues with AI assistants, and a judge agent that employs the LLM-as-a-Judge paradigm to assess personalization, response quality, and task success. Through extensive experiments with current LLM assistants across diverse tasks, we reveal significant variability in their personalization capabilities, providing crucial insights for advancing conversational AI systems.",
    "authors": [
      "Zheng Zhao",
      "Clara Vania",
      "Subhradeep Kayal",
      "Naila Khan",
      "Shay B. Cohen",
      "Emine Yilmaz"
    ],
    "published": "2025-06-11T16:16:07Z",
    "updated": "2025-06-11T16:16:07Z",
    "pdf_url": "https://arxiv.org/pdf/2506.09902v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2307.10172v3",
    "title": "DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI",
    "summary": "Despite advancements in conversational AI, language models encounter challenges to handle diverse conversational tasks, and existing dialogue dataset collections often lack diversity and comprehensiveness. To tackle these issues, we introduce DialogStudio: the largest and most diverse collection of dialogue datasets, unified under a consistent format while preserving their original information. Our collection encompasses data from open-domain dialogues, task-oriented dialogues, natural language understanding, conversational recommendation, dialogue summarization, and knowledge-grounded dialogues, making it an incredibly rich and diverse resource for dialogue research and model training. To further enhance the utility of DialogStudio, we identify the licenses for each dataset, design external knowledge and domain-aware prompts for selected dialogues to facilitate instruction-aware fine-tuning. Furthermore, we develop conversational AI models using the dataset collection, and our experiments in both zero-shot and few-shot learning scenarios demonstrate the superiority of DialogStudio. To improve transparency and support dataset and task-based research, as well as language model pre-training, all datasets, licenses, codes, and models associated with DialogStudio are made publicly accessible\\footnote{\\url{https://github.com/salesforce/DialogStudio}}.",
    "authors": [
      "Jianguo Zhang",
      "Kun Qian",
      "Zhiwei Liu",
      "Shelby Heinecke",
      "Rui Meng",
      "Ye Liu",
      "Zhou Yu",
      "Huan Wang",
      "Silvio Savarese",
      "Caiming Xiong"
    ],
    "published": "2023-07-19T17:57:53Z",
    "updated": "2024-02-05T08:10:52Z",
    "pdf_url": "https://arxiv.org/pdf/2307.10172v3",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2510.08149v1",
    "title": "AI Knowledge Assist: An Automated Approach for the Creation of Knowledge Bases for Conversational AI Agents",
    "summary": "The utilization of conversational AI systems by leveraging Retrieval Augmented Generation (RAG) techniques to solve customer problems has been on the rise with the rapid progress of Large Language Models (LLMs). However, the absence of a company-specific dedicated knowledge base is a major barrier to the integration of conversational AI systems in contact centers. To this end, we introduce AI Knowledge Assist, a system that extracts knowledge in the form of question-answer (QA) pairs from historical customer-agent conversations to automatically build a knowledge base. Fine-tuning a lightweight LLM on internal data demonstrates state-of-the-art performance, outperforming larger closed-source LLMs. More specifically, empirical evaluation on 20 companies demonstrates that the proposed AI Knowledge Assist system that leverages the LLaMA-3.1-8B model eliminates the cold-start gap in contact centers by achieving above 90% accuracy in answering information-seeking questions. This enables immediate deployment of RAG-powered chatbots.",
    "authors": [
      "Md Tahmid Rahman Laskar",
      "Julien Bouvier Tremblay",
      "Xue-Yong Fu",
      "Cheng Chen",
      "Shashi Bhushan TN"
    ],
    "published": "2025-10-09T12:34:31Z",
    "updated": "2025-10-09T12:34:31Z",
    "pdf_url": "https://arxiv.org/pdf/2510.08149v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2305.12434v1",
    "title": "BiasAsker: Measuring the Bias in Conversational AI System",
    "summary": "Powered by advanced Artificial Intelligence (AI) techniques, conversational AI systems, such as ChatGPT and digital assistants like Siri, have been widely deployed in daily life. However, such systems may still produce content containing biases and stereotypes, causing potential social problems. Due to the data-driven, black-box nature of modern AI techniques, comprehensively identifying and measuring biases in conversational systems remains a challenging task. Particularly, it is hard to generate inputs that can comprehensively trigger potential bias due to the lack of data containing both social groups as well as biased properties. In addition, modern conversational systems can produce diverse responses (e.g., chatting and explanation), which makes existing bias detection methods simply based on the sentiment and the toxicity hardly being adopted. In this paper, we propose BiasAsker, an automated framework to identify and measure social bias in conversational AI systems. To obtain social groups and biased properties, we construct a comprehensive social bias dataset, containing a total of 841 groups and 8,110 biased properties. Given the dataset, BiasAsker automatically generates questions and adopts a novel method based on existence measurement to identify two types of biases (i.e., absolute bias and related bias) in conversational systems. Extensive experiments on 8 commercial systems and 2 famous research models, such as ChatGPT and GPT-3, show that 32.83% of the questions generated by BiasAsker can trigger biased behaviors in these widely deployed conversational systems. All the code, data, and experimental results have been released to facilitate future research.",
    "authors": [
      "Yuxuan Wan",
      "Wenxuan Wang",
      "Pinjia He",
      "Jiazhen Gu",
      "Haonan Bai",
      "Michael Lyu"
    ],
    "published": "2023-05-21T11:25:59Z",
    "updated": "2023-05-21T11:25:59Z",
    "pdf_url": "https://arxiv.org/pdf/2305.12434v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2506.21532v3",
    "title": "\"What's Up, Doc?\": Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets",
    "summary": "People are increasingly seeking healthcare information from large language models (LLMs) via interactive chatbots, yet the nature and inherent risks of these conversations remain largely unexplored. In this paper, we filter large-scale conversational AI datasets to achieve HealthChat-11K, a curated dataset of 11K real-world conversations composed of 25K user messages. We use HealthChat-11K and a clinician-driven taxonomy for how users interact with LLMs when seeking healthcare information in order to systematically study user interactions across 21 distinct health specialties. Our analysis reveals insights into the nature of how and why users seek health information, such as common interactions, instances of incomplete context, affective behaviors, and interactions (e.g., leading questions) that can induce sycophancy, underscoring the need for improvements in the healthcare support capabilities of LLMs deployed as conversational AI. Code and artifacts to retrieve our analyses and combine them into a curated dataset can be found here: https://github.com/yahskapar/HealthChat",
    "authors": [
      "Akshay Paruchuri",
      "Maryam Aziz",
      "Rohit Vartak",
      "Ayman Ali",
      "Best Uchehara",
      "Xin Liu",
      "Ishan Chatterjee",
      "Monica Agrawal"
    ],
    "published": "2025-06-26T17:52:18Z",
    "updated": "2025-09-20T01:36:08Z",
    "pdf_url": "https://arxiv.org/pdf/2506.21532v3",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2509.14256v1",
    "title": "JU-NLP at Touch: Covert Advertisement in Conversational AI-Generation and Detection Strategies",
    "summary": "This paper proposes a comprehensive framework for the generation of covert advertisements within Conversational AI systems, along with robust techniques for their detection. It explores how subtle promotional content can be crafted within AI-generated responses and introduces methods to identify and mitigate such covert advertising strategies. For generation (Sub-Task~1), we propose a novel framework that leverages user context and query intent to produce contextually relevant advertisements. We employ advanced prompting strategies and curate paired training data to fine-tune a large language model (LLM) for enhanced stealthiness. For detection (Sub-Task~2), we explore two effective strategies: a fine-tuned CrossEncoder (\\texttt{all-mpnet-base-v2}) for direct classification, and a prompt-based reformulation using a fine-tuned \\texttt{DeBERTa-v3-base} model. Both approaches rely solely on the response text, ensuring practicality for real-world deployment. Experimental results show high effectiveness in both tasks, achieving a precision of 1.0 and recall of 0.71 for ad generation, and F1-scores ranging from 0.99 to 1.00 for ad detection. These results underscore the potential of our methods to balance persuasive communication with transparency in conversational AI.",
    "authors": [
      "Arka Dutta",
      "Agrik Majumdar",
      "Sombrata Biswas",
      "Dipankar Das",
      "Sivaji Bandyopadhyay"
    ],
    "published": "2025-09-12T14:53:56Z",
    "updated": "2025-09-12T14:53:56Z",
    "pdf_url": "https://arxiv.org/pdf/2509.14256v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2404.08156v1",
    "title": "Multimodal Contextual Dialogue Breakdown Detection for Conversational AI Models",
    "summary": "Detecting dialogue breakdown in real time is critical for conversational AI systems, because it enables taking corrective action to successfully complete a task. In spoken dialog systems, this breakdown can be caused by a variety of unexpected situations including high levels of background noise, causing STT mistranscriptions, or unexpected user flows. In particular, industry settings like healthcare, require high precision and high flexibility to navigate differently based on the conversation history and dialogue states. This makes it both more challenging and more critical to accurately detect dialog breakdown. To accurately detect breakdown, we found it requires processing audio inputs along with downstream NLP model inferences on transcribed text in real time. In this paper, we introduce a Multimodal Contextual Dialogue Breakdown (MultConDB) model. This model significantly outperforms other known best models by achieving an F1 of 69.27.",
    "authors": [
      "Md Messal Monem Miah",
      "Ulie Schnaithmann",
      "Arushi Raghuvanshi",
      "Youngseo Son"
    ],
    "published": "2024-04-11T23:09:18Z",
    "updated": "2024-04-11T23:09:18Z",
    "pdf_url": "https://arxiv.org/pdf/2404.08156v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  },
  {
    "id": "http://arxiv.org/abs/2308.13534v1",
    "title": "Building Trust in Conversational AI: A Comprehensive Review and Solution Architecture for Explainable, Privacy-Aware Systems using LLMs and Knowledge Graph",
    "summary": "Conversational AI systems have emerged as key enablers of human-like interactions across diverse sectors. Nevertheless, the balance between linguistic nuance and factual accuracy has proven elusive. In this paper, we first introduce LLMXplorer, a comprehensive tool that provides an in-depth review of over 150 Large Language Models (LLMs), elucidating their myriad implications ranging from social and ethical to regulatory, as well as their applicability across industries. Building on this foundation, we propose a novel functional architecture that seamlessly integrates the structured dynamics of Knowledge Graphs with the linguistic capabilities of LLMs. Validated using real-world AI news data, our architecture adeptly blends linguistic sophistication with factual rigour and further strengthens data security through Role-Based Access Control. This research provides insights into the evolving landscape of conversational AI, emphasizing the imperative for systems that are efficient, transparent, and trustworthy.",
    "authors": [
      "Ahtsham Zafar",
      "Venkatesh Balavadhani Parthasarathy",
      "Chan Le Van",
      "Saad Shahid",
      "Aafaq Iqbal khan",
      "Arsalan Shahid"
    ],
    "published": "2023-08-13T22:47:51Z",
    "updated": "2023-08-13T22:47:51Z",
    "pdf_url": "https://arxiv.org/pdf/2308.13534v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "embedding": null
  }
]