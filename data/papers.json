[
  {
    "id": "2203.08975v2",
    "title": "A Survey of Multi-Agent Deep Reinforcement Learning with Communication",
    "summary": "Communication is an effective mechanism for coordinating the behaviors of multiple agents, broadening their views of the environment, and to support their collaborations. In the field of multi-agent deep reinforcement learning (MADRL), agents can improve the overall learning performance and achieve their objectives by communication. Agents can communicate various types of messages, either to all agents or to specific agent groups, or conditioned on specific constraints. With the growing body of research work in MADRL with communication (Comm-MADRL), there is a lack of a systematic and structural approach to distinguish and classify existing Comm-MADRL approaches. In this paper, we survey recent works in the Comm-MADRL field and consider various aspects of communication that can play a role in designing and developing multi-agent reinforcement learning systems. With these aspects in mind, we propose 9 dimensions along which Comm-MADRL approaches can be analyzed, developed, and compared. By projecting existing works into the multi-dimensional space, we discover interesting trends. We also propose some novel directions for designing future Comm-MADRL systems through exploring possible combinations of the dimensions.",
    "authors": [
      "Changxi Zhu",
      "Mehdi Dastani",
      "Shihan Wang"
    ],
    "published": "2022-03-16",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2203.08975v2",
    "categories": [
      "cs.MA",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1311.5108v1",
    "title": "A Methodology to Engineer and Validate Dynamic Multi-level Multi-agent Based Simulations",
    "summary": "This article proposes a methodology to model and simulate complex systems, based on IRM4MLS, a generic agent-based meta-model able to deal with multi-level systems. This methodology permits the engineering of dynamic multi-level agent-based models, to represent complex systems over several scales and domains of interest. Its goal is to simulate a phenomenon using dynamically the lightest representation to save computer resources without loss of information. This methodology is based on two mechanisms: (1) the activation or deactivation of agents representing different domain parts of the same phenomenon and (2) the aggregation or disaggregation of agents representing the same phenomenon at different scales.",
    "authors": [
      "Jean-Baptiste Soyez",
      "Gildas Morvan",
      "Daniel Dupont",
      "Rochdi Merzouki"
    ],
    "published": "2013-11-20",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1311.5108v1",
    "categories": [
      "cs.MA"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2508.08322v1",
    "title": "Context Engineering for Multi-Agent LLM Code Assistants Using Elicit, NotebookLM, ChatGPT, and Claude Code",
    "summary": "Large Language Models (LLMs) have shown promise in automating code generation and software engineering tasks, yet they often struggle with complex, multi-file projects due to context limitations and knowledge gaps. We propose a novel context engineering workflow that combines multiple AI components: an Intent Translator (GPT-5) for clarifying user requirements, an Elicit-powered semantic literature retrieval for injecting domain knowledge, NotebookLM-based document synthesis for contextual understanding, and a Claude Code multi-agent system for code generation and validation. Our integrated approach leverages intent clarification, retrieval-augmented generation, and specialized sub-agents orchestrated via Claude's agent framework. We demonstrate that this method significantly improves the accuracy and reliability of code assistants in real-world repositories, yielding higher single-shot success rates and better adherence to project context than baseline single-agent approaches. Qualitative results on a large Next.js codebase show the multi-agent system effectively plans, edits, and tests complex features with minimal human intervention. We compare our system with recent frameworks like CodePlan, MASAI, and HyperAgent, highlighting how targeted context injection and agent role decomposition lead to state-of-the-art performance. Finally, we discuss the implications for deploying LLM-based coding assistants in production, along with lessons learned on context management and futu",
    "authors": [
      "Muhammad Haseeb"
    ],
    "published": "2025-08-09",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08322v1",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2412.06333v3",
    "title": "Augmenting the action space with conventions to improve multi-agent cooperation in Hanabi",
    "summary": "The card game Hanabi is considered a strong medium for the testing and development of multi-agent reinforcement learning (MARL) algorithms, due to its cooperative nature, partial observability, limited communication and remarkable complexity. Previous research efforts have explored the capabilities of MARL algorithms within Hanabi, focusing largely on advanced architecture design and algorithmic manipulations to achieve state-of-the-art performance for various number of cooperators. However, this often leads to complex solution strategies with high computational cost and requiring large amounts of training data. For humans to solve the Hanabi game effectively, they require the use of conventions, which often allows for a means to implicitly convey ideas or knowledge based on a predefined, and mutually agreed upon, set of \"rules\" or principles. Multi-agent problems containing partial observability, especially when limited communication is present, can benefit greatly from the use of implicit knowledge sharing. In this paper, we propose a novel approach to augmenting an agent's action space using conventions, which act as a sequence of special cooperative actions that span over and include multiple time steps and multiple agents, requiring agents to actively opt in for it to reach fruition. These conventions are based on existing human conventions, and result in a significant improvement on the performance of existing techniques for self-play and cross-play for various number o",
    "authors": [
      "F. Bredell",
      "H. A. Engelbrecht",
      "J. C. Schoeman"
    ],
    "published": "2024-12-09",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2412.06333v3",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2512.03278v2",
    "title": "Thucy: An LLM-based Multi-Agent System for Claim Verification across Relational Databases",
    "summary": "In today's age, it is becoming increasingly difficult to decipher truth from lies. Every day, politicians, media outlets, and public figures make conflicting claims -- often about topics that can, in principle, be verified against structured data. For instance, statements about crime rates, economic growth or healthcare can all be verified against official public records and structured datasets. Building a system that can automatically do that would have sounded like science fiction just a few years ago. Yet, with the extraordinary progress in LLMs and agentic AI, this is now within reach. Still, there remains a striking gap between what is technically possible and what is being demonstrated by recent work. Most existing verification systems operate only on small, single-table databases -- typically a few hundred rows -- that conveniently fit within an LLM's context window.\n  In this paper we report our progress on Thucy, the first cross-database, cross-table multi-agent claim verification system that also provides concrete evidence for each verification verdict. Thucy remains completely agnostic to the underlying data sources before deployment and must therefore autonomously discover, inspect, and reason over all available relational databases to verify claims. Importantly, Thucy also reports the exact SQL queries that support its verdict (whether the claim is accurate or not) offering full transparency to expert users familiar with SQL. When evaluated on the TabFact dataset",
    "authors": [
      "Michael Theologitis",
      "Dan Suciu"
    ],
    "published": "2025-12-02",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2512.03278v2",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2510.13343v1",
    "title": "AOAD-MAT: Transformer-based multi-agent deep reinforcement learning model considering agents' order of action decisions",
    "summary": "Multi-agent reinforcement learning focuses on training the behaviors of multiple learning agents that coexist in a shared environment. Recently, MARL models, such as the Multi-Agent Transformer (MAT) and ACtion dEpendent deep Q-learning (ACE), have significantly improved performance by leveraging sequential decision-making processes. Although these models can enhance performance, they do not explicitly consider the importance of the order in which agents make decisions. In this paper, we propose an Agent Order of Action Decisions-MAT (AOAD-MAT), a novel MAT model that considers the order in which agents make decisions. The proposed model explicitly incorporates the sequence of action decisions into the learning process, allowing the model to learn and predict the optimal order of agent actions. The AOAD-MAT model leverages a Transformer-based actor-critic architecture that dynamically adjusts the sequence of agent actions. To achieve this, we introduce a novel MARL architecture that cooperates with a subtask focused on predicting the next agent to act, integrated into a Proximal Policy Optimization based loss function to synergistically maximize the advantage of the sequential decision-making. The proposed method was validated through extensive experiments on the StarCraft Multi-Agent Challenge and Multi-Agent MuJoCo benchmarks. The experimental results show that the proposed AOAD-MAT model outperforms existing MAT and other baseline models, demonstrating the effectiveness of",
    "authors": [
      "Shota Takayama",
      "Katsuhide Fujita"
    ],
    "published": "2025-10-15",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2510.13343v1",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2401.07324v3",
    "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent",
    "summary": "Large Language Model (LLM) agents significantly extend the capabilities of standalone LLMs, empowering them to interact with external tools (e.g., APIs, functions) and complete various tasks in a self-directed fashion. The challenge of tool use demands that LLMs not only understand user queries and generate answers accurately but also excel in task planning, tool invocation, and result summarization. While traditional works focus on training a single LLM with all these capabilities, performance limitations become apparent, particularly with smaller models. To overcome these challenges, we propose a novel approach that decomposes the aforementioned capabilities into a planner, caller, and summarizer. Each component is implemented by a single LLM that focuses on a specific capability and collaborates with others to accomplish the task. This modular framework facilitates individual updates and the potential use of smaller LLMs for building each capability. To effectively train this framework, we introduce a two-stage training paradigm. First, we fine-tune a backbone LLM on the entire dataset without discriminating sub-tasks, providing the model with a comprehensive understanding of the task. Second, the fine-tuned LLM is used to instantiate the planner, caller, and summarizer respectively, which are continually fine-tuned on respective sub-tasks. Evaluation across various tool-use benchmarks illustrates that our proposed multi-LLM framework surpasses the traditional single-LLM a",
    "authors": [
      "Weizhou Shen",
      "Chenliang Li",
      "Hongzhan Chen",
      "Ming Yan",
      "Xiaojun Quan",
      "Hehong Chen",
      "Ji Zhang",
      "Fei Huang"
    ],
    "published": "2024-01-14",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2401.07324v3",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2410.12532v3",
    "title": "MedAide: Information Fusion and Anatomy of Medical Intents via LLM-based Agent Collaboration",
    "summary": "In healthcare intelligence, the ability to fuse heterogeneous, multi-intent information from diverse clinical sources is fundamental to building reliable decision-making systems. Large Language Model (LLM)-driven information interaction systems currently showing potential promise in the healthcare domain. Nevertheless, they often suffer from information redundancy and coupling when dealing with complex medical intents, leading to severe hallucinations and performance bottlenecks. To this end, we propose MedAide, an LLM-based medical multi-agent collaboration framework designed to enable intent-aware information fusion and coordinated reasoning across specialized healthcare domains. Specifically, we introduce a regularization-guided module that combines syntactic constraints with retrieval augmented generation to decompose complex queries into structured representations, facilitating fine-grained clinical information fusion and intent resolution. Additionally, a dynamic intent prototype matching module is proposed to utilize dynamic prototype representation with a semantic similarity matching mechanism to achieve adaptive recognition and updating of the agent's intent in multi-round healthcare dialogues. Ultimately, we design a rotation agent collaboration mechanism that introduces dynamic role rotation and decision-level information fusion across specialized medical agents. Extensive experiments are conducted on four medical benchmarks with composite intents. Experimental res",
    "authors": [
      "Dingkang Yang",
      "Jinjie Wei",
      "Mingcheng Li",
      "Jiyao Liu",
      "Lihao Liu",
      "Ming Hu",
      "Junjun He",
      "Yakun Ju",
      "Wei Zhou",
      "Yang Liu"
    ],
    "published": "2024-10-16",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2410.12532v3",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2502.07165v1",
    "title": "Don't Just Demo, Teach Me the Principles: A Principle-Based Multi-Agent Prompting Strategy for Text Classification",
    "summary": "We present PRINCIPLE-BASED PROMPTING, a simple but effective multi-agent prompting strategy for text classification. It first asks multiple LLM agents to independently generate candidate principles based on analysis of demonstration samples with or without labels, consolidates them into final principles via a finalizer agent, and then sends them to a classifier agent to perform downstream classification tasks. Extensive experiments on binary and multi-class classification datasets with different sizes of LLMs show that our approach not only achieves substantial performance gains (1.55% - 19.37%) over zero-shot prompting on macro-F1 score but also outperforms other strong baselines (CoT and stepback prompting). Principles generated by our approach help LLMs perform better on classification tasks than human crafted principles on two private datasets. Our multi-agent PRINCIPLE-BASED PROMPTING approach also shows on-par or better performance compared to demonstration-based few-shot prompting approaches, yet with substantially lower inference costs. Ablation studies show that label information and the multi-agent cooperative LLM framework play an important role in generating high-quality principles to facilitate downstream classification tasks.",
    "authors": [
      "Peipei Wei",
      "Dimitris Dimitriadis",
      "Yan Xu",
      "Mingwei Shen"
    ],
    "published": "2025-02-11",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2502.07165v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2412.20138v7",
    "title": "TradingAgents: Multi-Agents LLM Financial Trading Framework",
    "summary": "Significant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs). In finance, efforts have largely focused on single-agent systems handling specific tasks or multi-agent frameworks independently gathering data. However, the multi-agent systems' potential to replicate real-world trading firms' collaborative dynamics remains underexplored. TradingAgents proposes a novel stock trading framework inspired by trading firms, featuring LLM-powered agents in specialized roles such as fundamental analysts, sentiment analysts, technical analysts, and traders with varied risk profiles. The framework includes Bull and Bear researcher agents assessing market conditions, a risk management team monitoring exposure, and traders synthesizing insights from debates and historical data to make informed decisions. By simulating a dynamic, collaborative trading environment, this framework aims to improve trading performance. Detailed architecture and extensive experiments reveal its superiority over baseline models, with notable improvements in cumulative returns, Sharpe ratio, and maximum drawdown, highlighting the potential of multi-agent LLM frameworks in financial trading. TradingAgents is available at https://github.com/TauricResearch/TradingAgents.",
    "authors": [
      "Yijia Xiao",
      "Edward Sun",
      "Di Luo",
      "Wei Wang"
    ],
    "published": "2024-12-28",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2412.20138v7",
    "categories": [
      "q-fin.TR",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2602.03128v1",
    "title": "Understanding Multi-Agent LLM Frameworks: A Unified Benchmark and Experimental Analysis",
    "summary": "Multi-agent LLM frameworks are widely used to accelerate the development of agent systems powered by large language models (LLMs). These frameworks impose distinct architectural structures that govern how agents interact, store information, and coordinate tasks. However, their impact on system performance remains poorly understood. This gap is critical, as architectural choices alone can induce order-of-magnitude differences in latency and throughput, as well as substantial variation in accuracy and scalability. Addressing this challenge requires (i) jointly evaluating multiple capabilities, such as orchestration overhead, memory behavior, planning, specialization, and coordination, and (ii) conducting these evaluations under controlled, framework-level conditions to isolate architectural effects. Existing benchmarks focus on individual capabilities and lack standardized framework-level evaluation. We address these limitations by (i) introducing an architectural taxonomy for systematically comparing multi-agent LLM frameworks along fundamental dimensions, and (ii) developing MAFBench, a unified evaluation suite that integrates existing benchmarks under a standardized execution pipeline. Using MAFBench, we conduct a controlled empirical study across several widely used frameworks. Our results show that framework-level design choices alone can increase latency by over 100x, reduce planning accuracy by up to 30%, and lower coordination success from above 90% to below 30%. Finall",
    "authors": [
      "Abdelghny Orogat",
      "Ana Rostam",
      "Essam Mansour"
    ],
    "published": "2026-02-03",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2602.03128v1",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2602.04518v1",
    "title": "Learning the Value Systems of Agents with Preference-based and Inverse Reinforcement Learning",
    "summary": "Agreement Technologies refer to open computer systems in which autonomous software agents interact with one another, typically on behalf of humans, in order to come to mutually acceptable agreements. With the advance of AI systems in recent years, it has become apparent that such agreements, in order to be acceptable to the involved parties, must remain aligned with ethical principles and moral values. However, this is notoriously difficult to ensure, especially as different human users (and their software agents) may hold different value systems, i.e. they may differently weigh the importance of individual moral values. Furthermore, it is often hard to specify the precise meaning of a value in a particular context in a computational manner. Methods to estimate value systems based on human-engineered specifications, e.g. based on value surveys, are limited in scale due to the need for intense human moderation. In this article, we propose a novel method to automatically \\emph{learn} value systems from observations and human demonstrations. In particular, we propose a formal model of the \\emph{value system learning} problem, its instantiation to sequential decision-making domains based on multi-objective Markov decision processes, as well as tailored preference-based and inverse reinforcement learning algorithms to infer value grounding functions and value systems. The approach is illustrated and evaluated by two simulated use cases.",
    "authors": [
      "Andrés Holgado-Sánchez",
      "Holger Billhardt",
      "Alberto Fernández",
      "Sascha Ossowski"
    ],
    "published": "2026-02-04",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2602.04518v1",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1809.07124v2",
    "title": "Pommerman: A Multi-Agent Playground",
    "summary": "We present Pommerman, a multi-agent environment based on the classic console game Bomberman. Pommerman consists of a set of scenarios, each having at least four players and containing both cooperative and competitive aspects. We believe that success in Pommerman will require a diverse set of tools and methods, including planning, opponent/teammate modeling, game theory, and communication, and consequently can serve well as a multi-agent benchmark. To date, we have already hosted one competition, and our next one will be featured in the NIPS 2018 competition track.",
    "authors": [
      "Cinjon Resnick",
      "Wes Eldridge",
      "David Ha",
      "Denny Britz",
      "Jakob Foerster",
      "Julian Togelius",
      "Kyunghyun Cho",
      "Joan Bruna"
    ],
    "published": "2018-09-19",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1809.07124v2",
    "categories": [
      "cs.MA"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2102.08370v2",
    "title": "Quantifying the effects of environment and population diversity in multi-agent reinforcement learning",
    "summary": "Generalization is a major challenge for multi-agent reinforcement learning. How well does an agent perform when placed in novel environments and in interactions with new co-players? In this paper, we investigate and quantify the relationship between generalization and diversity in the multi-agent domain. Across the range of multi-agent environments considered here, procedurally generating training levels significantly improves agent performance on held-out levels. However, agent performance on the specific levels used in training sometimes declines as a result. To better understand the effects of co-player variation, our experiments introduce a new environment-agnostic measure of behavioral diversity. Results demonstrate that population size and intrinsic motivation are both effective methods of generating greater population diversity. In turn, training with a diverse set of co-players strengthens agent performance in some (but not all) cases.",
    "authors": [
      "Kevin R. McKee",
      "Joel Z. Leibo",
      "Charlie Beattie",
      "Richard Everett"
    ],
    "published": "2021-02-16",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2102.08370v2",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2412.05449v1",
    "title": "Towards Effective GenAI Multi-Agent Collaboration: Design and Evaluation for Enterprise Applications",
    "summary": "AI agents powered by large language models (LLMs) have shown strong capabilities in problem solving. Through combining many intelligent agents, multi-agent collaboration has emerged as a promising approach to tackle complex, multi-faceted problems that exceed the capabilities of single AI agents. However, designing the collaboration protocols and evaluating the effectiveness of these systems remains a significant challenge, especially for enterprise applications. This report addresses these challenges by presenting a comprehensive evaluation of coordination and routing capabilities in a novel multi-agent collaboration framework. We evaluate two key operational modes: (1) a coordination mode enabling complex task completion through parallel communication and payload referencing, and (2) a routing mode for efficient message forwarding between agents. We benchmark on a set of handcrafted scenarios from three enterprise domains, which are publicly released with the report. For coordination capabilities, we demonstrate the effectiveness of inter-agent communication and payload referencing mechanisms, achieving end-to-end goal success rates of 90%. Our analysis yields several key findings: multi-agent collaboration enhances goal success rates by up to 70% compared to single-agent approaches in our benchmarks; payload referencing improves performance on code-intensive tasks by 23%; latency can be substantially reduced with a routing mechanism that selectively bypasses agent orchestr",
    "authors": [
      "Raphael Shu",
      "Nilaksh Das",
      "Michelle Yuan",
      "Monica Sunkara",
      "Yi Zhang"
    ],
    "published": "2024-12-06",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2412.05449v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2303.14061v4",
    "title": "Learning Reward Machines in Cooperative Multi-Agent Tasks",
    "summary": "This paper presents a novel approach to Multi-Agent Reinforcement Learning (MARL) that combines cooperative task decomposition with the learning of reward machines (RMs) encoding the structure of the sub-tasks. The proposed method helps deal with the non-Markovian nature of the rewards in partially observable environments and improves the interpretability of the learnt policies required to complete the cooperative task. The RMs associated with each sub-task are learnt in a decentralised manner and then used to guide the behaviour of each agent. By doing so, the complexity of a cooperative multi-agent problem is reduced, allowing for more effective learning. The results suggest that our approach is a promising direction for future research in MARL, especially in complex environments with large state spaces and multiple agents.",
    "authors": [
      "Leo Ardon",
      "Daniel Furelos-Blanco",
      "Alessandra Russo"
    ],
    "published": "2023-03-24",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2303.14061v4",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.SC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2506.03053v2",
    "title": "MAEBE: Multi-Agent Emergent Behavior Framework",
    "summary": "Traditional AI safety evaluations on isolated LLMs are insufficient as multi-agent AI ensembles become prevalent, introducing novel emergent risks. This paper introduces the Multi-Agent Emergent Behavior Evaluation (MAEBE) framework to systematically assess such risks. Using MAEBE with the Greatest Good Benchmark (and a novel double-inversion question technique), we demonstrate that: (1) LLM moral preferences, particularly for Instrumental Harm, are surprisingly brittle and shift significantly with question framing, both in single agents and ensembles. (2) The moral reasoning of LLM ensembles is not directly predictable from isolated agent behavior due to emergent group dynamics. (3) Specifically, ensembles exhibit phenomena like peer pressure influencing convergence, even when guided by a supervisor, highlighting distinct safety and alignment challenges. Our findings underscore the necessity of evaluating AI systems in their interactive, multi-agent contexts.",
    "authors": [
      "Sinem Erisken",
      "Timothy Gothard",
      "Martin Leitgab",
      "Ram Potham"
    ],
    "published": "2025-06-03",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2506.03053v2",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2302.10809v4",
    "title": "Causal Explanations for Sequential Decision-Making in Multi-Agent Systems",
    "summary": "We present CEMA: Causal Explanations in Multi-Agent systems; a framework for creating causal natural language explanations of an agent's decisions in dynamic sequential multi-agent systems to build more trustworthy autonomous agents. Unlike prior work that assumes a fixed causal structure, CEMA only requires a probabilistic model for forward-simulating the state of the system. Using such a model, CEMA simulates counterfactual worlds that identify the salient causes behind the agent's decisions. We evaluate CEMA on the task of motion planning for autonomous driving and test it in diverse simulated scenarios. We show that CEMA correctly and robustly identifies the causes behind the agent's decisions, even when a large number of other agents is present, and show via a user study that CEMA's explanations have a positive effect on participants' trust in autonomous vehicles and are rated as high as high-quality baseline explanations elicited from other participants. We release the collected explanations with annotations as the HEADD dataset.",
    "authors": [
      "Balint Gyevnar",
      "Cheng Wang",
      "Christopher G. Lucas",
      "Shay B. Cohen",
      "Stefano V. Albrecht"
    ],
    "published": "2023-02-21",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2302.10809v4",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2110.08172v2",
    "title": "MLFC: From 10 to 50 Planners in the Multi-Agent Programming Contest",
    "summary": "In this paper, we describe the strategies used by our team, MLFC, that led us to achieve the 2nd place in the 15th edition of the Multi-Agent Programming Contest. The scenario used in the contest is an extension of the previous edition (14th) \"Agents Assemble\" wherein two teams of agents move around a 2D grid and compete to assemble complex block structures. We discuss the languages and tools used during the development of our team. Then, we summarise the main strategies that were carried over from our previous participation in the 14th edition and list the limitations (if any) of using these strategies in the latest contest edition. We also developed new strategies that were made specifically for the extended scenario: cartography (determining the size of the map); formal verification of the map merging protocol (to provide assurances that it works when increasing the number of agents); plan cache (efficiently scaling the number of planners); task achievement (forming groups of agents to achieve tasks); and bullies (agents that focus on stopping agents from the opposing team). Finally, we give a brief overview of our performance in the contest and discuss what we believe were our shortcomings.",
    "authors": [
      "Rafael C. Cardoso",
      "Angelo Ferrando",
      "Fabio Papacchini",
      "Matt Luckcuck",
      "Sven Linker",
      "Terry R. Payne"
    ],
    "published": "2021-10-15",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2110.08172v2",
    "categories": [
      "cs.MA"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1807.02648v1",
    "title": "How game complexity affects the playing behavior of synthetic agents",
    "summary": "Agent based simulation of social organizations, via the investigation of agents' training and learning tactics and strategies, has been inspired by the ability of humans to learn from social environments which are rich in agents, interactions and partial or hidden information. Such richness is a source of complexity that an effective learner has to be able to navigate. This paper focuses on the investigation of the impact of the environmental complexity on the game playing-and-learning behavior of synthetic agents. We demonstrate our approach using two independent turn-based zero-sum games as the basis of forming social events which are characterized both by competition and cooperation. The paper's key highlight is that as the complexity of a social environment changes, an effective player has to adapt its learning and playing profile to maintain a given performance profile",
    "authors": [
      "Chairi Kiourt",
      "Dimitris Kalles",
      "Panagiotis Kanellopoulos"
    ],
    "published": "2018-07-07",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1807.02648v1",
    "categories": [
      "cs.AI",
      "cs.CC",
      "cs.MA"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2512.13930v1",
    "title": "Hierarchical Multi-agent Large Language Model Reasoning for Autonomous Functional Materials Discovery",
    "summary": "Artificial intelligence is reshaping scientific exploration, but most methods automate procedural tasks without engaging in scientific reasoning, limiting autonomy in discovery. We introduce Materials Agents for Simulation and Theory in Electronic-structure Reasoning (MASTER), an active learning framework where large language models autonomously design, execute, and interpret atomistic simulations. In MASTER, a multimodal system translates natural language into density functional theory workflows, while higher-level reasoning agents guide discovery through a hierarchy of strategies, including a single agent baseline and three multi-agent approaches: peer review, triage-ranking, and triage-forms. Across two chemical applications, CO adsorption on Cu-surface transition metal (M) adatoms and on M-N-C catalysts, reasoning-driven exploration reduces required atomistic simulations by up to 90% relative to trial-and-error selection. Reasoning trajectories reveal chemically grounded decisions that cannot be explained by stochastic sampling or semantic bias. Altogether, multi-agent collaboration accelerates materials discovery and marks a new paradigm for autonomous scientific exploration.",
    "authors": [
      "Samuel Rothfarb",
      "Megan C. Davis",
      "Ivana Matanovic",
      "Baikun Li",
      "Edward F. Holby",
      "Wilton J. M. Kort-Kamp"
    ],
    "published": "2025-12-15",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2512.13930v1",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2402.11651v2",
    "title": "Learning From Failure: Integrating Negative Examples when Fine-tuning Large Language Models as Agents",
    "summary": "Large language models (LLMs) have achieved success in acting as agents, which interact with environments through tools such as search engines. However, LLMs are optimized for language generation instead of tool use during training or alignment, limiting their effectiveness as agents. To resolve this problem, previous work has first collected interaction trajectories between LLMs and environments, using only trajectories that successfully finished the task to fine-tune smaller models, making fine-tuning data scarce and acquiring it both difficult and costly. Discarding failed trajectories also leads to significant wastage of data and resources and limits the possible optimization paths during fine-tuning. In this paper, we argue that unsuccessful trajectories offer valuable insights, and LLMs can learn from these trajectories through appropriate quality control and fine-tuning strategies. By simply adding a prefix or suffix that tells the model whether to generate a successful trajectory during training, we improve model performance by a large margin on mathematical reasoning, multi-hop question answering, and strategic question answering tasks. We further analyze the inference results and find that our method provides a better trade-off between valuable information and errors in unsuccessful trajectories. To our knowledge, we are the first to demonstrate the value of negative trajectories and their application in agent-tunning scenarios. Our findings offer guidance for develo",
    "authors": [
      "Renxi Wang",
      "Haonan Li",
      "Xudong Han",
      "Yixuan Zhang",
      "Timothy Baldwin"
    ],
    "published": "2024-02-18",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2402.11651v2",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2409.02645v2",
    "title": "Emergent Language: A Survey and Taxonomy",
    "summary": "The field of emergent language represents a novel area of research within the domain of artificial intelligence, particularly within the context of multi-agent reinforcement learning. Although the concept of studying language emergence is not new, early approaches were primarily concerned with explaining human language formation, with little consideration given to its potential utility for artificial agents. In contrast, studies based on reinforcement learning aim to develop communicative capabilities in agents that are comparable to or even superior to human language. Thus, they extend beyond the learned statistical representations that are common in natural language processing research. This gives rise to a number of fundamental questions, from the prerequisites for language emergence to the criteria for measuring its success. This paper addresses these questions by providing a comprehensive review of 181 scientific publications on emergent language in artificial intelligence. Its objective is to serve as a reference for researchers interested in or proficient in the field. Consequently, the main contributions are the definition and overview of the prevailing terminology, the analysis of existing evaluation methods and metrics, and the description of the identified research gaps.",
    "authors": [
      "Jannik Peters",
      "Constantin Waubert de Puiseau",
      "Hasan Tercan",
      "Arya Gopikrishnan",
      "Gustavo Adolpho Lucas De Carvalho",
      "Christian Bitter",
      "Tobias Meisen"
    ],
    "published": "2024-09-04",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2409.02645v2",
    "categories": [
      "cs.MA",
      "cs.CL"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2512.06196v1",
    "title": "ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment",
    "summary": "As agents based on large language models are increasingly deployed to long-horizon tasks, maintaining their alignment with stakeholder preferences becomes critical. Effective alignment in such settings requires reward models that are interpretable so that stakeholders can understand and audit model objectives. Moreover, reward models must be capable of steering agents at interaction time, allowing preference shifts to be incorporated without retraining. We introduce ARCANE, a framework that frames alignment as a multi-agent collaboration problem that dynamically represents stakeholder preferences as natural-language rubrics: weighted sets of verifiable criteria that can be generated on-the-fly from task context. Inspired by utility theory, we formulate rubric learning as a reconstruction problem and apply a regularized Group-Sequence Policy Optimization (GSPO) procedure that balances interpretability, faithfulness, and computational efficiency. Using a corpus of 219 labeled rubrics derived from the GDPVal benchmark, we evaluate ARCANE on challenging tasks requiring multi-step reasoning and tool use. The learned rubrics produce compact, legible evaluations and enable configurable trade-offs (e.g., correctness vs. conciseness) without retraining. Our results show that rubric-based reward models offer a promising path toward interpretable, test-time adaptive alignment for complex, long-horizon AI systems.",
    "authors": [
      "Charlie Masters",
      "Marta Grześkiewicz",
      "Stefano V. Albrecht"
    ],
    "published": "2025-12-05",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2512.06196v1",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2405.16887v2",
    "title": "A Large Language Model-based multi-agent manufacturing system for intelligent shopfloor",
    "summary": "As customer demand for multi-variety and small-batch production increases, dynamic disturbances place greater demands on manufacturing systems. To address such challenges, researchers proposed the multi-agent manufacturing system. However, conventional agent negotiation typically relies on pre-defined and fixed heuristic rules, which are ill-suited to managing complex and fluctuating disturbances. In current implementations, mainstream approaches based on reinforcement learning require the development of simulators and training models specific to a given shopfloor, necessitating substantial computational resources and lacking scalability. To overcome this limitation, the present study proposes a Large Language Model-based (LLM-based) multi-agent manufacturing system for intelligent shopfloor management. By defining the diverse modules of agents and their collaborative methods, this system facilitates the processing of all workpieces with minimal human intervention. The agents in this system consist of the Machine Server Module (MSM), Bid Inviter Module (BIM), Bidder Module (BM), Thinking Module (TM), and Decision Module (DM). By harnessing the reasoning capabilities of LLMs, these modules enable agents to dynamically analyze shopfloor information and select appropriate processing machines. The LLM-based modules, predefined by system prompts, provide dynamic functionality for the system without the need for pre-training. Extensive experiments were conducted in physical shopflo",
    "authors": [
      "Zhen Zhao",
      "Dunbing Tang",
      "Changchun Liu",
      "Liping Wang",
      "Zequn Zhang",
      "Haihua Zhu",
      "Kai Chen",
      "Qingwei Nie",
      "Yuchen Ji"
    ],
    "published": "2024-05-27",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2405.16887v2",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2312.10793v3",
    "title": "Demystifying Instruction Mixing for Fine-tuning Large Language Models",
    "summary": "Instruction tuning significantly enhances the performance of large language models (LLMs) across various tasks. However, the procedure to optimizing the mixing of instruction datasets for LLM fine-tuning is still poorly understood. This study categorizes instructions into three primary types: NLP downstream tasks, coding, and general chat. We explore the effects of instruction tuning on different combinations of datasets on LLM performance, and find that certain instruction types are more advantageous for specific applications but can negatively impact other areas. This work provides insights into instruction mixtures, laying the foundations for future research.",
    "authors": [
      "Renxi Wang",
      "Haonan Li",
      "Minghao Wu",
      "Yuxia Wang",
      "Xudong Han",
      "Chiyu Zhang",
      "Timothy Baldwin"
    ],
    "published": "2023-12-17",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2312.10793v3",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2304.12244v3",
    "title": "WizardLM: Empowering large pre-trained language models to follow complex instructions",
    "summary": "Training large language models (LLMs) with open-domain instruction following data brings colossal success. However, manually creating such instruction data is very time-consuming and labor-intensive. Moreover, humans may struggle to produce high-complexity instructions. In this paper, we show an avenue for creating large amounts of instruction data with varying levels of complexity using LLM instead of humans. Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM. Human evaluations on a complexity-balanced test bed and Vicuna's testset show that instructions from Evol-Instruct are superior to human-created ones. By analyzing the human evaluation results of the high complexity part, we demonstrate that outputs from our WizardLM are preferred to outputs from OpenAI ChatGPT. In GPT-4 automatic evaluation, WizardLM achieves more than 90\\% capacity of ChatGPT on 17 out of 29 skills. Even though WizardLM still lags behind ChatGPT in some aspects, our findings suggest that fine-tuning with AI-evolved instructions is a promising direction for enhancing LLMs. Our code and data are public at https://github.com/nlpxucan/WizardLM",
    "authors": [
      "Can Xu",
      "Qingfeng Sun",
      "Kai Zheng",
      "Xiubo Geng",
      "Pu Zhao",
      "Jiazhan Feng",
      "Chongyang Tao",
      "Qingwei Lin",
      "Daxin Jiang"
    ],
    "published": "2023-04-24",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2304.12244v3",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2004.04722v1",
    "title": "Re-conceptualising the Language Game Paradigm in the Framework of Multi-Agent Reinforcement Learning",
    "summary": "In this paper, we formulate the challenge of re-conceptualising the language game experimental paradigm in the framework of multi-agent reinforcement learning (MARL). If successful, future language game experiments will benefit from the rapid and promising methodological advances in the MARL community, while future MARL experiments on learning emergent communication will benefit from the insights and results gained from language game experiments. We strongly believe that this cross-pollination has the potential to lead to major breakthroughs in the modelling of how human-like languages can emerge and evolve in multi-agent systems.",
    "authors": [
      "Paul Van Eecke",
      "Katrien Beuls"
    ],
    "published": "2020-04-09",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2004.04722v1",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2504.19565v3",
    "title": "Knowledge-Driven Agentic Scientific Corpus Distillation Framework for Biomedical Large Language Models Training",
    "summary": "Corpus distillation for biomedical large language models (LLMs) seeks to address the pressing challenge of insufficient quantity and quality in open-source annotated scientific corpora, which remains a bottleneck for effective LLM training in biomedical research. This paper proposes a knowledge-driven, agentic framework for scientific corpus distillation, tailored explicitly for LLM training in the biomedical domain, addressing the challenge posed by the complex hierarchy of biomedical knowledge. Central to our approach is a collaborative multi-agent architecture, where specialized agents, each guided by the Medical Subject Headings (MeSH) hierarchy, work in concert to autonomously extract, synthesize, and self-evaluate high-quality textual data from vast scientific literature. This agentic framework collectively generates and refines domain-specific question-answer pairs, ensuring comprehensive coverage and consistency with biomedical ontologies while minimizing manual involvement. Extensive experimental results show that language models trained on our multi-agent distilled datasets achieve notable improvements in biomedical question-answering tasks, outperforming both strong life sciences LLM baselines and advanced proprietary models. Notably, our AI-Ready dataset enables Llama3-70B to surpass GPT-4 with MedPrompt and Med-PaLM-2, despite their larger scale. Detailed ablation studies and case analyses further validate the effectiveness and synergy of each agent within the fr",
    "authors": [
      "Meng Xiao",
      "Xunxin Cai",
      "Qingqing Long",
      "Chengrui Wang",
      "Yuanchun Zhou",
      "Hengshu Zhu"
    ],
    "published": "2025-04-28",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2504.19565v3",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2310.00034v2",
    "title": "PB-LLM: Partially Binarized Large Language Models",
    "summary": "This paper explores network binarization, a radical form of quantization, compressing model weights to a single bit, specifically for Large Language Models (LLMs) compression. Due to previous binarization methods collapsing LLMs, we propose a novel approach, Partially-Binarized LLM (PB-LLM), which can achieve extreme low-bit quantization while maintaining the linguistic reasoning capacity of quantized LLMs. Specifically, our exploration first uncovers the ineffectiveness of naive applications of existing binarization algorithms and highlights the imperative role of salient weights in achieving low-bit quantization. Thus, PB-LLM filters a small ratio of salient weights during binarization, allocating them to higher-bit storage, i.e., partially-binarization. PB-LLM is extended to recover the capacities of quantized LMMs, by analyzing from the perspective of post-training quantization (PTQ) and quantization-aware training (QAT). Under PTQ, combining the concepts from GPTQ, we reconstruct the binarized weight matrix guided by the Hessian matrix and successfully recover the reasoning capacity of PB-LLM in low-bit. Under QAT, we freeze the salient weights during training, explore the derivation of optimal scaling factors crucial for minimizing the quantization error, and propose a scaling mechanism based on this derived scaling strategy for residual binarized weights. Those explorations and the developed methodologies significantly contribute to rejuvenating the performance of low-",
    "authors": [
      "Yuzhang Shang",
      "Zhihang Yuan",
      "Qiang Wu",
      "Zhen Dong"
    ],
    "published": "2023-09-29",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2310.00034v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2503.21676v2",
    "title": "How do language models learn facts? Dynamics, curricula and hallucinations",
    "summary": "Large language models accumulate vast knowledge during pre-training, yet the dynamics governing this acquisition remain poorly understood. This work investigates the learning dynamics of language models on a synthetic factual recall task, uncovering three key findings: First, language models learn in three phases, exhibiting a performance plateau before acquiring precise factual knowledge. Mechanistically, this plateau coincides with the formation of attention-based circuits that support recall. Second, the training data distribution significantly impacts learning dynamics, as imbalanced distributions lead to shorter plateaus. Finally, hallucinations emerge simultaneously with knowledge, and integrating new knowledge into the model through fine-tuning is challenging, as it quickly corrupts its existing parametric memories. Our results emphasize the importance of data distribution in knowledge acquisition and suggest novel data scheduling strategies to accelerate neural network training.",
    "authors": [
      "Nicolas Zucchet",
      "Jörg Bornschein",
      "Stephanie Chan",
      "Andrew Lampinen",
      "Razvan Pascanu",
      "Soham De"
    ],
    "published": "2025-03-27",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2503.21676v2",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2505.00753v4",
    "title": "LLM-Based Human-Agent Collaboration and Interaction Systems: A Survey",
    "summary": "Recent advances in large language models (LLMs) have sparked growing interest in building fully autonomous agents. However, fully autonomous LLM-based agents still face significant challenges, including limited reliability due to hallucinations, difficulty in handling complex tasks, and substantial safety and ethical risks, all of which limit their feasibility and trustworthiness in real-world applications. To overcome these limitations, LLM-based human-agent systems (LLM-HAS) incorporate human-provided information, feedback, or control into the agent system to enhance system performance, reliability and safety. These human-agent collaboration systems enable humans and LLM-based agents to collaborate effectively by leveraging their complementary strengths. This paper provides the first comprehensive and structured survey of LLM-HAS. It clarifies fundamental concepts, systematically presents core components shaping these systems, including environment &amp; profiling, human feedback, interaction types, orchestration and communication, explores emerging applications, and discusses unique challenges and opportunities arising from human-AI collaboration. By consolidating current knowledge and offering a structured overview, we aim to foster further research and innovation in this rapidly evolving interdisciplinary field. Paper lists and resources are available at https://github.com/HenryPengZou/Awesome-Human-Agent-Collaboration-Interaction-Systems.",
    "authors": [
      "Henry Peng Zou",
      "Wei-Chieh Huang",
      "Yaozu Wu",
      "Yankai Chen",
      "Chunyu Miao",
      "Hoang Nguyen",
      "Yue Zhou",
      "Weizhi Zhang",
      "Liancheng Fang",
      "Langzhou He"
    ],
    "published": "2025-05-01",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2505.00753v4",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2409.01907v1",
    "title": "Focus Agent: LLM-Powered Virtual Focus Group",
    "summary": "In the domain of Human-Computer Interaction, focus groups represent a widely utilised yet resource-intensive methodology, often demanding the expertise of skilled moderators and meticulous preparatory efforts. This study introduces the ``Focus Agent,'' a Large Language Model (LLM) powered framework that simulates both the focus group (for data collection) and acts as a moderator in a focus group setting with human participants. To assess the data quality derived from the Focus Agent, we ran five focus group sessions with a total of 23 human participants as well as deploying the Focus Agent to simulate these discussions with AI participants. Quantitative analysis indicates that Focus Agent can generate opinions similar to those of human participants. Furthermore, the research exposes some improvements associated with LLMs acting as moderators in focus group discussions that include human participants.",
    "authors": [
      "Taiyu Zhang",
      "Xuesong Zhang",
      "Robbe Cools",
      "Adalberto L. Simeone"
    ],
    "published": "2024-09-03",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2409.01907v1",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1710.05833v2",
    "title": "Multi-messenger Observations of a Binary Neutron Star Merger",
    "summary": "On 2017 August 17 a binary neutron star coalescence candidate (later designated GW170817) with merger time 12:41:04 UTC was observed through gravitational waves by the Advanced LIGO and Advanced Virgo detectors. The Fermi Gamma-ray Burst Monitor independently detected a gamma-ray burst (GRB 170817A) with a time delay of $\\sim$1.7 s with respect to the merger time. From the gravitational-wave signal, the source was initially localized to a sky region of 31 deg$^2$ at a luminosity distance of $40^{+8}_{-8}$ Mpc and with component masses consistent with neutron stars. The component masses were later measured to be in the range 0.86 to 2.26 Msun. An extensive observing campaign was launched across the electromagnetic spectrum leading to the discovery of a bright optical transient (SSS17a, now with the IAU identification of AT 2017gfo) in NGC 4993 (at $\\sim$40 Mpc) less than 11 hours after the merger by the One-Meter, Two Hemisphere (1M2H) team using the 1 m Swope Telescope. The optical transient was independently detected by multiple teams within an hour. Subsequent observations targeted the object and its environment. Early ultraviolet observations revealed a blue transient that faded within 48 hours. Optical and infrared observations showed a redward evolution over $\\sim$10 days. Following early non-detections, X-ray and radio emission were discovered at the transient's position $\\sim$9 and $\\sim$16 days, respectively, after the merger. Both the X-ray and radio emission likely ",
    "authors": [
      " LIGO Scientific Collaboration",
      " Virgo Collaboration",
      "Fermi GBM",
      " INTEGRAL",
      "IceCube Collaboration",
      "AstroSat Cadmium Zinc Telluride Imager Team",
      "IPN Collaboration",
      "The Insight-Hxmt Collaboration",
      "ANTARES Collaboration",
      "The Swift Collaboration"
    ],
    "published": "2017-10-16",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1710.05833v2",
    "categories": [
      "astro-ph.HE",
      "gr-qc"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2512.21309v2",
    "title": "A Plan Reuse Mechanism for LLM-Driven Agent",
    "summary": "Integrating large language models (LLMs) into personal assistants, like Xiao Ai and Blue Heart V, effectively enhances their ability to interact with humans, solve complex tasks, and manage IoT devices. Such assistants are also termed LLM-driven agents. Upon receiving user requests, the LLM-driven agent generates plans using an LLM, executes these plans through various tools, and then returns the response to the user. During this process, the latency for generating a plan with an LLM can reach tens of seconds, significantly degrading user experience. Real-world dataset analysis shows that about 30% of the requests received by LLM-driven agents are identical or similar, which allows the reuse of previously generated plans to reduce latency. However, it is difficult to accurately define the similarity between the request texts received by the LLM-driven agent through directly evaluating the original request texts. Moreover, the diverse expressions of natural language and the unstructured format of plan texts make implementing plan reuse challenging. To address these issues, we present and implement a plan reuse mechanism for LLM-driven agents called AgentReuse. AgentReuse leverages the similarities and differences among requests' semantics and uses intent classification to evaluate the similarities between requests and enable the reuse of plans. Experimental results based on a real-world dataset demonstrate that AgentReuse achieves a 93% effective plan reuse rate, an F1 score o",
    "authors": [
      "Guopeng Li",
      "Ruiqi Wu",
      "Haisheng Tan"
    ],
    "published": "2025-12-24",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2512.21309v2",
    "categories": [
      "cs.MA"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2504.00577v1",
    "title": "AWAKE Input to the European Strategy for Particle Physics Update on behalf of the AWAKE Collaboration",
    "summary": "The Advanced Wakefield Experiment, AWAKE, is a well-established international collaboration and aims to develop the proton-driven plasma wakefield acceleration of electron bunches to energies and qualities suitable for first particle physics applications, such as strong-field QED and fixed target experiments ($\\sim$50-200GeV). Numerical simulations show that these energies can be reached with an average accelerating gradient of $\\sim1$GeV/m in a single proton-driven plasma wakefield stage. This is enabled by the high energy per particle and per bunch of the CERN SPS 19kJ, 400GeV and LHC ($\\sim$120kJ, 7TeV) proton bunches. Bunches produced by synchrotrons are long, and AWAKE takes advantage of the self-modulation process to drive wakefields with GV/m amplitude. By the end of 2025, all physics concepts related to self-modulation will have been experimentally established as part of the AWAKE ongoing program that started in 2016. Key achievements include: direct observation of self-modulation, stabilization and control by two seeding methods, acceleration of externally injected electrons from 19MeV to more than 2GeV, and sustained high wakefield amplitudes beyond self-modulation saturation using a plasma density step. In addition to a brief summary of achievements reached so far, this document outlines the AWAKE roadmap as a demonstrator facility for producing beams with quality sufficient for first applications. The plan includes: 1) Accelerating a quality-controlled electron bu",
    "authors": [
      "E. Gschwendtner",
      "P. Muggli",
      "M. Turner",
      "AWAKE Collaboration"
    ],
    "published": "2025-04-01",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2504.00577v1",
    "categories": [
      "physics.acc-ph"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2510.25595v1",
    "title": "Communication and Verification in LLM Agents towards Collaboration under Information Asymmetry",
    "summary": "While Large Language Model (LLM) agents are often approached from the angle of action planning/generation to accomplish a goal (e.g., given by language descriptions), their abilities to collaborate with each other to achieve a joint goal are not well explored. To address this limitation, this paper studies LLM agents in task collaboration, particularly under the condition of information asymmetry, where agents have disparities in their knowledge and skills and need to work together to complete a shared task. We extend Einstein Puzzles, a classical symbolic puzzle, to a table-top game. In this game, two LLM agents must reason, communicate, and act to satisfy spatial and relational constraints required to solve the puzzle. We apply a fine-tuning-plus-verifier framework in which LLM agents are equipped with various communication strategies and verification signals from the environment. Empirical results highlight the critical importance of aligned communication, especially when agents possess both information-seeking and -providing capabilities. Interestingly, agents without communication can still achieve high task performance; however, further analysis reveals a lack of true rule understanding and lower trust from human evaluators. Instead, by integrating an environment-based verifier, we enhance agents' ability to comprehend task rules and complete tasks, promoting both safer and more interpretable collaboration in AI systems. https://github.com/Roihn/EinsteinPuzzles",
    "authors": [
      "Run Peng",
      "Ziqiao Ma",
      "Amy Pang",
      "Sikai Li",
      "Zhang Xi-Jia",
      "Yingzhuo Yu",
      "Cristian-Paul Bara",
      "Joyce Chai"
    ],
    "published": "2025-10-29",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2510.25595v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1211.0310v1",
    "title": "Large Synoptic Survey Telescope: Dark Energy Science Collaboration",
    "summary": "This white paper describes the LSST Dark Energy Science Collaboration (DESC), whose goal is the study of dark energy and related topics in fundamental physics with data from the Large Synoptic Survey Telescope (LSST). It provides an overview of dark energy science and describes the current and anticipated state of the field. It makes the case for the DESC by laying out a robust analytical framework for dark energy science that has been defined by its members and the comprehensive three-year work plan they have developed for implementing that framework. The analysis working groups cover five key probes of dark energy: weak lensing, large scale structure, galaxy clusters, Type Ia supernovae, and strong lensing. The computing working groups span cosmological simulations, galaxy catalogs, photon simulations and a systematic software and computational framework for LSST dark energy data analysis. The technical working groups make the connection between dark energy science and the LSST system. The working groups have close linkages, especially through the use of the photon simulations to study the impact of instrument design and survey strategy on analysis methodology and cosmological parameter estimation. The white paper describes several high priority tasks identified by each of the 16 working groups. Over the next three years these tasks will help prepare for LSST analysis, make synergistic connections with ongoing cosmological surveys and provide the dark energy community with ",
    "authors": [
      " LSST Dark Energy Science Collaboration"
    ],
    "published": "2012-11-01",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1211.0310v1",
    "categories": [
      "astro-ph.CO",
      "hep-ex"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2402.11163v1",
    "title": "KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph",
    "summary": "In this paper, we aim to improve the reasoning ability of large language models (LLMs) over knowledge graphs (KGs) to answer complex questions. Inspired by existing methods that design the interaction strategy between LLMs and KG, we propose an autonomous LLM-based agent framework, called KG-Agent, which enables a small LLM to actively make decisions until finishing the reasoning process over KGs. In KG-Agent, we integrate the LLM, multifunctional toolbox, KG-based executor, and knowledge memory, and develop an iteration mechanism that autonomously selects the tool then updates the memory for reasoning over KG. To guarantee the effectiveness, we leverage program language to formulate the multi-hop reasoning process over the KG, and synthesize a code-based instruction dataset to fine-tune the base LLM. Extensive experiments demonstrate that only using 10K samples for tuning LLaMA-7B can outperform state-of-the-art methods using larger LLMs or more data, on both in-domain and out-domain datasets. Our code and data will be publicly released.",
    "authors": [
      "Jinhao Jiang",
      "Kun Zhou",
      "Wayne Xin Zhao",
      "Yang Song",
      "Chen Zhu",
      "Hengshu Zhu",
      "Ji-Rong Wen"
    ],
    "published": "2024-02-17",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2402.11163v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2511.14460v1",
    "title": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning",
    "summary": "Large Language Models (LLMs) are increasingly being explored for building Agents capable of active environmental interaction (e.g., via tool use) to solve complex problems. Reinforcement Learning (RL) is considered a key technology with significant potential for training such Agents; however, the effective application of RL to LLM Agents is still in its nascent stages and faces considerable challenges. Currently, this emerging field lacks in-depth exploration into RL approaches specifically tailored for the LLM Agent context, alongside a scarcity of flexible and easily extensible training frameworks designed for this purpose. To help advance this area, this paper first revisits and clarifies Reinforcement Learning methodologies for LLM Agents by systematically extending the Markov Decision Process (MDP) framework to comprehensively define the key components of an LLM Agent. Secondly, we introduce Agent-R1, a modular, flexible, and user-friendly training framework for RL-based LLM Agents, designed for straightforward adaptation across diverse task scenarios and interactive environments. We conducted experiments on Multihop QA benchmark tasks, providing initial validation for the effectiveness of our proposed methods and framework.",
    "authors": [
      "Mingyue Cheng",
      "Jie Ouyang",
      "Shuo Yu",
      "Ruiran Yan",
      "Yucong Luo",
      "Zirui Liu",
      "Daoyu Wang",
      "Qi Liu",
      "Enhong Chen"
    ],
    "published": "2025-11-18",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2511.14460v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2510.05158v1",
    "title": "Lang-PINN: From Language to Physics-Informed Neural Networks via a Multi-Agent Framework",
    "summary": "Physics-informed neural networks (PINNs) provide a powerful approach for solving partial differential equations (PDEs), but constructing a usable PINN remains labor-intensive and error-prone. Scientists must interpret problems as PDE formulations, design architectures and loss functions, and implement stable training pipelines. Existing large language model (LLM) based approaches address isolated steps such as code generation or architecture suggestion, but typically assume a formal PDE is already specified and therefore lack an end-to-end perspective. We present Lang-PINN, an LLM-driven multi-agent system that builds trainable PINNs directly from natural language task descriptions. Lang-PINN coordinates four complementary agents: a PDE Agent that parses task descriptions into symbolic PDEs, a PINN Agent that selects architectures, a Code Agent that generates modular implementations, and a Feedback Agent that executes and diagnoses errors for iterative refinement. This design transforms informal task statements into executable and verifiable PINN code. Experiments show that Lang-PINN achieves substantially lower errors and greater robustness than competitive baselines: mean squared error (MSE) is reduced by up to 3--5 orders of magnitude, end-to-end execution success improves by more than 50\\%, and reduces time overhead by up to 74\\%.",
    "authors": [
      "Xin He",
      "Liangliang You",
      "Hongduan Tian",
      "Bo Han",
      "Ivor Tsang",
      "Yew-Soon Ong"
    ],
    "published": "2025-10-03",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2510.05158v1",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2502.05986v2",
    "title": "Preventing Rogue Agents Improves Multi-Agent Collaboration",
    "summary": "Multi-agent systems, where specialized agents collaborate to solve a shared task hold great potential, from increased modularity to simulating complex environments. However, they also have a major caveat -- a single agent can cause the entire system to fail. Consider a simple game where the knowledge to solve the task is distributed between agents, which share information in a communication channel. At each round, any of the agents can terminate the game and make the final prediction, even if they are uncertain about the outcome of their action. Detection of such rogue agents before they act may prevent the system's failure. In this work, we propose to monitor agents during action prediction and intervene when a future error is likely to occur. To test our approach, we introduce WhoDunitEnv, a multi-agent collaboration environment that allows modular control over task complexity and communication structure. Experiments on WhoDunitEnv, code generation tasks and the GovSim environment for resource sustainability show that our approach leads to substantial performance gains up to 17.4%, 2.5% and 20%, respectively. Thorough analysis shows that our monitors successfully identify critical points of agent confusion and our interventions effectively stop agent errors from propagating.",
    "authors": [
      "Ohav Barbi",
      "Ori Yoran",
      "Mor Geva"
    ],
    "published": "2025-02-09",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2502.05986v2",
    "categories": [
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2509.05882v2",
    "title": "Collaborate, Deliberate, Evaluate: How LLM Alignment Affects Coordinated Multi-Agent Outcomes",
    "summary": "As Large Language Models (LLMs) get integrated into diverse workflows, they are increasingly being regarded as \"collaborators\" with humans, and required to work in coordination with other AI systems. If such AI collaborators are to reliably coordinate their actions and behaviors with humans or other AIs, their properties and behaviors over multi-turn interactions must be known and predictable. This paper examines how different alignment methods affect LLM agents' effectiveness as partners in multi-turn, multi-party collaborations. We study this question through the lens of intervention agents that insert themselves into group dialogues not to provide answers, but to encourage the collaborative group to slow down and reflect upon their reasoning for deliberative decision-making. Common alignment techniques are typically developed under simplified single-user settings and assume the optimality of the underlying token MDP. Using the theoretical lens of the modified-action MDP, we show how they do not account for the dynamics of long-horizon multi-party interactions. We present a novel roleplay simulation methodology, where we align LLMs according to different methods and then deploy them in collaborative task dialogues to quantify how interventions affect the trajectory of group collaboration, belief alignment, and coordination. Our results show that an intervention agent that is robust to action modification significantly outperforms common alignment baselines in supporting cor",
    "authors": [
      "Abhijnan Nath",
      "Carine Graff",
      "Nikhil Krishnaswamy"
    ],
    "published": "2025-09-07",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2509.05882v2",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "0811.2750v2",
    "title": "IceCube Collaboration Contributions to ARENA 2008",
    "summary": "Contributions of the IceCube Collaboration to the 3rd International Workshop on Acoustic and Radio EeV Neutrino detection Activities (ARENA 2008). The conference was held at Roma University \"Sapienza,\" June 25-27, 2008, in Rome, Italy. This is an html index of the IceCube Collaboration contributions, with clickable links to the individual papers.",
    "authors": [
      " IceCube Collaboration"
    ],
    "published": "2008-11-15",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/0811.2750v2",
    "categories": [
      "astro-ph"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2508.04652v7",
    "title": "LLM Collaboration With Multi-Agent Reinforcement Learning",
    "summary": "A large amount of work has been done in Multi-Agent Systems (MAS) for modeling and solving problems with multiple interacting agents. However, most LLMs are pretrained independently and not specifically optimized for coordination. Existing LLM fine-tuning frameworks rely on individual rewards, which require complex reward designs for each agent to encourage collaboration. To address these challenges, we model LLM collaboration as a cooperative Multi-Agent Reinforcement Learning (MARL) problem. We develop a multi-agent, multi-turn algorithm, Multi-Agent Group Relative Policy Optimization (MAGRPO), to solve it, building on current RL approaches for LLMs as well as MARL techniques. Our experiments on LLM writing and coding collaboration demonstrate that fine-tuning MAS with MAGRPO enables agents to generate high-quality responses efficiently through effective cooperation. Our approach opens the door to using other MARL methods for LLMs and highlights the associated challenges. Our code is available at https://github.com/OpenMLRL/CoMLRL.",
    "authors": [
      "Shuo Liu",
      "Tianle Chen",
      "Zeyu Liang",
      "Xueguang Lyu",
      "Christopher Amato"
    ],
    "published": "2025-08-06",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2508.04652v7",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1709.01586v3",
    "title": "Robust Semi-Cooperative Multi-Agent Coordination in the Presence of Stochastic Disturbances",
    "summary": "This paper presents a robust distributed coordination protocol that achieves generation of collision-free trajectories for multiple unicycle agents in the presence of stochastic uncertainties. We build upon our earlier work on semi-cooperative coordination and we redesign the coordination controllers so that the agents counteract a class of state (wind) disturbances and measurement noise. Safety and convergence is proved analytically, while simulation results demonstrate the efficacy of the proposed solution.",
    "authors": [
      "Kunal Garg",
      "Dongkun Han",
      "Dimitra Panagou"
    ],
    "published": "2017-09-05",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1709.01586v3",
    "categories": [
      "eess.SY",
      "cs.MA"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2506.17560v1",
    "title": "Towards Zero-Shot Coordination between Teams of Agents: The N-XPlay Framework",
    "summary": "Zero-shot coordination (ZSC) -- the ability to collaborate with unfamiliar partners -- is essential to making autonomous agents effective teammates. Existing ZSC methods evaluate coordination capabilities between two agents who have not previously interacted. However, these scenarios do not reflect the complexity of real-world multi-agent systems, where coordination often involves a hierarchy of sub-groups and interactions between teams of agents, known as Multi-Team Systems (MTS). To address this gap, we first introduce N-player Overcooked, an N-agent extension of the popular two-agent ZSC benchmark, enabling evaluation of ZSC in N-agent scenarios. We then propose N-XPlay for ZSC in N-agent, multi-team settings. Comparison against Self-Play across two-, three- and five-player Overcooked scenarios, where agents are split between an ``ego-team'' and a group of unseen collaborators shows that agents trained with N-XPlay are better able to simultaneously balance ``intra-team'' and ``inter-team'' coordination than agents trained with SP.",
    "authors": [
      "Ava Abderezaei",
      "Chi-Hui Lin",
      "Joseph Miceli",
      "Naren Sivagnanadasan",
      "Stéphane Aroca-Ouellette",
      "Jake Brawer",
      "Alessandro Roncone"
    ],
    "published": "2025-06-21",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2506.17560v1",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2404.07677v2",
    "title": "ODA: Observation-Driven Agent for integrating LLMs and Knowledge Graphs",
    "summary": "The integration of Large Language Models (LLMs) and knowledge graphs (KGs) has achieved remarkable success in various natural language processing tasks. However, existing methodologies that integrate LLMs and KGs often navigate the task-solving process solely based on the LLM's analysis of the question, overlooking the rich cognitive potential inherent in the vast knowledge encapsulated in KGs. To address this, we introduce Observation-Driven Agent (ODA), a novel AI agent framework tailored for tasks involving KGs. ODA incorporates KG reasoning abilities via global observation, which enhances reasoning capabilities through a cyclical paradigm of observation, action, and reflection. Confronting the exponential explosion of knowledge during observation, we innovatively design a recursive observation mechanism. Subsequently, we integrate the observed knowledge into the action and reflection modules. Through extensive experiments, ODA demonstrates state-of-the-art performance on several datasets, notably achieving accuracy improvements of 12.87% and 8.9%.",
    "authors": [
      "Lei Sun",
      "Zhengwei Tao",
      "Youdi Li",
      "Hiroshi Arakawa"
    ],
    "published": "2024-04-11",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2404.07677v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "0205016v1",
    "title": "From Alife Agents to a Kingdom of N Queens",
    "summary": "This paper presents a new approach to solving N-queen problems, which involves a model of distributed autonomous agents with artificial life (ALife) and a method of representing N-queen constraints in an agent environment. The distributed agents locally interact with their living environment, i.e., a chessboard, and execute their reactive behaviors by applying their behavioral rules for randomized motion, least-conflict position searching, and cooperating with other agents etc. The agent-based N-queen problem solving system evolves through selection and contest according to the rule of Survival of the Fittest, in which some agents will die or be eaten if their moving strategies are less efficient than others. The experimental results have shown that this system is capable of solving large-scale N-queen problems. This paper also provides a model of ALife agents for solving general CSPs.",
    "authors": [
      "Jing Han",
      "Jiming Liu",
      "Qingsheng Cai"
    ],
    "published": "2002-05-13",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/0205016v1",
    "categories": [
      "cs.AI",
      "cs.DS",
      "cs.MA"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2310.03903v3",
    "title": "LLM-Coordination: Evaluating and Analyzing Multi-agent Coordination Abilities in Large Language Models",
    "summary": "Large Language Models (LLMs) have demonstrated emergent common-sense reasoning and Theory of Mind (ToM) capabilities, making them promising candidates for developing coordination agents. This study introduces the LLM-Coordination Benchmark, a novel benchmark for analyzing LLMs in the context of Pure Coordination Settings, where agents must cooperate to maximize gains. Our benchmark evaluates LLMs through two distinct tasks. The first is Agentic Coordination, where LLMs act as proactive participants in four pure coordination games. The second is Coordination Question Answering (CoordQA), which tests LLMs on 198 multiple-choice questions across these games to evaluate three key abilities: Environment Comprehension, ToM Reasoning, and Joint Planning. Results from Agentic Coordination experiments reveal that LLM-Agents excel in multi-agent coordination settings where decision-making primarily relies on environmental variables but face challenges in scenarios requiring active consideration of partners' beliefs and intentions. The CoordQA experiments further highlight significant room for improvement in LLMs' Theory of Mind reasoning and joint planning capabilities. Zero-Shot Coordination (ZSC) experiments in the Agentic Coordination setting demonstrate that LLM agents, unlike RL methods, exhibit robustness to unseen partners. These findings indicate the potential of LLMs as Agents in pure coordination setups and underscore areas for improvement. Code Available at https://github.co",
    "authors": [
      "Saaket Agashe",
      "Yue Fan",
      "Anthony Reyna",
      "Xin Eric Wang"
    ],
    "published": "2023-10-05",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2310.03903v3",
    "categories": [
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2410.02958v2",
    "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML",
    "summary": "Automated machine learning (AutoML) accelerates AI development by automating tasks in the development pipeline, such as optimal model search and hyperparameter tuning. Existing AutoML systems often require technical expertise to set up complex tools, which is in general time-consuming and requires a large amount of human effort. Therefore, recent works have started exploiting large language models (LLM) to lessen such burden and increase the usability of AutoML frameworks via a natural language interface, allowing non-expert users to build their data-driven solutions. These methods, however, are usually designed only for a particular process in the AI development pipeline and do not efficiently use the inherent capacity of the LLMs. This paper proposes AutoML-Agent, a novel multi-agent framework tailored for full-pipeline AutoML, i.e., from data retrieval to model deployment. AutoML-Agent takes user's task descriptions, facilitates collaboration between specialized LLM agents, and delivers deployment-ready models. Unlike existing work, instead of devising a single plan, we introduce a retrieval-augmented planning strategy to enhance exploration to search for more optimal plans. We also decompose each plan into sub-tasks (e.g., data preprocessing and neural network design) each of which is solved by a specialized agent we build via prompting executing in parallel, making the search process more efficient. Moreover, we propose a multi-stage verification to verify executed resul",
    "authors": [
      "Patara Trirat",
      "Wonyong Jeong",
      "Sung Ju Hwang"
    ],
    "published": "2024-10-03",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2410.02958v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2501.02842v1",
    "title": "Foundations of GenIR",
    "summary": "The chapter discusses the foundational impact of modern generative AI models on information access (IA) systems. In contrast to traditional AI, the large-scale training and superior data modeling of generative AI models enable them to produce high-quality, human-like responses, which brings brand new opportunities for the development of IA paradigms. In this chapter, we identify and introduce two of them in details, i.e., information generation and information synthesis. Information generation allows AI to create tailored content addressing user needs directly, enhancing user experience with immediate, relevant outputs. Information synthesis leverages the ability of generative AI to integrate and reorganize existing information, providing grounded responses and mitigating issues like model hallucination, which is particularly valuable in scenarios requiring precision and external knowledge. This chapter delves into the foundational aspects of generative models, including architecture, scaling, and training, and discusses their applications in multi-modal scenarios. Additionally, it examines the retrieval-augmented generation paradigm and other methods for corpus modeling and understanding, demonstrating how generative AI can enhance information access systems. It also summarizes potential challenges and fruitful directions for future studies.",
    "authors": [
      "Qingyao Ai",
      "Jingtao Zhan",
      "Yiqun Liu"
    ],
    "published": "2025-01-06",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2501.02842v1",
    "categories": [
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2601.16513v1",
    "title": "Competing Visions of Ethical AI: A Case Study of OpenAI",
    "summary": "Introduction. AI Ethics is framed distinctly across actors and stakeholder groups. We report results from a case study of OpenAI analysing ethical AI discourse. Method. Research addressed: How has OpenAI's public discourse leveraged 'ethics', 'safety', 'alignment' and adjacent related concepts over time, and what does discourse signal about framing in practice? A structured corpus, differentiating between communication for a general audience and communication with an academic audience, was assembled from public documentation. Analysis. Qualitative content analysis of ethical themes combined inductively derived and deductively applied codes. Quantitative analysis leveraged computational content analysis methods via NLP to model topics and quantify changes in rhetoric over time. Visualizations report aggregate results. For reproducible results, we have released our code at https://github.com/famous-blue-raincoat/AI_Ethics_Discourse. Results. Results indicate that safety and risk discourse dominate OpenAI's public communication and documentation, without applying academic and advocacy ethics frameworks or vocabularies. Conclusions. Implications for governance are presented, along with discussion of ethics-washing practices in industry.",
    "authors": [
      "Melissa Wilfley",
      "Mengting Ai",
      "Madelyn Rose Sanfilippo"
    ],
    "published": "2026-01-23",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2601.16513v1",
    "categories": [
      "cs.CY"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2408.00025v3",
    "title": "Need of AI in Modern Education: in the Eyes of Explainable AI (xAI)",
    "summary": "Modern Education is not \\textit{Modern} without AI. However, AI's complex nature makes understanding and fixing problems challenging. Research worldwide shows that a parent's income greatly influences a child's education. This led us to explore how AI, especially complex models, makes important decisions using Explainable AI tools. Our research uncovered many complexities linked to parental income and offered reasonable explanations for these decisions. However, we also found biases in AI that go against what we want from AI in education: clear transparency and equal access for everyone. These biases can impact families and children's schooling, highlighting the need for better AI solutions that offer fair opportunities to all. This chapter tries to shed light on the complex ways AI operates, especially concerning biases. These are the foundational steps towards better educational policies, which include using AI in ways that are more reliable, accountable, and beneficial for everyone involved.",
    "authors": [
      "Supriya Manna",
      "Niladri Sett"
    ],
    "published": "2024-07-31",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2408.00025v3",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2112.01298v2",
    "title": "Meaningful human control: actionable properties for AI system development",
    "summary": "How can humans remain in control of artificial intelligence (AI)-based systems designed to perform tasks autonomously? Such systems are increasingly ubiquitous, creating benefits - but also undesirable situations where moral responsibility for their actions cannot be properly attributed to any particular person or group. The concept of meaningful human control has been proposed to address responsibility gaps and mitigate them by establishing conditions that enable a proper attribution of responsibility for humans; however, clear requirements for researchers, designers, and engineers are yet inexistent, making the development of AI-based systems that remain under meaningful human control challenging. In this paper, we address the gap between philosophical theory and engineering practice by identifying, through an iterative process of abductive thinking, four actionable properties for AI-based systems under meaningful human control, which we discuss making use of two applications scenarios: automated vehicles and AI-based hiring. First, a system in which humans and AI algorithms interact should have an explicitly defined domain of morally loaded situations within which the system ought to operate. Second, humans and AI agents within the system should have appropriate and mutually compatible representations. Third, responsibility attributed to a human should be commensurate with that human's ability and authority to control the system. Fourth, there should be explicit links betw",
    "authors": [
      "Luciano Cavalcante Siebert",
      "Maria Luce Lupetti",
      "Evgeni Aizenberg",
      "Niek Beckers",
      "Arkady Zgonnikov",
      "Herman Veluwenkamp",
      "David Abbink",
      "Elisa Giaccardi",
      "Geert-Jan Houben",
      "Catholijn M. Jonker"
    ],
    "published": "2021-11-25",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2112.01298v2",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2407.00662v2",
    "title": "Multi-Agent Training for Pommerman: Curriculum Learning and Population-based Self-Play Approach",
    "summary": "Pommerman is a multi-agent environment that has received considerable attention from researchers in recent years. This environment is an ideal benchmark for multi-agent training, providing a battleground for two teams with communication capabilities among allied agents. Pommerman presents significant challenges for model-free reinforcement learning due to delayed action effects, sparse rewards, and false positives, where opponent players can lose due to their own mistakes. This study introduces a system designed to train multi-agent systems to play Pommerman using a combination of curriculum learning and population-based self-play. We also tackle two challenging problems when deploying the multi-agent training system for competitive games: sparse reward and suitable matchmaking mechanism. Specifically, we propose an adaptive annealing factor based on agents' performance to adjust the dense exploration reward during training dynamically. Additionally, we implement a matchmaking mechanism utilizing the Elo rating system to pair agents effectively. Our experimental results demonstrate that our trained agent can outperform top learning agents without requiring communication among allied agents.",
    "authors": [
      "Nhat-Minh Huynh",
      "Hoang-Giang Cao",
      "I-Chen Wu"
    ],
    "published": "2024-06-30",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2407.00662v2",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2108.13296v1",
    "title": "Multi-Agent Simulation for AI Behaviour Discovery in Operations Research",
    "summary": "We describe ACE0, a lightweight platform for evaluating the suitability and viability of AI methods for behaviour discovery in multiagent simulations. Specifically, ACE0 was designed to explore AI methods for multi-agent simulations used in operations research studies related to new technologies such as autonomous aircraft. Simulation environments used in production are often high-fidelity, complex, require significant domain knowledge and as a result have high R&amp;D costs. Minimal and lightweight simulation environments can help researchers and engineers evaluate the viability of new AI technologies for behaviour discovery in a more agile and potentially cost effective manner. In this paper we describe the motivation for the development of ACE0.We provide a technical overview of the system architecture, describe a case study of behaviour discovery in the aerospace domain, and provide a qualitative evaluation of the system. The evaluation includes a brief description of collaborative research projects with academic partners, exploring different AI behaviour discovery methods.",
    "authors": [
      "Michael Papasimeon",
      "Lyndon Benke"
    ],
    "published": "2021-08-30",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2108.13296v1",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2208.01769v1",
    "title": "Deep Reinforcement Learning for Multi-Agent Interaction",
    "summary": "The development of autonomous agents which can interact with other agents to accomplish a given task is a core area of research in artificial intelligence and machine learning. Towards this goal, the Autonomous Agents Research Group develops novel machine learning algorithms for autonomous systems control, with a specific focus on deep reinforcement learning and multi-agent reinforcement learning. Research problems include scalable learning of coordinated agent policies and inter-agent communication; reasoning about the behaviours, goals, and composition of other agents from limited observations; and sample-efficient learning based on intrinsic motivation, curriculum learning, causal inference, and representation learning. This article provides a broad overview of the ongoing research portfolio of the group and discusses open problems for future directions.",
    "authors": [
      "Ibrahim H. Ahmed",
      "Cillian Brewitt",
      "Ignacio Carlucho",
      "Filippos Christianos",
      "Mhairi Dunion",
      "Elliot Fosong",
      "Samuel Garcin",
      "Shangmin Guo",
      "Balint Gyevnar",
      "Trevor McInroe"
    ],
    "published": "2022-08-02",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2208.01769v1",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2601.10758v1",
    "title": "Too Helpful to Be Safe: User-Mediated Attacks on Planning and Web-Use Agents",
    "summary": "Large Language Models (LLMs) have enabled agents to move beyond conversation toward end-to-end task execution and become more helpful. However, this helpfulness introduces new security risks stem less from direct interface abuse than from acting on user-provided content. Existing studies on agent security largely focus on model-internal vulnerabilities or adversarial access to agent interfaces, overlooking attacks that exploit users as unintended conduits. In this paper, we study user-mediated attacks, where benign users are tricked into relaying untrusted or attacker-controlled content to agents, and analyze how commercial LLM agents respond under such conditions. We conduct a systematic evaluation of 12 commercial agents in a sandboxed environment, covering 6 trip-planning agents and 6 web-use agents, and compare agent behavior across scenarios with no, soft, and hard user-requested safety checks. Our results show that agents are too helpful to be safe by default. Without explicit safety requests, trip-planning agents bypass safety constraints in over 92% of cases, converting unverified content into confident booking guidance. Web-use agents exhibit near-deterministic execution of risky actions, with 9 out of 17 supported tests reaching a 100% bypass rate. Even when users express soft or hard safety intent, constraint bypass remains substantial, reaching up to 54.7% and 7% for trip-planning agents, respectively. These findings reveal that the primary issue is not a lack of ",
    "authors": [
      "Fengchao Chen",
      "Tingmin Wu",
      "Van Nguyen",
      "Carsten Rudolph"
    ],
    "published": "2026-01-14",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2601.10758v1",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1503.07220v2",
    "title": "Individual Planning in Agent Populations: Exploiting Anonymity and Frame-Action Hypergraphs",
    "summary": "Interactive partially observable Markov decision processes (I-POMDP) provide a formal framework for planning for a self-interested agent in multiagent settings. An agent operating in a multiagent environment must deliberate about the actions that other agents may take and the effect these actions have on the environment and the rewards it receives. Traditional I-POMDPs model this dependence on the actions of other agents using joint action and model spaces. Therefore, the solution complexity grows exponentially with the number of agents thereby complicating scalability. In this paper, we model and extend anonymity and context-specific independence -- problem structures often present in agent populations -- for computational gain. We empirically demonstrate the efficiency from exploiting these problem structures by solving a new multiagent problem involving more than 1,000 agents.",
    "authors": [
      "Ekhlas Sonu",
      "Yingke Chen",
      "Prashant Doshi"
    ],
    "published": "2015-03-24",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1503.07220v2",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2412.20505v1",
    "title": "Planning, Living and Judging: A Multi-agent LLM-based Framework for Cyclical Urban Planning",
    "summary": "Urban regeneration presents significant challenges within the context of urbanization, requiring adaptive approaches to tackle evolving needs. Leveraging advancements in large language models (LLMs), we propose Cyclical Urban Planning (CUP), a new paradigm that continuously generates, evaluates, and refines urban plans in a closed-loop. Specifically, our multi-agent LLM-based framework consists of three key components: (1) Planning, where LLM agents generate and refine urban plans based on contextual data; (2) Living, where agents simulate the behaviors and interactions of residents, modeling life in the urban environment; and (3) Judging, which involves evaluating plan effectiveness and providing iterative feedback for improvement. The cyclical process enables a dynamic and responsive planning approach. Experiments on the real-world dataset demonstrate the effectiveness of our framework as a continuous and adaptive planning process.",
    "authors": [
      "Hang Ni",
      "Yuzhi Wang",
      "Hao Liu"
    ],
    "published": "2024-12-29",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2412.20505v1",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2306.07353v1",
    "title": "HDDL 2.1: Towards Defining a Formalism and a Semantics for Temporal HTN Planning",
    "summary": "Real world applications as in industry and robotics need modelling rich and diverse automated planning problems. Their resolution usually requires coordinated and concurrent action execution. In several cases, these problems are naturally decomposed in a hierarchical way and expressed by a Hierarchical Task Network (HTN) formalism.\n  HDDL, a hierarchical extension of the Planning Domain Definition Language (PDDL), unlike PDDL 2.1 does not allow to represent planning problems with numerical and temporal constraints, which are essential for real world applications. We propose to fill the gap between HDDL and these operational needs and to extend HDDL by taking inspiration from PDDL 2.1 in order to express numerical and temporal expressions. This paper opens discussions on the semantics and the syntax needed for a future HDDL 2.1 extension.",
    "authors": [
      "Damien Pellier",
      "Alexandre Albore",
      "Humbert Fiorino",
      "Rafael Bailon-Ruiz"
    ],
    "published": "2023-06-12",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2306.07353v1",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2011.01774v1",
    "title": "Provenance-Based Assessment of Plans in Context",
    "summary": "Many real-world planning domains involve diverse information sources, external entities, and variable-reliability agents, all of which may impact the confidence, risk, and sensitivity of plans. Humans reviewing a plan may lack context about these factors; however, this information is available during the domain generation, which means it can also be interwoven into the planner and its resulting plans. This paper presents a provenance-based approach to explaining automated plans. Our approach (1) extends the SHOP3 HTN planner to generate dependency information, (2) transforms the dependency information into an established PROV-O representation, and (3) uses graph propagation and TMS-inspired algorithms to support dynamic and counter-factual assessment of information flow, confidence, and support. We qualified our approach's explanatory scope with respect to explanation targets from the automated planning literature and the information analysis literature, and we demonstrate its ability to assess a plan's pertinence, sensitivity, risk, assumption support, diversity, and relative confidence.",
    "authors": [
      "Scott E. Friedman",
      "Robert P. Goldman",
      "Richard G. Freedman",
      "Ugur Kuter",
      "Christopher Geib",
      "Jeffrey Rye"
    ],
    "published": "2020-11-03",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2011.01774v1",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2512.24957v2",
    "title": "AMAP Agentic Planning Technical Report",
    "summary": "We present STAgent, an agentic large language model tailored for spatio-temporal understanding, designed to solve complex tasks such as constrained point-of-interest discovery and itinerary planning. STAgent is a specialized model capable of interacting with ten distinct tools within spatio-temporal scenarios, enabling it to explore, verify, and refine intermediate steps during complex reasoning. Notably, STAgent effectively preserves its general capabilities. We empower STAgent with these capabilities through three key contributions: (1) a stable tool environment that supports over ten domain-specific tools, enabling asynchronous rollout and training; (2) a hierarchical data curation framework that identifies high-quality data like a needle in a haystack, curating high-quality queries by retaining less than 1\\% of the raw data, emphasizing both diversity and difficulty; and (3) a cascaded training recipe that starts with a seed SFT stage acting as a guardian to measure query difficulty, followed by a second SFT stage fine-tuned on queries with high certainty, and an ultimate RL stage that leverages data of low certainty. Initialized with Qwen3-30B-A3B to establish a strong SFT foundation and leverage insights into sample difficulty, STAgent yields promising performance on TravelBench while maintaining its general capabilities across a wide range of general benchmarks, thereby demonstrating the effectiveness of our proposed agentic model.",
    "authors": [
      " AMAP AI Agent Team",
      "Yulan Hu",
      "Xiangwen Zhang",
      "Sheng Ouyang",
      "Hao Yi",
      "Lu Xu",
      "Qinglin Lang",
      "Lide Tan",
      "Xiang Cheng",
      "Tianchen Ye"
    ],
    "published": "2025-12-31",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2512.24957v2",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2110.02480v1",
    "title": "Efficient Multi-agent Epistemic Planning: Teaching Planners About Nested Belief",
    "summary": "Many AI applications involve the interaction of multiple autonomous agents, requiring those agents to reason about their own beliefs, as well as those of other agents. However, planning involving nested beliefs is known to be computationally challenging. In this work, we address the task of synthesizing plans that necessitate reasoning about the beliefs of other agents. We plan from the perspective of a single agent with the potential for goals and actions that involve nested beliefs, non-homogeneous agents, co-present observations, and the ability for one agent to reason as if it were another. We formally characterize our notion of planning with nested belief, and subsequently demonstrate how to automatically convert such problems into problems that appeal to classical planning technology for solving efficiently. Our approach represents an important step towards applying the well-established field of automated planning to the challenging task of planning involving nested beliefs of multiple agents.",
    "authors": [
      "Christian Muise",
      "Vaishak Belle",
      "Paolo Felli",
      "Sheila McIlraith",
      "Tim Miller",
      "Adrian R. Pearce",
      "Liz Sonenberg"
    ],
    "published": "2021-10-06",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2110.02480v1",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1709.04517v2",
    "title": "Visualizations for an Explainable Planning Agent",
    "summary": "In this paper, we report on the visualization capabilities of an Explainable AI Planning (XAIP) agent that can support human in the loop decision making. Imposing transparency and explainability requirements on such agents is especially important in order to establish trust and common ground with the end-to-end automated planning system. Visualizing the agent's internal decision-making processes is a crucial step towards achieving this. This may include externalizing the \"brain\" of the agent -- starting from its sensory inputs, to progressively higher order decisions made by it in order to drive its planning components. We also show how the planner can bootstrap on the latest techniques in explainable planning to cast plan visualization as a plan explanation problem, and thus provide concise model-based visualization of its plans. We demonstrate these functionalities in the context of the automated planning components of a smart assistant in an instrumented meeting space.",
    "authors": [
      "Tathagata Chakraborti",
      "Kshitij P. Fadnis",
      "Kartik Talamadupula",
      "Mishal Dholakia",
      "Biplav Srivastava",
      "Jeffrey O. Kephart",
      "Rachel K. E. Bellamy"
    ],
    "published": "2017-09-13",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1709.04517v2",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2008.00969v2",
    "title": "Predicted Composite Signed-Distance Fields for Real-Time Motion Planning in Dynamic Environments",
    "summary": "We present a novel framework for motion planning in dynamic environments that accounts for the predicted trajectories of moving objects in the scene. We explore the use of composite signed-distance fields in motion planning and detail how they can be used to generate signed-distance fields (SDFs) in real-time to incorporate predicted obstacle motions. We benchmark our approach of using composite SDFs against performing exact SDF calculations on the workspace occupancy grid. Our proposed technique generates predictions substantially faster and typically exhibits an 81--97% reduction in time for subsequent predictions. We integrate our framework with GPMP2 to demonstrate a full implementation of our approach in real-time, enabling a 7-DoF Panda arm to smoothly avoid a moving robot.",
    "authors": [
      "Mark Nicholas Finean",
      "Wolfgang Merkt",
      "Ioannis Havoutis"
    ],
    "published": "2020-08-03",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2008.00969v2",
    "categories": [
      "cs.RO",
      "eess.SY"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2501.08068v2",
    "title": "A Roadmap to Guide the Integration of LLMs in Hierarchical Planning",
    "summary": "Recent advances in Large Language Models (LLMs) are fostering their integration into several reasoning-related fields, including Automated Planning (AP). However, their integration into Hierarchical Planning (HP), a subfield of AP that leverages hierarchical knowledge to enhance planning performance, remains largely unexplored. In this preliminary work, we propose a roadmap to address this gap and harness the potential of LLMs for HP. To this end, we present a taxonomy of integration methods, exploring how LLMs can be utilized within the HP life cycle. Additionally, we provide a benchmark with a standardized dataset for evaluating the performance of future LLM-based HP approaches, and present initial results for a state-of-the-art HP planner and LLM planner. As expected, the latter exhibits limited performance (3\\% correct plans, and none with a correct hierarchical decomposition) but serves as a valuable baseline for future approaches.",
    "authors": [
      "Israel Puerta-Merino",
      "Carlos Núñez-Molina",
      "Pablo Mesejo",
      "Juan Fernández-Olivares"
    ],
    "published": "2025-01-14",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2501.08068v2",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2512.18950v1",
    "title": "Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement",
    "summary": "We present MACLA, a framework that decouples reasoning from learning by maintaining a frozen large language model while performing all adaptation in an external hierarchical procedural memory. MACLA extracts reusable procedures from trajectories, tracks reliability via Bayesian posteriors, selects actions through expected-utility scoring, and refines procedures by contrasting successes and failures. Across four benchmarks (ALFWorld, WebShop, TravelPlanner, InterCodeSQL), MACLA achieves 78.1 percent average performance, outperforming all baselines. On ALFWorld unseen tasks, MACLA reaches 90.3 percent with 3.1 percent positive generalization. The system constructs memory in 56 seconds, 2800 times faster than the state-of-the-art LLM parameter-training baseline, compressing 2851 trajectories into 187 procedures. Experimental results demonstrate that structured external memory with Bayesian selection and contrastive refinement enables sample-efficient, interpretable, and continually improving agents without LLM parameter updates.",
    "authors": [
      "Saman Forouzandeh",
      "Wei Peng",
      "Parham Moradi",
      "Xinghuo Yu",
      "Mahdi Jalili"
    ],
    "published": "2025-12-22",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2512.18950v1",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2404.19065v1",
    "title": "HELPER-X: A Unified Instructable Embodied Agent to Tackle Four Interactive Vision-Language Domains with Memory-Augmented Language Models",
    "summary": "Recent research on instructable agents has used memory-augmented Large Language Models (LLMs) as task planners, a technique that retrieves language-program examples relevant to the input instruction and uses them as in-context examples in the LLM prompt to improve the performance of the LLM in inferring the correct action and task plans. In this technical report, we extend the capabilities of HELPER, by expanding its memory with a wider array of examples and prompts, and by integrating additional APIs for asking questions. This simple expansion of HELPER into a shared memory enables the agent to work across the domains of executing plans from dialogue, natural language instruction following, active question asking, and commonsense room reorganization. We evaluate the agent on four diverse interactive visual-language embodied agent benchmarks: ALFRED, TEACh, DialFRED, and the Tidy Task. HELPER-X achieves few-shot, state-of-the-art performance across these benchmarks using a single agent, without requiring in-domain training, and remains competitive with agents that have undergone in-domain training.",
    "authors": [
      "Gabriel Sarch",
      "Sahil Somani",
      "Raghav Kapoor",
      "Michael J. Tarr",
      "Katerina Fragkiadaki"
    ],
    "published": "2024-04-29",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2404.19065v1",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2512.15790v1",
    "title": "Bilevel Optimization for Covert Memory Tampering in Heterogeneous Multi-Agent Architectures (XAMT)",
    "summary": "The increasing operational reliance on complex Multi-Agent Systems (MAS) across safety-critical domains necessitates rigorous adversarial robustness assessment. Modern MAS are inherently heterogeneous, integrating conventional Multi-Agent Reinforcement Learning (MARL) with emerging Large Language Model (LLM) agent architectures utilizing Retrieval-Augmented Generation (RAG). A critical shared vulnerability is reliance on centralized memory components: the shared Experience Replay (ER) buffer in MARL and the external Knowledge Base (K) in RAG agents. This paper proposes XAMT (Bilevel Optimization for Covert Memory Tampering in Heterogeneous Multi-Agent Architectures), a novel framework that formalizes attack generation as a bilevel optimization problem. The Upper Level minimizes perturbation magnitude (delta) to enforce covertness while maximizing system behavior divergence toward an adversary-defined target (Lower Level). We provide rigorous mathematical instantiations for CTDE MARL algorithms and RAG-based LLM agents, demonstrating that bilevel optimization uniquely crafts stealthy, minimal-perturbation poisons evading detection heuristics. Comprehensive experimental protocols utilize SMAC and SafeRAG benchmarks to quantify effectiveness at sub-percent poison rates (less than or equal to 1 percent in MARL, less than or equal to 0.1 percent in RAG). XAMT defines a new unified class of training-time threats essential for developing intrinsically secure MAS, with implications f",
    "authors": [
      "Akhil Sharma",
      "Shaikh Yaser Arafat",
      "Jai Kumar Sharma",
      "Ken Huang"
    ],
    "published": "2025-12-15",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2512.15790v1",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2504.08525v4",
    "title": "Task Memory Engine (TME): Enhancing State Awareness for Multi-Step LLM Agent Tasks",
    "summary": "Large Language Models (LLMs) are increasingly used as autonomous agents for multi-step tasks. However, most existing frameworks fail to maintain a structured understanding of the task state, often relying on linear prompt concatenation or shallow memory buffers. This leads to brittle performance, frequent hallucinations, and poor long-range coherence. In this work, we propose the Task Memory Engine (TME), a lightweight and structured memory module that tracks task execution using a hierarchical Task Memory Tree (TMT). Each node in the tree corresponds to a task step, storing relevant input, output, status, and sub-task relationships. We introduce a prompt synthesis method that dynamically generates LLM prompts based on the active node path, significantly improving execution consistency and contextual grounding. Through case studies and comparative experiments on multi-step agent tasks, we demonstrate that TME leads to better task completion accuracy and more interpretable behavior with minimal implementation overhead. A reference implementation of the core TME components is available at https://github.com/biubiutomato/TME-Agent, including basic examples and structured memory integration. While the current implementation uses a tree-based structure, TME is designed to be graph-aware, supporting reusable substeps, converging task paths, and shared dependencies. This lays the groundwork for future DAG-based memory architectures.",
    "authors": [
      "Ye Ye"
    ],
    "published": "2025-04-11",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2504.08525v4",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2502.13172v2",
    "title": "Unveiling Privacy Risks in LLM Agent Memory",
    "summary": "Large Language Model (LLM) agents have become increasingly prevalent across various real-world applications. They enhance decision-making by storing private user-agent interactions in the memory module for demonstrations, introducing new privacy risks for LLM agents. In this work, we systematically investigate the vulnerability of LLM agents to our proposed Memory EXTRaction Attack (MEXTRA) under a black-box setting. To extract private information from memory, we propose an effective attacking prompt design and an automated prompt generation method based on different levels of knowledge about the LLM agent. Experiments on two representative agents demonstrate the effectiveness of MEXTRA. Moreover, we explore key factors influencing memory leakage from both the agent designer's and the attacker's perspectives. Our findings highlight the urgent need for effective memory safeguards in LLM agent design and deployment.",
    "authors": [
      "Bo Wang",
      "Weiyi He",
      "Shenglai Zeng",
      "Zhen Xiang",
      "Yue Xing",
      "Jiliang Tang",
      "Pengfei He"
    ],
    "published": "2025-02-17",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2502.13172v2",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2412.09645v3",
    "title": "Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models",
    "summary": "Recent advancements in visual generative models have enabled high-quality image and video generation, opening diverse applications. However, evaluating these models often demands sampling hundreds or thousands of images or videos, making the process computationally expensive, especially for diffusion-based models with inherently slow sampling. Moreover, existing evaluation methods rely on rigid pipelines that overlook specific user needs and provide numerical results without clear explanations. In contrast, humans can quickly form impressions of a model's capabilities by observing only a few samples. To mimic this, we propose the Evaluation Agent framework, which employs human-like strategies for efficient, dynamic, multi-round evaluations using only a few samples per round, while offering detailed, user-tailored analyses. It offers four key advantages: 1) efficiency, 2) promptable evaluation tailored to diverse user needs, 3) explainability beyond single numerical scores, and 4) scalability across various models and tools. Experiments show that Evaluation Agent reduces evaluation time to 10% of traditional methods while delivering comparable results. The Evaluation Agent framework is fully open-sourced to advance research in visual generative models and their efficient evaluation.",
    "authors": [
      "Fan Zhang",
      "Shulin Tian",
      "Ziqi Huang",
      "Yu Qiao",
      "Ziwei Liu"
    ],
    "published": "2024-12-10",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2412.09645v3",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2502.09809v1",
    "title": "AgentGuard: Repurposing Agentic Orchestrator for Safety Evaluation of Tool Orchestration",
    "summary": "The integration of tool use into large language models (LLMs) enables agentic systems with real-world impact. In the meantime, unlike standalone LLMs, compromised agents can execute malicious workflows with more consequential impact, signified by their tool-use capability. We propose AgentGuard, a framework to autonomously discover and validate unsafe tool-use workflows, followed by generating safety constraints to confine the behaviors of agents, achieving the baseline of safety guarantee at deployment. AgentGuard leverages the LLM orchestrator's innate capabilities - knowledge of tool functionalities, scalable and realistic workflow generation, and tool execution privileges - to act as its own safety evaluator. The framework operates through four phases: identifying unsafe workflows, validating them in real-world execution, generating safety constraints, and validating constraint efficacy. The output, an evaluation report with unsafe workflows, test cases, and validated constraints, enables multiple security applications. We empirically demonstrate AgentGuard's feasibility with experiments. With this exploratory work, we hope to inspire the establishment of standardized testing and hardening procedures for LLM agents to enhance their trustworthiness in real-world applications.",
    "authors": [
      "Jizhou Chen",
      "Samuel Lee Cong"
    ],
    "published": "2025-02-13",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2502.09809v1",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2509.21557v2",
    "title": "Generation-Time vs. Post-hoc Citation: A Holistic Evaluation of LLM Attribution",
    "summary": "Trustworthy Large Language Models (LLMs) must cite human-verifiable sources in high-stakes domains such as healthcare, law, academia, and finance, where even small errors can have severe consequences. Practitioners and researchers face a choice: let models generate citations during decoding, or let models draft answers first and then attach appropriate citations. To clarify this choice, we introduce two paradigms: Generation-Time Citation (G-Cite), which produces the answer and citations in one pass, and Post-hoc Citation (P-Cite), which adds or verifies citations after drafting. We conduct a comprehensive evaluation from zero-shot to advanced retrieval-augmented methods across four popular attribution datasets and provide evidence-based recommendations that weigh trade-offs across use cases. Our results show a consistent trade-off between coverage and citation correctness, with retrieval as the main driver of attribution quality in both paradigms. P-Cite methods achieve high coverage with competitive correctness and moderate latency, whereas G-Cite methods prioritize precision at the cost of coverage and speed. We recommend a retrieval-centric, P-Cite-first approach for high-stakes applications, reserving G-Cite for precision-critical settings such as strict claim verification. Our codes and human evaluation results are available at https://anonymous.4open.science/r/Citation_Paradigms-BBB5/",
    "authors": [
      "Yash Saxena",
      "Raviteja Bommireddy",
      "Ankur Padia",
      "Manas Gaur"
    ],
    "published": "2025-09-25",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2509.21557v2",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2509.13978v2",
    "title": "LLM Agents for Interactive Workflow Provenance: Reference Architecture and Evaluation Methodology",
    "summary": "Modern scientific discovery increasingly relies on workflows that process data across the Edge, Cloud, and High Performance Computing (HPC) continuum. Comprehensive and in-depth analyses of these data are critical for hypothesis validation, anomaly detection, reproducibility, and impactful findings. Although workflow provenance techniques support such analyses, at large scale, the provenance data become complex and difficult to analyze. Existing systems depend on custom scripts, structured queries, or static dashboards, limiting data interaction. In this work, we introduce an evaluation methodology, reference architecture, and open-source implementation that leverages interactive Large Language Model (LLM) agents for runtime data analysis. Our approach uses a lightweight, metadata-driven design that translates natural language into structured provenance queries. Evaluations across LLaMA, GPT, Gemini, and Claude, covering diverse query classes and a real-world chemistry workflow, show that modular design, prompt tuning, and Retrieval-Augmented Generation (RAG) enable accurate and insightful LLM agent responses beyond recorded provenance.",
    "authors": [
      "Renan Souza",
      "Timothy Poteet",
      "Brian Etz",
      "Daniel Rosendo",
      "Amal Gueroudji",
      "Woong Shin",
      "Prasanna Balaprakash",
      "Rafael Ferreira da Silva"
    ],
    "published": "2025-09-17",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2509.13978v2",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2601.11903v1",
    "title": "AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems",
    "summary": "Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.\n  Keywords Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight",
    "authors": [
      "YenTing Lee",
      "Keerthi Koneru",
      "Zahra Moslemi",
      "Sheethal Kumar",
      "Ramesh Radhakrishnan"
    ],
    "published": "2026-01-17",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2601.11903v1",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2311.18580v2",
    "title": "FFT: Towards Harmlessness Evaluation and Analysis for LLMs with Factuality, Fairness, Toxicity",
    "summary": "The widespread of generative artificial intelligence has heightened concerns about the potential harms posed by AI-generated texts, primarily stemming from factoid, unfair, and toxic content. Previous researchers have invested much effort in assessing the harmlessness of generative language models. However, existing benchmarks are struggling in the era of large language models (LLMs), due to the stronger language generation and instruction following capabilities, as well as wider applications. In this paper, we propose FFT, a new benchmark with 2116 elaborated-designed instances, for LLM harmlessness evaluation with factuality, fairness, and toxicity. To investigate the potential harms of LLMs, we evaluate 9 representative LLMs covering various parameter scales, training stages, and creators. Experiments show that the harmlessness of LLMs is still under-satisfactory, and extensive analysis derives some insightful findings that could inspire future research for harmless LLM research.",
    "authors": [
      "Shiyao Cui",
      "Zhenyu Zhang",
      "Yilong Chen",
      "Wenyuan Zhang",
      "Tianyun Liu",
      "Siqi Wang",
      "Tingwen Liu"
    ],
    "published": "2023-11-30",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2311.18580v2",
    "categories": [
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2510.01295v1",
    "title": "The Social Laboratory: A Psychometric Framework for Multi-Agent LLM Evaluation",
    "summary": "As Large Language Models (LLMs) transition from static tools to autonomous agents, traditional evaluation benchmarks that measure performance on downstream tasks are becoming insufficient. These methods fail to capture the emergent social and cognitive dynamics that arise when agents communicate, persuade, and collaborate in interactive environments. To address this gap, we introduce a novel evaluation framework that uses multi-agent debate as a controlled \"social laboratory\" to discover and quantify these behaviors. In our framework, LLM-based agents, instantiated with distinct personas and incentives, deliberate on a wide range of challenging topics under the supervision of an LLM moderator. Our analysis, enabled by a new suite of psychometric and semantic metrics, reveals several key findings. Across hundreds of debates, we uncover a powerful and robust emergent tendency for agents to seek consensus, consistently reaching high semantic agreement (μ &gt; 0.88) even without explicit instruction and across sensitive topics. We show that assigned personas induce stable, measurable psychometric profiles, particularly in cognitive effort, and that the moderators persona can significantly alter debate outcomes by structuring the environment, a key finding for external AI alignment. This work provides a blueprint for a new class of dynamic, psychometrically grounded evaluation protocols designed for the agentic setting, offering a crucial methodology for understanding and shaping ",
    "authors": [
      "Zarreen Reza"
    ],
    "published": "2025-10-01",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2510.01295v1",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2408.13006v2",
    "title": "Systematic Evaluation of LLM-as-a-Judge in LLM Alignment Tasks: Explainable Metrics and Diverse Prompt Templates",
    "summary": "LLM-as-a-Judge has been widely applied to evaluate and compare different LLM alignmnet approaches (e.g., RLHF and DPO). However, concerns regarding its reliability have emerged, due to LLM judges' biases and inconsistent decision-making. Previous research has developed evaluation frameworks to assess reliability of LLM judges and their alignment with human preferences. However, the employed evaluation metrics often lack adequate explainability and fail to address LLM internal inconsistency. Additionally, existing studies inadequately explore the impact of various prompt templates when applying LLM-as-a-Judge methods, leading to potentially inconsistent comparisons between different alignment algorithms. In this work, we systematically evaluate LLM-as-a-Judge on alignment tasks by defining more theoretically interpretable evaluation metrics and explicitly mitigating LLM internal inconsistency from reliability metrics. We develop an open-source framework to evaluate, compare, and visualize the reliability and alignment of LLM judges, which facilitates practitioners to choose LLM judges for alignment tasks. In the experiments, we examine effects of diverse prompt templates on LLM-judge reliability and also demonstrate our developed framework by comparing various LLM judges on two common alignment datasets (i.e., TL;DR Summarization and HH-RLHF-Helpfulness). Our results indicate a significant impact of prompt templates on LLM judge performance, as well as a mediocre alignment lev",
    "authors": [
      "Hui Wei",
      "Shenghua He",
      "Tian Xia",
      "Fei Liu",
      "Andy Wong",
      "Jingyang Lin",
      "Mei Han"
    ],
    "published": "2024-08-23",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2408.13006v2",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2511.15755v2",
    "title": "Multi-Agent LLM Orchestration Achieves Deterministic, High-Quality Decision Support for Incident Response",
    "summary": "Large language models (LLMs) promise to accelerate incident response in production systems, yet single-agent approaches generate vague, unusable recommendations. We present MyAntFarm.ai, a reproducible containerized framework demonstrating that multi-agent orchestration fundamentally transforms LLM-based incident response quality. Through 348 controlled trials comparing single-agent copilot versus multi-agent systems on identical incident scenarios, we find that multi-agent orchestration achieves 100% actionable recommendation rate versus 1.7% for single-agent approaches, an 80 times improvement in action specificity and 140 times improvement in solution correctness. Critically, multi-agent systems exhibit zero quality variance across all trials, enabling production SLA commitments impossible with inconsistent single-agent outputs. Both architectures achieve similar comprehension latency (approx.40s), establishing that the architectural value lies in deterministic quality, not speed. We introduce Decision Quality (DQ), a novel metric capturing validity, specificity, and correctness properties essential for operational deployment that existing LLM metrics do not address. These findings reframe multi-agent orchestration from a performance optimization to a production-readiness requirement for LLM-based incident response. All code, Docker configurations, and trial data are publicly available for reproduction.",
    "authors": [
      "Philip Drammeh"
    ],
    "published": "2025-11-19",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2511.15755v2",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2512.19769v1",
    "title": "A Declarative Language for Building And Orchestrating LLM-Powered Agent Workflows",
    "summary": "Building deployment-ready LLM agents requires complex orchestration of tools, data sources, and control flow logic, yet existing systems tightly couple agent logic to specific programming languages and deployment models. We present a declarative system that separates agent workflow specification from implementation, enabling the same pipeline definition to execute across multiple backend languages (Java, Python, Go) and deployment environments (cloud-native, on-premises).\n  Our key insight is that most agent workflows consist of common patterns -- data serialization, filtering, RAG retrieval, API orchestration -- that can be expressed through a unified DSL rather than imperative code. This approach transforms agent development from application programming to configuration, where adding new tools or fine-tuning agent behaviors requires only pipeline specification changes, not code deployment. Our system natively supports A/B testing of agent strategies, allowing multiple pipeline variants to run on the same backend infrastructure with automatic metric collection and comparison.\n  We evaluate our approach on real-world e-commerce workflows at PayPal, processing millions of daily interactions. Our results demonstrate 60% reduction in development time, and 3x improvement in deployment velocity compared to imperative implementations. The language's declarative approach enables non-engineers to modify agent behaviors safely, while maintaining sub-100ms orchestration overhead. We sh",
    "authors": [
      "Ivan Daunis"
    ],
    "published": "2025-12-22",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2512.19769v1",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2012.08866v2",
    "title": "Container Orchestration on HPC Systems",
    "summary": "Containerisation demonstrates its efficiency in application deployment in cloud computing. Containers can encapsulate complex programs with their dependencies in isolated environments, hence are being adopted in HPC clusters. HPC workload managers lack micro-services support and deeply integrated container management, as opposed to container orchestrators (e.g. Kubernetes). We introduce Torque-Operator (a plugin) which serves as a bridge between HPC workload managers and container Orchestrators.",
    "authors": [
      "Naweiluo Zhou",
      "Yiannis Georgiou",
      "Li Zhong",
      "Huan Zhou",
      "Marcin Pospieszny"
    ],
    "published": "2020-12-16",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2012.08866v2",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2601.02577v1",
    "title": "Orchestral AI: A Framework for Agent Orchestration",
    "summary": "The rapid proliferation of LLM agent frameworks has forced developers to choose between vendor lock-in through provider-specific SDKs and complex multi-package ecosystems that obscure control flow and hinder reproducibility. Integrating tool calling across multiple LLM providers remains a core engineering challenge due to fragmented APIs, incompatible message formats, and inconsistent streaming and tool-calling behavior, making it difficult to build portable, reliable agent systems. We introduce Orchestral, a lightweight Python framework that provides a unified, type-safe interface for building LLM agents across major providers while preserving the simplicity required for scientific computing and production deployment. Orchestral defines a single universal representation for messages, tools, and LLM usage that operates seamlessly across providers, eliminating manual format translation and reducing framework-induced complexity. Automatic tool schema generation from Python type hints removes the need for handwritten descriptors while maintaining type safety across provider boundaries. A synchronous execution model with streaming support enables deterministic behavior, straightforward debugging, and real-time interaction without introducing server dependencies. The framework's modular architecture cleanly separates provider integration, tool execution, conversation orchestration, and user-facing interfaces, enabling extensibility without architectural entanglement. Orchestral su",
    "authors": [
      "Alexander Roman",
      "Jacob Roman"
    ],
    "published": "2026-01-05",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2601.02577v1",
    "categories": [
      "cs.AI",
      "astro-ph.IM",
      "hep-ph"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2507.06520v1",
    "title": "Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration",
    "summary": "We present Gradientsys, a next-generation multi-agent scheduling framework that coordinates diverse specialized AI agents using a typed Model-Context Protocol (MCP) and a ReAct-based dynamic planning loop. At its core, Gradientsys employs an LLM-powered scheduler for intelligent one-to-many task dispatch, enabling parallel execution of heterogeneous agents such as PDF parsers, web search modules, GUI controllers, and web builders. The framework supports hybrid synchronous/asynchronous execution, respects agent capacity constraints, and incorporates a robust retry-and-replan mechanism to handle failures gracefully. To promote transparency and trust, Gradientsys includes an observability layer streaming real-time agent activity and intermediate reasoning via Server-Sent Events (SSE). We offer an architectural overview and evaluate Gradientsys against existing frameworks in terms of extensibility, scheduling topology, tool reusability, parallelism, and observability. Experiments on the GAIA general-assistant benchmark show that Gradientsys achieves higher task success rates with reduced latency and lower API costs compared to a MinionS-style baseline, demonstrating the strength of its LLM-driven multi-agent orchestration.",
    "authors": [
      "Xinyuan Song",
      "Zeyu Wang",
      "Siyi Wu",
      "Tianyu Shi",
      "Lynn Ai"
    ],
    "published": "2025-07-09",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2507.06520v1",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1503.06377v2",
    "title": "On Orchestrating Virtual Network Functions in NFV",
    "summary": "Middleboxes or network appliances like firewalls, proxies and WAN optimizers have become an integral part of today's ISP and enterprise networks. Middlebox functionalities are usually deployed on expensive and proprietary hardware that require trained personnel for deployment and maintenance. Middleboxes contribute significantly to a network's capital and operational costs. In addition, organizations often require their traffic to pass through a specific sequence of middleboxes for compliance with security and performance policies. This makes the middlebox deployment and maintenance tasks even more complicated. Network Function Virtualization (NFV) is an emerging and promising technology that is envisioned to overcome these challenges. It proposes to move packet processing from dedicated hardware middleboxes to software running on commodity servers. In NFV terminology, software middleboxes are referred to as Virtualized Network Functions (VNFs). It is a challenging problem to determine the required number and placement of VNFs that optimizes network operational costs and utilization, without violating service level agreements. We call this the VNF Orchestration Problem (VNF-OP) and provide an Integer Linear Programming (ILP) formulation with implementation in CPLEX. We also provide a dynamic programming based heuristic to solve larger instances of VNF-OP. Trace driven simulations on real-world network topologies demonstrate that the heuristic can provide solutions that are wi",
    "authors": [
      "Md. Faizul Bari",
      "Shihabur Rahman Chowdhury",
      "Reaz Ahmed",
      "Raouf Boutaba"
    ],
    "published": "2015-03-22",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1503.06377v2",
    "categories": [
      "cs.NI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2506.17266v1",
    "title": "Securing Generative AI Agentic Workflows: Risks, Mitigation, and a Proposed Firewall Architecture",
    "summary": "Generative Artificial Intelligence (GenAI) presents significant advancements but also introduces novel security challenges, particularly within agentic workflows where AI agents operate autonomously. These risks escalate in multi-agent systems due to increased interaction complexity. This paper outlines critical security vulnerabilities inherent in GenAI agentic workflows, including data privacy breaches, model manipulation, and issues related to agent autonomy and system integration. It discusses key mitigation strategies such as data encryption, access control, prompt engineering, model monitoring, agent sandboxing, and security audits. Furthermore, it details a proposed \"GenAI Security Firewall\" architecture designed to provide comprehensive, adaptable, and efficient protection for these systems by integrating various security services and leveraging GenAI itself for enhanced defense. Addressing these security concerns is paramount for the responsible and safe deployment of this transformative technology.",
    "authors": [
      "Sunil Kumar Jang Bahadur",
      "Gopala Dhar"
    ],
    "published": "2025-06-10",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2506.17266v1",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2508.02866v3",
    "title": "PROV-AGENT: Unified Provenance for Tracking AI Agent Interactions in Agentic Workflows",
    "summary": "Large Language Models (LLMs) and other foundation models are increasingly used as the core of AI agents. In agentic workflows, these agents plan tasks, interact with humans and peers, and influence scientific outcomes across federated and heterogeneous environments. However, agents can hallucinate or reason incorrectly, propagating errors when one agent's output becomes another's input. Thus, assuring that agents' actions are transparent, traceable, reproducible, and reliable is critical to assess hallucination risks and mitigate their workflow impacts. While provenance techniques have long supported these principles, existing methods fail to capture and relate agent-centric metadata such as prompts, responses, and decisions with the broader workflow context and downstream outcomes. In this paper, we introduce PROV-AGENT, a provenance model that extends W3C PROV and leverages the Model Context Protocol (MCP) and data observability to integrate agent interactions into end-to-end workflow provenance. Our contributions include: (1) a provenance model tailored for agentic workflows, (2) a near real-time, open-source system for capturing agentic provenance, and (3) a cross-facility evaluation spanning edge, cloud, and HPC environments, demonstrating support for critical provenance queries and agent reliability analysis.",
    "authors": [
      "Renan Souza",
      "Amal Gueroudji",
      "Stephen DeWitt",
      "Daniel Rosendo",
      "Tirthankar Ghosal",
      "Robert Ross",
      "Prasanna Balaprakash",
      "Rafael Ferreira da Silva"
    ],
    "published": "2025-08-04",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2508.02866v3",
    "categories": [
      "cs.DC",
      "cs.DB"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1905.11863v1",
    "title": "MolSSI and BioExcel Workflow Workshop 2018 Report",
    "summary": "Workflows in biomolecular science are very important as they are intricately intertwined with the scientific outcomes, as well as algorithmic and methodological innovations. The use and effectiveness of workflow tools to meet the needs of the biomolecular science community is varied. MolSSI co-organized a biomolecular workflows workshop in December 2018 with the goal of identifying specific software gaps and opportunities for improved workflow practices. This report captures presentations and discussion from that workshop. The workshop participants were primary tools developers, along with \"neutral observers\" and some biomolecular domain scientists. After contextualizing and motivating the workshop, the report covers the existing roles and emerging trends in how workflow systems are utilized. A few recurring observations are presented as recommendations for improving the use and effectiveness of workflow tools. The tools presented are discussed in Appendix B.",
    "authors": [
      "Levi N. Naden",
      "Sam Ellis",
      "Shantenu Jha"
    ],
    "published": "2019-05-28",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1905.11863v1",
    "categories": [
      "cs.SE"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2207.01222v1",
    "title": "KubeAdaptor: A Docking Framework for Workflow Containerization on Kubernetes",
    "summary": "As Kubernetes becomes the infrastructure of the cloud-native era, the integration of workflow systems with Kubernetes is gaining more and more popularity. To our knowledge, workflow systems employ scheduling algorithms that optimize task execution order of workflow to improve performance and execution efficiency. However, due to its inherent scheduling mechanism, Kubernetes does not execute containerized scheduling following the optimized task execution order of workflow amid migrating workflow systems to the Kubernetes platform. This inconsistency in task scheduling order seriously degrades the efficiency of workflow execution and brings numerous challenges to the containerized process of workflow systems on Kubernetes. In this paper, we propose a cloud-native workflow engine, also known as KubeAdaptor, a docking framework able to implement workflow containerization on Kubernetes, integrate workflow systems with Kubernetes, ensuring the consistency of task scheduling order. We introduce the design and architecture of the KubeAdaptor, elaborate on the functionality implementation and the event-trigger mechanism within the KubeAdaptor. Experimental results about four real-world workflows show that the KubeAdaptor ensures the consistency of the workflow systems and Kubernetes in the task scheduling order. Compared with the baseline Argo workflow engine, the KubeAdaptor achieves better performance in terms of the average execution time of task pod, average workflow lifecycle, an",
    "authors": [
      "Chenggang Shan",
      "Guan Wang",
      "Yuanqing Xia",
      "Yufeng Zhan",
      "Jinhui Zhang"
    ],
    "published": "2022-07-04",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2207.01222v1",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2306.09930v2",
    "title": "Flow-Bench: A Dataset for Computational Workflow Anomaly Detection",
    "summary": "A computational workflow, also known as workflow, consists of tasks that must be executed in a specific order to attain a specific goal. Often, in fields such as biology, chemistry, physics, and data science, among others, these workflows are complex and are executed in large-scale, distributed, and heterogeneous computing environments prone to failures and performance degradation. Therefore, anomaly detection for workflows is an important paradigm that aims to identify unexpected behavior or errors in workflow execution. This crucial task to improve the reliability of workflow executions can be further assisted by machine learning-based techniques. However, such application is limited, in large part, due to the lack of open datasets and benchmarking. To address this gap, we make the following contributions in this paper: (1) we systematically inject anomalies and collect raw execution logs from workflows executing on distributed infrastructures; (2) we summarize the statistics of new datasets, and provide insightful analyses; (3) we convert workflows into tabular, graph and text data, and benchmark with supervised and unsupervised anomaly detection techniques correspondingly. The presented dataset and benchmarks allow examining the effectiveness and efficiency of scientific computational workflows and identifying potential research opportunities for improvement and generalization. The dataset and benchmark code are publicly available \\url{https://poseidon-workflows.github.io",
    "authors": [
      "George Papadimitriou",
      "Hongwei Jin",
      "Cong Wang",
      "Rajiv Mayani",
      "Krishnan Raghavan",
      "Anirban Mandal",
      "Prasanna Balaprakash",
      "Ewa Deelman"
    ],
    "published": "2023-06-16",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2306.09930v2",
    "categories": [
      "cs.DC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2503.15520v1",
    "title": "Agent-S: LLM Agentic workflow to automate Standard Operating Procedures",
    "summary": "AI agents using Large Language Models (LLMs) as foundations have shown promise in solving complex real-world tasks. In this paper, we propose an LLM-based agentic workflow for automating Standard Operating Procedures (SOP). For customer care operations, an SOP defines a logical step-by-step process for human agents to resolve customer issues. We observe that any step in the SOP can be categorized as user interaction or API call, while the logical flow in the SOP defines the navigation. We use LLMs augmented with memory and environments (API tools, user interface, external knowledge source) for SOP automation. Our agentic architecture consists of three task-specific LLMs, a Global Action Repository (GAR), execution memory, and multiple environments. SOP workflow is written as a simple logical block of text. Based on the current execution memory and the SOP, the agent chooses the action to execute; it interacts with an appropriate environment (user/API) to collect observations and feedback, which are, in turn, inputted to memory to decide the next action. The agent is designed to be fault-tolerant, where it dynamically decides to repeat an action or seek input from an external knowledge source. We demonstrate the efficacy of the proposed agent on the three SOPs from the e-commerce seller domain. The experimental results validate the agent's performance under complex real-world scenarios.",
    "authors": [
      "Mandar Kulkarni"
    ],
    "published": "2025-02-03",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2503.15520v1",
    "categories": [
      "cs.HC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2511.07568v1",
    "title": "Procedural Knowledge Improves Agentic LLM Workflows",
    "summary": "Large language models (LLMs) often struggle when performing agentic tasks without substantial tool support, prom-pt engineering, or fine tuning. Despite research showing that domain-dependent, procedural knowledge can dramatically increase planning efficiency, little work evaluates its potential for improving LLM performance on agentic tasks that may require implicit planning. We formalize, implement, and evaluate an agentic LLM workflow that leverages procedural knowledge in the form of a hierarchical task network (HTN). Empirical results of our implementation show that hand-coded HTNs can dramatically improve LLM performance on agentic tasks, and using HTNs can boost a 20b or 70b parameter LLM to outperform a much larger 120b parameter LLM baseline. Furthermore, LLM-created HTNs improve overall performance, though less so. The results suggest that leveraging expertise--from humans, documents, or LLMs--to curate procedural knowledge will become another important tool for improving LLM workflows.",
    "authors": [
      "Vincent Hsiao",
      "Mark Roberts",
      "Leslie Smith"
    ],
    "published": "2025-11-10",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2511.07568v1",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2507.19543v1",
    "title": "Agent WARPP: Workflow Adherence via Runtime Parallel Personalization",
    "summary": "Large language models (LLMs) are increasingly applied in task-oriented dialogue (TOD) systems but often struggle with long, conditional workflows that involve external tool calls and depend on user-specific information. We present Workflow Adherence via Runtime Parallel Personalization, or WARPP, a training-free, modular framework that combines multi-agent orchestration with runtime personalization to improve workflow adherence in LLM-based systems. By dynamically pruning conditional branches based on user attributes, the framework reduces reasoning overhead and narrows tool selection at runtime. WARPP deploys a parallelized architecture where a dedicated Personalizer agent operates alongside modular, domain-specific agents to dynamically tailor execution paths in real time. The framework is evaluated across five representative user intents of varying complexity within three domains: banking, flights, and healthcare. Our evaluation leverages synthetic datasets and LLM-powered simulated users to test scenarios with conditional dependencies. Our results demonstrate that WARPP outperforms both the non-personalized method and the ReAct baseline, achieving increasingly larger gains in parameter fidelity and tool accuracy as intent complexity grows, while also reducing average token usage, without any additional training.",
    "authors": [
      "Maria Emilia Mazzolenis",
      "Ruirui Zhang"
    ],
    "published": "2025-07-23",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2507.19543v1",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2403.02574v1",
    "title": "ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary",
    "summary": "The literature review is an indispensable step in the research process. It provides the benefit of comprehending the research problem and understanding the current research situation while conducting a comparative analysis of prior works. However, literature summary is challenging and time consuming. The previous LLM-based studies on literature review mainly focused on the complete process, including literature retrieval, screening, and summarization. However, for the summarization step, simple CoT method often lacks the ability to provide extensive comparative summary. In this work, we firstly focus on the independent literature summarization step and introduce ChatCite, an LLM agent with human workflow guidance for comparative literature summary. This agent, by mimicking the human workflow, first extracts key elements from relevant literature and then generates summaries using a Reflective Incremental Mechanism. In order to better evaluate the quality of the generated summaries, we devised a LLM-based automatic evaluation metric, G-Score, in refer to the human evaluation criteria. The ChatCite agent outperformed other models in various dimensions in the experiments. The literature summaries generated by ChatCite can also be directly used for drafting literature reviews.",
    "authors": [
      "Yutong Li",
      "Lu Chen",
      "Aiwei Liu",
      "Kai Yu",
      "Lijie Wen"
    ],
    "published": "2024-03-05",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2403.02574v1",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2412.12881v1",
    "title": "RAG-Star: Enhancing Deliberative Reasoning with Retrieval Augmented Verification and Refinement",
    "summary": "Existing large language models (LLMs) show exceptional problem-solving capabilities but might struggle with complex reasoning tasks. Despite the successes of chain-of-thought and tree-based search methods, they mainly depend on the internal knowledge of LLMs to search over intermediate reasoning steps, limited to dealing with simple tasks involving fewer reasoning steps. In this paper, we propose \\textbf{RAG-Star}, a novel RAG approach that integrates the retrieved information to guide the tree-based deliberative reasoning process that relies on the inherent knowledge of LLMs. By leveraging Monte Carlo Tree Search, RAG-Star iteratively plans intermediate sub-queries and answers for reasoning based on the LLM itself. To consolidate internal and external knowledge, we propose an retrieval-augmented verification that utilizes query- and answer-aware reward modeling to provide feedback for the inherent reasoning of LLMs. Our experiments involving Llama-3.1-8B-Instruct and GPT-4o demonstrate that RAG-Star significantly outperforms previous RAG and reasoning methods.",
    "authors": [
      "Jinhao Jiang",
      "Jiayi Chen",
      "Junyi Li",
      "Ruiyang Ren",
      "Shijie Wang",
      "Wayne Xin Zhao",
      "Yang Song",
      "Tao Zhang"
    ],
    "published": "2024-12-17",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2412.12881v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2502.13957v2",
    "title": "RAG-Gym: Systematic Optimization of Language Agents for Retrieval-Augmented Generation",
    "summary": "Retrieval-augmented generation (RAG) has shown great promise for knowledge-intensive tasks and recently advanced with agentic RAG, where language agents engage in multi-round interactions with external knowledge sources for adaptive information retrieval. However, existing agentic RAG methods often depend on ad-hoc prompt engineering and lack a unified optimization framework. We introduce RAG-Gym, a comprehensive platform that systematically explores three optimization dimensions: (1) prompt engineering, (2) actor tuning, and (3) critic training. For prompt engineering, we propose Re$^2$Search, a novel agent incorporating reasoning reflection that significantly outperforms standard prompts. In actor tuning, we evaluate three popular post-training algorithms with fine-grained process supervision and identify direct preference optimization as the most effective. We further demonstrate that a trained critic can enhance inference by selecting higher-quality intermediate reasoning steps. Together, these findings lead to the optimized Re$^2$Search++ agent, which surpasses most recent methods like Search-R1 by a relative increase of 3.2% to 11.6% in average F1. Finally, we examine the impact of different reward sources and analyze scaling properties in training and inference, offering practical insights for agentic RAG optimization. The project homepage is available at https://rag-gym.github.io.",
    "authors": [
      "Guangzhi Xiong",
      "Qiao Jin",
      "Xiao Wang",
      "Yin Fang",
      "Haolin Liu",
      "Yifan Yang",
      "Fangyuan Chen",
      "Zhixing Song",
      "Dengyu Wang",
      "Minjia Zhang"
    ],
    "published": "2025-02-19",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2502.13957v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2402.07483v2",
    "title": "T-RAG: Lessons from the LLM Trenches",
    "summary": "Large Language Models (LLM) have shown remarkable language capabilities fueling attempts to integrate them into applications across a wide range of domains. An important application area is question answering over private enterprise documents where the main considerations are data security, which necessitates applications that can be deployed on-prem, limited computational resources and the need for a robust application that correctly responds to queries. Retrieval-Augmented Generation (RAG) has emerged as the most prominent framework for building LLM-based applications. While building a RAG is relatively straightforward, making it robust and a reliable application requires extensive customization and relatively deep knowledge of the application domain. We share our experiences building and deploying an LLM application for question answering over private organizational documents. Our application combines the use of RAG with a finetuned open-source LLM. Additionally, our system, which we call Tree-RAG (T-RAG), uses a tree structure to represent entity hierarchies within the organization. This is used to generate a textual description to augment the context when responding to user queries pertaining to entities within the organization's hierarchy. Our evaluations, including a Needle in a Haystack test, show that this combination performs better than a simple RAG or finetuning implementation. Finally, we share some lessons learned based on our experiences building an LLM applica",
    "authors": [
      "Masoomali Fatehkia",
      "Ji Kim Lucas",
      "Sanjay Chawla"
    ],
    "published": "2024-02-12",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2402.07483v2",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2502.11228v2",
    "title": "Vendi-RAG: Adaptively Trading-Off Diversity And Quality Significantly Improves Retrieval Augmented Generation With LLMs",
    "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) for domain-specific question-answering (QA) tasks by leveraging external knowledge sources. However, traditional RAG systems primarily focus on relevance-based retrieval and often struggle with redundancy, especially when reasoning requires connecting information from multiple sources. This paper introduces Vendi-RAG, a framework based on an iterative process that jointly optimizes retrieval diversity and answer quality. This joint optimization leads to significantly higher accuracy for multi-hop QA tasks. Vendi-RAG leverages the Vendi Score (VS), a flexible similarity-based diversity metric, to promote semantic diversity in document retrieval. It then uses an LLM judge that evaluates candidate answers, generated after a reasoning step, and outputs a score that the retriever uses to balance relevance and diversity among the retrieved documents during each iteration. Experiments on three challenging datasets -- HotpotQA, MuSiQue, and 2WikiMultiHopQA -- demonstrate Vendi-RAG's effectiveness in multi-hop reasoning tasks. The framework achieves significant accuracy improvements over traditional single-step and multi-step RAG approaches, with accuracy increases reaching up to +4.2% on HotpotQA, +4.1% on 2WikiMultiHopQA, and +1.3% on MuSiQue compared to Adaptive-RAG, the current best baseline. The benefits of Vendi-RAG are even more pronounced as the number of retrieved documents increases. Finally, we evalu",
    "authors": [
      "Mohammad Reza Rezaei",
      "Adji Bousso Dieng"
    ],
    "published": "2025-02-16",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2502.11228v2",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2401.15391v1",
    "title": "MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries",
    "summary": "Retrieval-augmented generation (RAG) augments large language models (LLM) by retrieving relevant knowledge, showing promising potential in mitigating LLM hallucinations and enhancing response quality, thereby facilitating the great adoption of LLMs in practice. However, we find that existing RAG systems are inadequate in answering multi-hop queries, which require retrieving and reasoning over multiple pieces of supporting evidence. Furthermore, to our knowledge, no existing RAG benchmarking dataset focuses on multi-hop queries. In this paper, we develop a novel dataset, MultiHop-RAG, which consists of a knowledge base, a large collection of multi-hop queries, their ground-truth answers, and the associated supporting evidence. We detail the procedure of building the dataset, utilizing an English news article dataset as the underlying RAG knowledge base. We demonstrate the benchmarking utility of MultiHop-RAG in two experiments. The first experiment compares different embedding models for retrieving evidence for multi-hop queries. In the second experiment, we examine the capabilities of various state-of-the-art LLMs, including GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop queries given the evidence. Both experiments reveal that existing RAG methods perform unsatisfactorily in retrieving and answering multi-hop queries. We hope MultiHop-RAG will be a valuable resource for the community in developing effective RAG systems, thereby facilitating greater adoption",
    "authors": [
      "Yixuan Tang",
      "Yi Yang"
    ],
    "published": "2024-01-27",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2401.15391v1",
    "categories": [
      "cs.CL"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2510.25518v1",
    "title": "Retrieval Augmented Generation (RAG) for Fintech: Agentic Design and Evaluation",
    "summary": "Retrieval-Augmented Generation (RAG) systems often face limitations in specialized domains such as fintech, where domain-specific ontologies, dense terminology, and acronyms complicate effective retrieval and synthesis. This paper introduces an agentic RAG architecture designed to address these challenges through a modular pipeline of specialized agents. The proposed system supports intelligent query reformulation, iterative sub-query decomposition guided by keyphrase extraction, contextual acronym resolution, and cross-encoder-based context re-ranking. We evaluate our approach against a standard RAG baseline using a curated dataset of 85 question--answer--reference triples derived from an enterprise fintech knowledge base. Experimental results demonstrate that the agentic RAG system outperforms the baseline in retrieval precision and relevance, albeit with increased latency. These findings suggest that structured, multi-agent methodologies offer a promising direction for enhancing retrieval robustness in complex, domain-specific settings.",
    "authors": [
      "Thomas Cook",
      "Richard Osuagwu",
      "Liman Tsatiashvili",
      "Vrynsia Vrynsia",
      "Koustav Ghosal",
      "Maraim Masoud",
      "Riccardo Mattivi"
    ],
    "published": "2025-10-29",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2510.25518v1",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2504.04915v1",
    "title": "Collab-RAG: Boosting Retrieval-Augmented Generation for Complex Question Answering via White-Box and Black-Box LLM Collaboration",
    "summary": "Retrieval-Augmented Generation (RAG) systems often struggle to handle multi-hop question-answering tasks accurately due to irrelevant context retrieval and limited complex reasoning capabilities. We introduce Collab-RAG, a collaborative training framework that leverages mutual enhancement between a white-box small language model (SLM) and a blackbox large language model (LLM) for RAG. Specifically, the SLM decomposes complex queries into simpler sub-questions, thus enhancing the accuracy of the retrieval and facilitating more effective reasoning by the black-box LLM. Concurrently, the black-box LLM provides feedback signals to improve the SLM's decomposition capability. We observe that Collab-RAG relies solely on supervision from an affordable black-box LLM without additional distillation from frontier LLMs, yet demonstrates strong generalization across multiple black-box LLMs. Experimental evaluations across five multi-hop QA datasets demonstrate that Collab-RAG substantially outperforms existing black-box-only and SLM fine-tuning baselines by 1.8%-14.2% on average. In particular, our fine-tuned 3B SLM surpasses a frozen 32B LLM in question decomposition, highlighting the efficiency of Collab-RAG in improving reasoning and retrieval for complex questions. The code of Collab-RAG is available on https://github.com/ritaranx/Collab-RAG/.",
    "authors": [
      "Ran Xu",
      "Wenqi Shi",
      "Yuchen Zhuang",
      "Yue Yu",
      "Joyce C. Ho",
      "Haoyu Wang",
      "Carl Yang"
    ],
    "published": "2025-04-07",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2504.04915v1",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2406.06575v1",
    "title": "Ask-EDA: A Design Assistant Empowered by LLM, Hybrid RAG and Abbreviation De-hallucination",
    "summary": "Electronic design engineers are challenged to find relevant information efficiently for a myriad of tasks within design construction, verification and technology development. Large language models (LLM) have the potential to help improve productivity by serving as conversational agents that effectively function as subject-matter experts. In this paper we demonstrate Ask-EDA, a chat agent designed to serve as a 24x7 expert available to provide guidance to design engineers. Ask-EDA leverages LLM, hybrid retrieval augmented generation (RAG) and abbreviation de-hallucination (ADH) techniques to deliver more relevant and accurate responses. We curated three evaluation datasets, namely q2a-100, cmds-100 and abbr-100. Each dataset is tailored to assess a distinct aspect: general design question answering, design command handling and abbreviation resolution. We demonstrated that hybrid RAG offers over a 40% improvement in Recall on the q2a-100 dataset and over a 60% improvement on the cmds-100 dataset compared to not using RAG, while ADH yields over a 70% enhancement in Recall on the abbr-100 dataset. The evaluation results show that Ask-EDA can effectively respond to design-related inquiries.",
    "authors": [
      "Luyao Shi",
      "Michael Kazda",
      "Bradley Sears",
      "Nick Shropshire",
      "Ruchir Puri"
    ],
    "published": "2024-06-03",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2406.06575v1",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2504.01346v4",
    "title": "RAG over Tables: Hierarchical Memory Index, Multi-Stage Retrieval, and Benchmarking",
    "summary": "Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by integrating them with an external knowledge base to improve the answer relevance and accuracy. In real-world scenarios, beyond pure text, a substantial amount of knowledge is stored in tables, and user questions often require retrieving answers that are distributed across multiple tables. Retrieving knowledge from a table corpora (i.e., various individual tables) for a question remains nascent, at least, for (i) how to understand intra- and inter-table knowledge effectively, (ii) how to filter unnecessary tables and how to retrieve the most relevant tables efficiently, (iii) how to prompt LLMs to infer over the retrieval, (iv) how to evaluate the corresponding performance in a realistic setting. Facing the above challenges, in this paper, we first propose a table-corpora-aware RAG framework, named T-RAG, which consists of the hierarchical memory index, multi-stage retrieval, and graph-aware prompting for effective and efficient table knowledge retrieval and inference. Further, we first develop a multi-table question answering benchmark named MultiTableQA, which spans 3 different task types, 57,193 tables, and 23,758 questions in total, and the sources are all from real-world scenarios. Based on MultiTableQA, we did the holistic comparison over table retrieval methods, RAG methods, and table-to-graph representation learning methods, where T-RAG shows the leading accuracy, recall, and running time per",
    "authors": [
      "Jiaru Zou",
      "Dongqi Fu",
      "Sirui Chen",
      "Xinrui He",
      "Zihao Li",
      "Yada Zhu",
      "Jiawei Han",
      "Jingrui He"
    ],
    "published": "2025-04-02",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2504.01346v4",
    "categories": [
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2409.03708v2",
    "title": "RAG based Question-Answering for Contextual Response Prediction System",
    "summary": "Large Language Models (LLMs) have shown versatility in various Natural Language Processing (NLP) tasks, including their potential as effective question-answering systems. However, to provide precise and relevant information in response to specific customer queries in industry settings, LLMs require access to a comprehensive knowledge base to avoid hallucinations. Retrieval Augmented Generation (RAG) emerges as a promising technique to address this challenge. Yet, developing an accurate question-answering framework for real-world applications using RAG entails several challenges: 1) data availability issues, 2) evaluating the quality of generated content, and 3) the costly nature of human evaluation. In this paper, we introduce an end-to-end framework that employs LLMs with RAG capabilities for industry use cases. Given a customer query, the proposed system retrieves relevant knowledge documents and leverages them, along with previous chat history, to generate response suggestions for customer service agents in the contact centers of a major retail company. Through comprehensive automated and human evaluations, we show that this solution outperforms the current BERT-based algorithms in accuracy and relevance. Our findings suggest that RAG-based LLMs can be an excellent support to human customer service representatives by lightening their workload.",
    "authors": [
      "Sriram Veturi",
      "Saurabh Vaichal",
      "Reshma Lal Jagadheesh",
      "Nafis Irtiza Tripto",
      "Nian Yan"
    ],
    "published": "2024-09-05",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2409.03708v2",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2601.07504v1",
    "title": "FROAV: A Framework for RAG Observation and Agent Verification -- Lowering the Barrier to LLM Agent Research",
    "summary": "The rapid advancement of Large Language Models (LLMs) and their integration into autonomous agent systems has created unprecedented opportunities for document analysis, decision support, and knowledge retrieval. However, the complexity of developing, evaluating, and iterating on LLM-based agent workflows presents significant barriers to researchers, particularly those without extensive software engineering expertise. We present FROAV (Framework for RAG Observation and Agent Verification), an open-source research platform that democratizes LLM agent research by providing a plug-and-play architecture combining visual workflow orchestration, a comprehensive evaluation framework, and extensible Python integration. FROAV implements a multi-stage Retrieval-Augmented Generation (RAG) pipeline coupled with a rigorous \"LLM-as-a-Judge\" evaluation system, all accessible through intuitive graphical interfaces. Our framework integrates n8n for no-code workflow design, PostgreSQL for granular data management, FastAPI for flexible backend logic, and Streamlit for human-in-the-loop interaction. Through this integrated ecosystem, researchers can rapidly prototype RAG strategies, conduct prompt engineering experiments, validate agent performance against human judgments, and collect structured feedback-all without writing infrastructure code. We demonstrate the framework's utility through its application to financial document analysis, while emphasizing its material-agnostic architecture that a",
    "authors": [
      "Tzu-Hsuan Lin",
      "Chih-Hsuan Kao"
    ],
    "published": "2026-01-12",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2601.07504v1",
    "categories": [
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2506.09580v1",
    "title": "The Everyday Security of Living with Conflict",
    "summary": "When `cyber' is used as a prefix, attention is typically drawn to the technological and spectacular aspects of war and conflict -- and, by extension, security. We offer a different approach to engaging with and understanding security in such contexts, by foregrounding the everyday -- mundane -- experiences of security within communities living with and fleeing from war. We do so through three vignettes from our field research in Colombia, Lebanon and Sweden, respectively, and by highlighting the significance of ethnography for security research with communities living in regions afflicted by war. We conclude by setting out a call to action for security researchers and practitioners to consider such lived experiences in the design of security technology that aims to cater to the needs of communities in `global conflict and disaster regions'.",
    "authors": [
      "Jessica McClearn",
      "Reem Talhouk",
      "Rikke Bjerg Jensen"
    ],
    "published": "2025-06-11",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2506.09580v1",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2503.14006v2",
    "title": "Securing Automated Insulin Delivery Systems: A Review of Security Threats and Protective Strategies",
    "summary": "Automated Insulin Delivery (AID) systems represent a significant advancement in diabetes care and wearable physiological closed-loop control technologies, integrating continuous glucose monitoring, control algorithms, and insulin pumps to improve blood glucose level control and reduce the burden of patient self-management. However, their increasing dependence on wireless communication and automatic control introduces security risks that may compromise patient privacy or result in life-threatening treatment errors. This paper presents a comprehensive survey of the AID system security landscape, covering technical vulnerabilities, regulatory frameworks, and commercial security measures. In addition, we conduct a systematic review of attack vectors and defence mechanisms proposed in the literature, following the PRISMA framework. Our findings highlight critical gaps, including the lack of specific security evaluation frameworks, insufficient protections in real-world deployments, and the need for comprehensive, lightweight, and adaptive defence mechanisms. We further investigate available research resources and outline open research challenges and future directions to guide the development of more secure and reliable AID systems. By focusing on AID systems, this review offers a representative case study for examining and improving the cybersecurity of safety-critical medical wearable systems.",
    "authors": [
      "Yuchen Niu",
      "Siew-Kei Lam"
    ],
    "published": "2025-03-18",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2503.14006v2",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2103.08436v1",
    "title": "Formal Modelling and Security Analysis of Bitcoin's Payment Protocol",
    "summary": "The Payment Protocol standard BIP70, specifying how payments in Bitcoin are performed by merchants and customers, is supported by the largest payment processors and most widely-used wallets. The protocol has been shown to be vulnerable to refund attacks due to lack of authentication of the refund addresses. In this paper, we give the first formal model of the protocol and formalise the refund address security goals for the protocol, namely refund address authentication and secrecy. The formal model utilises communication channels as abstractions conveying security goals on which the protocol modeller and verifier can rely. We analyse the Payment Protocol confirming that it is vulnerable to an attack violating the refund address authentication security goal. Moreover, we present a concrete protocol revision proposal supporting the merchant with publicly verifiable evidence that can mitigate the attack. We verify that the revised protocol meets the security goals defined for the refund address. Hence, we demonstrate that the revised protocol is secure, not only against the existing attacks, but also against any further attacks violating the formalised security goals.",
    "authors": [
      "Paolo Modesti",
      "Siamak F. Shahandashti",
      "Patrick McCorry",
      "Feng Hao"
    ],
    "published": "2021-03-15",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2103.08436v1",
    "categories": [
      "cs.CR",
      "cs.FL"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2409.09288v2",
    "title": "Generating API Parameter Security Rules with LLM for API Misuse Detection",
    "summary": "In this paper, we present a new framework, named GPTAid, for automatic APSRs generation by analyzing API source code with LLM and detecting API misuse caused by incorrect parameter use. To validate the correctness of the LLM-generated APSRs, we propose an execution feedback-checking approach based on the observation that security-critical API misuse is often caused by APSRs violations, and most of them result in runtime errors. Specifically, GPTAid first uses LLM to generate raw APSRs and the Right calling code, and then generates Violation code for each raw APSR by modifying the Right calling code using LLM. Subsequently, GPTAid performs dynamic execution on each piece of Violation code and further filters out the incorrect APSRs based on runtime errors. To further generate concrete APSRs, GPTAid employs a code differential analysis to refine the filtered ones. Particularly, as the programming language is more precise than natural language, GPTAid identifies the key operations within Violation code by differential analysis, and then generates the corresponding concrete APSR based on the aforementioned operations. These concrete APSRs could be precisely interpreted into applicable detection code, which proven to be effective in API misuse detection. Implementing on the dataset containing 200 randomly selected APIs from eight popular libraries, GPTAid achieves a precision of 92.3%. Moreover, it generates 6 times more APSRs than state-of-the-art detectors on a comparison datase",
    "authors": [
      "Jinghua Liu",
      "Yi Yang",
      "Kai Chen",
      "Miaoqian Lin"
    ],
    "published": "2024-09-14",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2409.09288v2",
    "categories": [
      "cs.CR",
      "cs.SE"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1002.1174v1",
    "title": "M-Banking Security - a futuristic improved security approach",
    "summary": "In last few decades large technology development raised various new needs. Financial sector has also no exception. People are approaching all over the world to fulfill there dreams. Any sector needs to understand changing need of customer. In order to satisfy financial need for customer banks are taking help of new technology such as internet. Only problem remain is of security. The aim of this work is to provide a secure environment in terms of security for transaction by various ways. In order to improve security we are making use of \"Steganography\" technique in the way never used before. Task of enhancing security include construction of formula for both data encryption and also for hiding pattern. Server should not process any fake request hence concept of custom \"Session id\" and \"Request id\" is introduced. Implementation of such a security constraints in banking sector not only help to serve customer in better way but also make customer confident and satisfy.",
    "authors": [
      "Geeta S. Navale",
      "Swati S. Joshi",
      "Aaradhana A. Deshmukh"
    ],
    "published": "2010-02-05",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1002.1174v1",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2210.02137v1",
    "title": "Internet Service Providers' and Individuals' Attitudes, Barriers, and Incentives to Secure IoT",
    "summary": "Internet Service Providers (ISPs) and individual users of Internet of Things (IoT) play a vital role in securing IoT. However, encouraging them to do so is hard. Our study investigates ISPs' and individuals' attitudes towards the security of IoT, the obstacles they face, and their incentives to keep IoT secure, drawing evidence from Japan.\n  Due to the complex interactions of the stakeholders, we follow an iterative methodology where we present issues and potential solutions to our stakeholders in turn. For ISPs, we survey 27 ISPs in Japan, followed by a workshop with representatives from government and 5 ISPs. Based on the findings from this, we conduct semi-structured interviews with 20 participants followed by a more quantitative survey with 328 participants. We review these results in a second workshop with representatives from government and 7 ISPs. The appreciation of challenges by each party has lead to findings that are supported by all stakeholders.\n  Securing IoT devices is neither users' nor ISPs' priority. Individuals are keen on more interventions both from the government as part of regulation and from ISPs in terms of filtering malicious traffic. Participants are willing to pay for enhanced monitoring and filtering. While ISPs do want to help users, there appears to be a lack of effective technology to aid them. ISPs would like to see more public recognition for their efforts, but internally they struggle with executive buy-in and effective means to communicate ",
    "authors": [
      "Nissy Sombatruang",
      "Tristan Caulfield",
      "Ingolf Becker",
      "Akira Fujita",
      "Takahiro Kasama",
      "Koji Nakao",
      "Daisuke Inoue"
    ],
    "published": "2022-10-05",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2210.02137v1",
    "categories": [
      "cs.CY",
      "cs.CR"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2111.06002v1",
    "title": "SyzScope: Revealing High-Risk Security Impacts of Fuzzer-Exposed Bugs in Linux kernel",
    "summary": "Fuzzing has become one of the most effective bug finding approach for software. In recent years, 24*7 continuous fuzzing platforms have emerged to test critical pieces of software, e.g., Linux kernel. Though capable of discovering many bugs and providing reproducers (e.g., proof-of-concepts), a major problem is that they neglect a critical function that should have been built-in, i.e., evaluation of a bug's security impact. It is well-known that the lack of understanding of security impact can lead to delayed bug fixes as well as patch propagation. In this paper, we develop SyzScope, a system that can automatically uncover new \"high-risk\" impacts given a bug with seemingly \"low-risk\" impacts. From analyzing over a thousand low-risk bugs on syzbot, SyzScope successfully determined that 183 low-risk bugs (more than 15%) in fact contain high-risk impacts, e.g., control flow hijack and arbitrary memory write, some of which still do not have patches available yet.",
    "authors": [
      "Xiaochen Zou",
      "Guoren Li",
      "Weiteng Chen",
      "Hang Zhang",
      "Zhiyun Qian"
    ],
    "published": "2021-11-11",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2111.06002v1",
    "categories": [
      "cs.CR",
      "cs.SE"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2206.02156v2",
    "title": "Perspectives of Non-Expert Users on Cyber Security and Privacy: An Analysis of Online Discussions on Twitter",
    "summary": "Current research on users` perspectives of cyber security and privacy related to traditional and smart devices at home is very active, but the focus is often more on specific modern devices such as mobile and smart IoT devices in a home context. In addition, most were based on smaller-scale empirical studies such as online surveys and interviews. We endeavour to fill these research gaps by conducting a larger-scale study based on a real-world dataset of 413,985 tweets posted by non-expert users on Twitter in six months of three consecutive years (January and February in 2019, 2020 and 2021). Two machine learning-based classifiers were developed to identify the 413,985 tweets. We analysed this dataset to understand non-expert users` cyber security and privacy perspectives, including the yearly trend and the impact of the COVID-19 pandemic. We applied topic modelling, sentiment analysis and qualitative analysis of selected tweets in the dataset, leading to various interesting findings. For instance, we observed a 54% increase in non-expert users` tweets on cyber security and/or privacy related topics in 2021, compared to before the start of global COVID-19 lockdowns (January 2019 to February 2020). We also observed an increased level of help-seeking tweets during the COVID-19 pandemic. Our analysis revealed a diverse range of topics discussed by non-expert users across the three years, including VPNs, Wi-Fi, smartphones, laptops, smart home devices, financial security, and secu",
    "authors": [
      "Nandita Pattnaik",
      "Shujun Li",
      "Jason R. C. Nurse"
    ],
    "published": "2022-06-05",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2206.02156v2",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2511.15479v1",
    "title": "Towards a Formal Verification of Secure Vehicle Software Updates",
    "summary": "With the rise of software-defined vehicles (SDVs), where software governs most vehicle functions alongside enhanced connectivity, the need for secure software updates has become increasingly critical. Software vulnerabilities can severely impact safety, the economy, and society. In response to this challenge, Strandberg et al. [escar Europe, 2021] introduced the Unified Software Update Framework (UniSUF), designed to provide a secure update framework that integrates seamlessly with existing vehicular infrastructures.\n  Although UniSUF has previously been evaluated regarding cybersecurity, these assessments have not employed formal verification methods. To bridge this gap, we perform a formal security analysis of UniSUF. We model UniSUF's architecture and assumptions to reflect real-world automotive systems and develop a ProVerif-based framework that formally verifies UniSUF's compliance with essential security requirements - confidentiality, integrity, authenticity, freshness, order, and liveness - demonstrating their satisfiability through symbolic execution. Our results demonstrate that UniSUF adheres to the specified security guarantees, ensuring the correctness and reliability of its security framework.",
    "authors": [
      "Martin Slind Hagen",
      "Emil Lundqvist",
      "Alex Phu",
      "Yenan Wang",
      "Kim Strandberg",
      "Elad Michael Schiller"
    ],
    "published": "2025-11-19",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2511.15479v1",
    "categories": [
      "cs.CR",
      "cs.DC",
      "cs.LO"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1704.02440v1",
    "title": "Audit Analysis Models, Security Frameworks and Their Relevance for VoIP",
    "summary": "Voice over IP (VoIP) is the transmission of voice and multimedia content over Internet Protocol (IP) networks, this paper reviews models, frameworks and auditing standards proposed to this date to manage VoIP security through a literature review, with descriptions of both the historical and philosophical evolution reflecting an adequate knowledge of related research. Three research questions are raised here: RQ1. What are the requirements to be met by a model of security audit in VoIP systems to achieve their goals? RQ2. Today, are there additional attacks that previous works have not considered? RQ3. Which security requirements in the VoIP systems are covered (and which are not covered) by security frameworks? After some discussion about VoIP Protocols, Attacks on VoIP, Information Technology (IT) audit, IT security audits, Frameworks and auditing standards, we present a unified view of VoIP Security Requirements; as well as considering the contributions and disadvantages of frameworks and auditing standards toward achieving those requirements through a comparative evaluation. It was determined that there is no security framework which considers social engineering attacks in spite of being an important aspect to consider in security management VoIP; also there is no specific framework that covers all categories of security requirements for VoIP system, therefore, a more extensive model is needed.",
    "authors": [
      "Oscar Gavilanez",
      "Franklin Gavilanez",
      "Glen Rodriguez"
    ],
    "published": "2017-04-08",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1704.02440v1",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "0908.0122v1",
    "title": "Complete Security Framework for Wireless Sensor Networks",
    "summary": "Security concern for a Sensor Networks and level of security desired may differ according to application specific needs where the sensor networks are deployed. Till now, most of the security solutions proposed for sensor networks are layer wise i.e a particular solution is applicable to single layer itself. So, to integrate them all is a new research challenge. In this paper we took up the challenge and have proposed an integrated comprehensive security framework that will provide security services for all services of sensor network. We have added one extra component i.e. Intelligent Security Agent (ISA) to assess level of security and cross layer interactions. This framework has many components like Intrusion Detection System, Trust Framework, Key Management scheme and Link layer communication protocol. We have also tested it on three different application scenarios in Castalia and Omnet++ simulator.",
    "authors": [
      "Kalpana Sharma",
      "M. K. Ghose",
      " Kuldeep"
    ],
    "published": "2009-08-02",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/0908.0122v1",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2208.05586v3",
    "title": "Multi-Factor Key Derivation Function (MFKDF) for Fast, Flexible, Secure, &amp; Practical Key Management",
    "summary": "We present the first general construction of a Multi-Factor Key Derivation Function (MFKDF). Our function expands upon password-based key derivation functions (PBKDFs) with support for using other popular authentication factors like TOTP, HOTP, and hardware tokens in the key derivation process. In doing so, it provides an exponential security improvement over PBKDFs with less than 12 ms of additional computational overhead in a typical web browser. We further present a threshold MFKDF construction, allowing for client-side key recovery and reconstitution if a factor is lost. Finally, by \"stacking\" derived keys, we provide a means of cryptographically enforcing arbitrarily specific key derivation policies. The result is a paradigm shift toward direct cryptographic protection of user data using all available authentication factors, with no noticeable change to the user experience. We demonstrate the ability of our solution to not only significantly improve the security of existing systems implementing PBKDFs, but also to enable new applications where PBKDFs would not be considered a feasible approach.",
    "authors": [
      "Vivek Nair",
      "Dawn Song"
    ],
    "published": "2022-08-10",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2208.05586v3",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1704.02441v1",
    "title": "Ontologies for Network Security and Future Challenges",
    "summary": "Efforts have been recently made to construct ontologies for network security. The proposed ontologies are related to specific aspects of network security. Therefore, it is necessary to identify the specific aspects covered by existing ontologies for network security. A review and analysis of the principal issues, challenges, and the extent of progress related to distinct ontologies was performed. Each example was classified according to the typology of the ontologies for network security. Some aspects include identifying threats, intrusion detection systems (IDS), alerts, attacks, countermeasures, security policies, and network management tools. The research performed here proposes the use of three stages: 1. Inputs; 2. Processing; and 3. Outputs. The analysis resulted in the introduction of new challenges and aspects that may be used as the basis for future research. One major issue that was discovered identifies the need to develop new ontologies that relate to distinct aspects of network security, thereby facilitating management tasks.",
    "authors": [
      "Danny Velasco",
      "Glen Rodriguez"
    ],
    "published": "2017-04-08",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1704.02441v1",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1002.1950v1",
    "title": "Convergence of Corporate and Information Security",
    "summary": "As physical and information security boundaries have become increasingly blurry many organizations are experiencing challenges with how to effectively and efficiently manage security within the corporate. There is no current standard or best practice offered by the security community regarding convergence; however many organizations such as the Alliance for Enterprise Security Risk Management (AESRM) offer some excellent suggestions for integrating a converged security program. This paper reports on how organizations have traditionally managed asset protection, why that is changing and how to establish convergence to optimize security value to the business within an enterprise.",
    "authors": [
      " Syed",
      "M. Rahman",
      "Shannon E. Donahue"
    ],
    "published": "2010-02-09",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1002.1950v1",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1805.07570v1",
    "title": "Physical and Mechatronic Security, Technologies and Future Trends for Vehicular Environment",
    "summary": "Cloning spare parts and entities of mass products is an old and serious unsolved problem for the automotive industry. The economic losses in addition to a loss of know-how and IP theft as well as security and safety threats are huge in all dimensions. This presentation gives an overview of the traditional state of the art on producing clone resistant electronic units in the last two decades. A survey is attempting to demonstrate the techniques so far known as Physically Unclonable Functions PUFs showing their advantages and drawbacks. The necessity for fabricating mechatronic-security in the vehicular environment is emerging to become a vital requirement for new automotive security regulations (legal regulations) in the near future. The automotive industry is facing a challenge to produce low-cost and highly safe and secure networked automotive systems. The emerging networked smart traffic environment is offering new safety services and creating at the same time new needs and threats in a highly networked world. There is a crying need for automotive security that approaches the level of the robust biological security for cars as dominating mobility actors in the modern smart life environment. Possible emerging technologies allowing embedding practical mechatronic-security modules as a low-cost digital alternative are presented. Such digital clone-resistant mechatronic-units (as Electronic Control Units ECUs) may serve as smart security anchors for the automotive environment i",
    "authors": [
      "Wael Adi",
      "Ayoub Mars"
    ],
    "published": "2018-05-19",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1805.07570v1",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1808.06100v6",
    "title": "On the solution existence and stability of polynomial optimization problems",
    "summary": "This paper introduces and investigates a regularity condition in the asymptotic sense for optimization problems whose objective functions are polynomial. Under this regularity condition, the normalization argument in asymptotic analysis enables us to see the solution existence as well as the solution stability of these problems. We prove a Frank-Wolfe type theorem for regular optimization problems and an Eaves type theorem for non-regular pseudoconvex optimization problems. Moreover, we show results on the stability such as upper semicontinuity and local upper-Hölder stability of the solution map of polynomial optimization problems. At the end of the paper, we discuss the genericity of the regularity condition.",
    "authors": [
      "Vu Trung Hieu"
    ],
    "published": "2018-08-18",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1808.06100v6",
    "categories": [
      "math.OC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2501.00258v1",
    "title": "Optimal design of frame structures with mixed categorical and continuous design variables using the Gumbel-Softmax method",
    "summary": "In optimizing real-world structures, due to fabrication or budgetary restraints, the design variables may be restricted to a set of standard engineering choices. Such variables, commonly called categorical variables, are discrete and unordered in essence, precluding the utilization of gradient-based optimizers for the problems containing them. In this paper, incorporating the Gumbel-Softmax (GSM) method, we propose a new gradient-based optimizer for handling such variables in the optimal design of large-scale frame structures. The GSM method provides a means to draw differentiable samples from categorical distributions, thereby enabling sensitivity analysis for the variables generated from such distributions. The sensitivity information can greatly reduce the computational cost of traversing high-dimensional and discrete design spaces in comparison to employing gradient-free optimization methods. In addition, since the developed optimizer is gradient-based, it can naturally handle the simultaneous optimization of categorical and continuous design variables. Through three numerical case studies, different aspects of the proposed optimizer are studied and its advantages over population-based optimizers, specifically a genetic algorithm, are demonstrated.",
    "authors": [
      "Mehran Ebrahimi",
      "Hyunmin Cheong",
      "Pradeep Kumar Jayaraman",
      "Farhad Javid"
    ],
    "published": "2024-12-31",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2501.00258v1",
    "categories": [
      "cs.CE",
      "math.OC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2303.08710v1",
    "title": "Two-Scale Optimization of Graded Lattice Structures respecting Buckling on Micro- and Macroscale",
    "summary": "Interest in components with detailed structures increased with the progress in advanced manufacturing techniques in recent years. Parts with graded lattice elements can provide interesting mechanical, thermal, and acoustic properties compared to parts where only coarse features are included. One of these improvements is better global buckling resistance of the component. However, thin features are prone to local buckling. Normally, analyses with high computational effort are conducted on high-resolution finite element meshes to optimize parts with good global and local stability. Until recently, works focused only on either global or local buckling behavior. We use two-scale optimization based on asymptotic homogenization of elastic properties and local buckling behavior to reduce the effort of full-scale analyses. For this, we present an approach for concurrent local and global buckling optimization of parameterized graded lattice structures. It is based on a worst-case model for the homogenized buckling load factor, which acts as a safeguard against pure local buckling. Cross-modes residing on both scales are not detected. We support our theory with numerical examples and validations on dehomogenized designs, which show the capabilities of our method, and discuss the advantages and limitations of the worst-case model.",
    "authors": [
      "Daniel Hübner",
      "Fabian Wein",
      "Michael Stingl"
    ],
    "published": "2023-03-15",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2303.08710v1",
    "categories": [
      "cs.CE",
      "math.OC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2201.02491v3",
    "title": "An efficient and easy-to-extend Matlab code of the Moving Morphable Component (MMC) method for three-dimensional topology optimization",
    "summary": "Explicit topology optimization methods have received ever-increasing interest in recent years. In particular, a 188-line Matlab code of the two-dimensional (2D) Moving Morphable Component (MMC)-based topology optimization method was released by Zhang et al. (Struct Multidiscip Optim 53(6):1243-1260, 2016). The present work aims to propose an efficient and easy-to-extend 256-line Matlab code of the MMC method for three-dimensional (3D) topology optimization implementing some new numerical techniques. To be specific, by virtue of the function aggregation technique, accurate sensitivity analysis, which is also easy-to-extend to other problems, is achieved. Besides, based on an efficient identification algorithm for load transmission path, the degrees of freedoms (DOFs) not belonging to the load transmission path are removed in finite element analysis (FEA), which significantly accelerates the optimization process. As a result, compared to the corresponding 188-line 2D code, the performance of the optimization results, the computational efficiency of FEA, and the convergence rate and the robustness of optimization process are greatly improved. For the sake of completeness, a refined 218-line Matlab code implementing the 2D-MMC method is also provided.",
    "authors": [
      "Zongliang Du",
      "Tianchen Cui",
      "Chang Liu",
      "Weisheng Zhang",
      "Yilin Guo",
      "Xu Guo"
    ],
    "published": "2022-01-07",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2201.02491v3",
    "categories": [
      "math.OC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1810.05633v2",
    "title": "Stochastic (Approximate) Proximal Point Methods: Convergence, Optimality, and Adaptivity",
    "summary": "We develop model-based methods for solving stochastic convex optimization problems, introducing the approximate-proximal point, or aProx, family, which includes stochastic subgradient, proximal point, and bundle methods. When the modeling approaches we propose are appropriately accurate, the methods enjoy stronger convergence and robustness guarantees than classical approaches, even though the model-based methods typically add little to no computational overhead over stochastic subgradient methods. For example, we show that improved models converge with probability 1 and enjoy optimal asymptotic normality results under weak assumptions; these methods are also adaptive to a natural class of what we term easy optimization problems, achieving linear convergence under appropriate strong growth conditions on the objective. Our substantial experimental investigation shows the advantages of more accurate modeling over standard subgradient methods across many smooth and non-smooth optimization problems.",
    "authors": [
      "Hilal Asi",
      "John C. Duchi"
    ],
    "published": "2018-10-12",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1810.05633v2",
    "categories": [
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2105.13646v3",
    "title": "Conic-Optimization Based Algorithms for Nonnegative Matrix Factorization",
    "summary": "Nonnegative matrix factorization is the following problem: given a nonnegative input matrix $V$ and a factorization rank $K$, compute two nonnegative matrices, $W$ with $K$ columns and $H$ with $K$ rows, such that $WH$ approximates $V$ as well as possible. In this paper, we propose two new approaches for computing high-quality NMF solutions using conic optimization. These approaches rely on the same two steps. First, we reformulate NMF as minimizing a concave function over a product of convex cones--one approach is based on the exponential cone, and the other on the second-order cone. Then, we solve these reformulations iteratively: at each step, we minimize exactly, over the feasible set, a majorization of the objective functions obtained via linearization at the current iterate. Hence these subproblems are convex conic programs and can be solved efficiently using dedicated algorithms. We prove that our approaches reach a stationary point with an accuracy decreasing as $\\mathcal{O}(\\frac{1}{i})$, where $i$ denotes the iteration number. To the best of our knowledge, our analysis is the first to provide a convergence rate to stationary points for NMF. Furthermore, in the particular cases of rank-one factorizations (that is, $K=1$), we show that one of our formulations can be expressed as a convex optimization problem implying that optimal rank-one approximations can be computed efficiently. Finally, we show on several numerical examples that our approaches are able to frequent",
    "authors": [
      "Valentin Leplat",
      "Yurii Nesterov",
      "Nicolas Gillis",
      "François Glineur"
    ],
    "published": "2021-05-28",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2105.13646v3",
    "categories": [
      "math.OC",
      "math.CO"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2111.15645v5",
    "title": "Survey Descent: A Multipoint Generalization of Gradient Descent for Nonsmooth Optimization",
    "summary": "For strongly convex objectives that are smooth, the classical theory of gradient descent ensures linear convergence relative to the number of gradient evaluations. An analogous nonsmooth theory is challenging. Even when the objective is smooth at every iterate, the corresponding local models are unstable and the number of cutting planes invoked by traditional remedies is difficult to bound, leading to convergences guarantees that are sublinear relative to the cumulative number of gradient evaluations. We instead propose a multipoint generalization of the gradient descent iteration for local optimization. While designed with general objectives in mind, we are motivated by a ``max-of-smooth'' model that captures the subdifferential dimension at optimality. We prove linear convergence when the objective is itself max-of-smooth, and experiments suggest a more general phenomenon.",
    "authors": [
      "X. Y. Han",
      "Adrian S. Lewis"
    ],
    "published": "2021-11-30",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2111.15645v5",
    "categories": [
      "math.OC",
      "cs.CG",
      "cs.LG",
      "math.NA"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2005.11788v1",
    "title": "Convergence Results for Optimal Control Problems Governed by Elliptic Quasivariational Inequalities",
    "summary": "We consider an optimal control problem $\\cQ$ governed by an elliptic quasivariational inequality with unilateral constraints. The existence of optimal pairs of the problem is a well known result, see \\cite{SS}, for instance. We associate to $\\cQ$ a new optimal control problem $\\wQ$, obtained by perturbing the state inequality (including the set of constraints and the nonlinear operator) and the cost functional, as well. Then, we provide sufficient conditions which guarantee the convergence of solutions of Problem $\\wQ$ to a solution of Problem $\\cQ$. The proofs are based on convergence results for elliptic quasivariational inequalities, obtained by using arguments of compactness, lower semicontinuity, monotonicity, penalty and various estimates. Finally, we illustrate the use of the abstract convergence results in the study of optimal control associated with two boundary value problems. The first one describes the equilibrium of an elastic body in frictional contact with an obstacle, the so-called foundation. The process is static and the contact is modeled with normal compliance and unilateral constraint, associated to a version of Coulomb's law of dry friction. The second one describes a stationary heat transfer problem with unilateral constraints. For the two problems we prove existence, uniqueness and convergence results together with the corresponding physical interpretation.",
    "authors": [
      "Mircea Sofonea",
      "Domingo A. Tarzia"
    ],
    "published": "2020-05-24",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2005.11788v1",
    "categories": [
      "math.OC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1607.01655v3",
    "title": "L1 penalization of volumetric dose objectives in optimal control of PDEs",
    "summary": "This work is concerned with a class of optimal control problems governed by a partial differential equation that are motivated by an application in radiotherapy treatment planning, where the primary design objective is to minimize the volume where a functional of the state violates a prescribed level, but prescribing these levels in the form of pointwise state constraints can lead to infeasible problems. We therefore propose an alternative approach based on $L^1$ penalization of the violation. We establish well-posedness of the corresponding optimal control problem, derive first-order optimality conditions, and present a semismooth Newton method for the efficient numerical solution of these problems. The performance of this method for a model problem is illustrated and contrasted with the alternative approach based on (regularized) state constraints.",
    "authors": [
      "Richard C. Barnard",
      "Christian Clason"
    ],
    "published": "2016-07-06",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1607.01655v3",
    "categories": [
      "math.OC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1507.06243v7",
    "title": "A Smooth Primal-Dual Optimization Framework for Nonsmooth Composite Convex Minimization",
    "summary": "We propose a new first-order primal-dual optimization framework for a convex optimization template with broad applications. Our optimization algorithms feature optimal convergence guarantees under a variety of common structure assumptions on the problem template. Our analysis relies on a novel combination of three classic ideas applied to the primal-dual gap function: smoothing, acceleration, and homotopy. The algorithms due to the new approach achieve the best known convergence rate results, in particular when the template consists of only non-smooth functions. We also outline a restart strategy for the acceleration to significantly enhance the practical performance. We demonstrate relations with the augmented Lagrangian method and show how to exploit the strongly convex objectives with rigorous convergence rate guarantees. We provide numerical evidence with two examples and illustrate that the new methods can outperform the state-of-the-art, including Chambolle-Pock, and the alternating direction method-of-multipliers algorithms.",
    "authors": [
      "Quoc Tran-Dinh",
      "Olivier Fercoq",
      "Volkan Cevher"
    ],
    "published": "2015-07-22",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1507.06243v7",
    "categories": [
      "math.OC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2204.12344v2",
    "title": "REDCHO: Robust Exact Dynamic Consensus of High Order",
    "summary": "This article addresses the problem of average consensus in a multi-agent system when the desired consensus quantity is a time varying signal. Recently, the EDCHO protocol leveraged high order sliding modes to achieve exact consensus under a constrained set of initial conditions, limiting its applicability to static networks. In this work, we propose REDCHO, an extension of the previous protocol which is robust to mismatch in the initial conditions, making it suitable to use cases in which connection and disconnection of agents is possible. The convergence properties of the protocol are formally explored. Finally, the effectiveness and advantages of our proposal are shown with concrete simulation examples showing the benefits of REDCHO against other methods in the literature.",
    "authors": [
      "Rodrigo Aldana-López",
      "Rosario Aragüés",
      "Carlos Sagüés"
    ],
    "published": "2022-04-26",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2204.12344v2",
    "categories": [
      "eess.SY",
      "cs.MA",
      "math.OC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2202.03012v2",
    "title": "EDCHO: High Order Exact Dynamic Consensus",
    "summary": "This article addresses the problem of average consensus in a multi-agent system when the desired consensus quantity is a time varying signal. Although this problem has been addressed in existing literature by linear schemes, only bounded steady-state errors have been achieved. Other approaches have used first order sliding modes to achieve zero steady-state error, but suffer from the chattering effect. In this work, we propose a new exact dynamic consensus algorithm which leverages high order sliding modes, in the form of a distributed differentiator to achieve zero steady-state error of the average of time varying reference signals in a group of agents. Moreover, our proposal is also able to achieve consensus to high order derivatives of the average signal, if desired. An in depth formal study on the stability and convergence for EDCHO is provided for undirected connected graphs. Finally, the effectiveness and advantages of our proposal are shown with concrete simulation scenarios.",
    "authors": [
      "Rodrigo Aldana-López",
      "Rosario Aragüés",
      "Carlos Sagüés"
    ],
    "published": "2022-02-07",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2202.03012v2",
    "categories": [
      "eess.SY",
      "cs.MA",
      "math.OC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2507.22648v1",
    "title": "Distributed Average Consensus in Wireless Multi-Agent Systems with Over-the-Air Aggregation",
    "summary": "In this paper, we address the average consensus problem of multi-agent systems over wireless networks. We propose a distributed average consensus algorithm by invoking the concept of over-the-air aggregation, which exploits the signal superposition property of wireless multiple-access channels. The proposed algorithm deploys a modified version of the well-known Ratio Consensus algorithm with an additional normalization step for compensating for the arbitrary channel coefficients. We show that, when the noise level at the receivers is negligible, the algorithm converges asymptotically to the average for time-invariant and time-varying channels. Numerical simulations corroborate the validity of our results.",
    "authors": [
      "Themistoklis Charalambous",
      "Zheng Chen",
      "Christoforos N. Hadjicostis"
    ],
    "published": "2025-07-30",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2507.22648v1",
    "categories": [
      "eess.SY",
      "eess.SP"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2411.14245v2",
    "title": "Pulsar Consensus",
    "summary": "In this paper, we informally introduce the Pulsar proof of stake consensus paper and discuss the relevant design decisions and considerations. The Pulsar protocol we propose is designed to facilitate the creation of a proof of stake sidechain for a proof of work blockchain. We present an overview of a novel composable density-based chain selection rule for proof of stake systems which can be seen as a superset of some standard existing longest chain rules for proof of stake protocols. We discuss the Pulsar protocol in comparison to existing proof of stake protocols and define its benefits over existing designs while defining the limitations of the work. Pulsar is currently implemented in the Mintlayer proof of stake Bitcoin sidechain.",
    "authors": [
      "Samer Afach",
      "Benjamin Marsh",
      "Enrico Rubboli"
    ],
    "published": "2024-11-21",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2411.14245v2",
    "categories": [
      "cs.CR"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2602.16260v1",
    "title": "Autonomous and non-autonomous fixed-time leader-follower consensus for second-order multi-agent systems",
    "summary": "This paper addresses the problem of consensus tracking with fixed-time convergence, for leader-follower multi-agent systems with double-integrator dynamics, where only a subset of followers has access to the state of the leader. The control scheme is divided into two steps. The first one is dedicated to the estimation of the leader state by each follower in a distributed way and in a fixed-time. Then, based on the estimate of the leader state, each follower computes its control law to track the leader in a fixed-time. In this paper, two control strategies are investigated and compared to solve the two mentioned steps. The first one is an autonomous protocol which ensures a fixed-time convergence for the observer and for the controller parts where the Upper Bound of the Settling-Time (UBST) is set a priory by the user. Then, the previous strategy is redesigned using time-varying gains to obtain a non-autonomous protocol. This enables to obtain less conservative estimates of the UBST while guaranteeing that the time-varying gains remain bounded. Some numerical examples show the effectiveness of the proposed consensus protocols.",
    "authors": [
      "Miguel A. Trujillo",
      "Rodrigo Aldana-López",
      "David Gomez Gutierrez",
      "Michael Defoort",
      "Javier Ruiz Leon",
      "Hector M. Becerra"
    ],
    "published": "2026-02-18",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2602.16260v1",
    "categories": [
      "eess.SY",
      "math.DS",
      "math.OC"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2504.20440v1",
    "title": "Consensus Recommendations for Hyperpolarized [1-13C]pyruvate MRI Multi-center Human Studies",
    "summary": "Magnetic resonance imaging of hyperpolarized (HP) [1-13C]pyruvate allows in-vivo assessment of metabolism and has translated into human studies across diseases at 15 centers worldwide. Consensus on best practice for multi-center studies is required to develop clinical applications. This paper presents the results of a 2-round formal consensus building exercise carried out by experts with HP [1-13C]pyruvate human study experience. Twenty-nine participants from 13 sites brought together expertise in pharmacy methods, MR physics, translational imaging, and data-analysis; with the goal of providing recommendations and best practice statements on conduct of multi-center human studies of HP [1-13C]pyruvate MRI.\n  Overall, the group reached consensus on approximately two-thirds of 246 statements in the questionnaire, covering 'HP 13C-Pyruvate Preparation', 'MRI System Setup, Calibration, and Phantoms', 'Acquisition and Reconstruction', and 'Data Analysis and Quantification'.\n  Consensus was present across categories, examples include that: (i) different HP pyruvate preparation methods could be used in human studies, but that the same release criteria have to be followed; (ii) site qualification and quality assurance must be performed with phantoms and that the same field strength must be used, but that the rest of the system setup and calibration methods could be determined by individual sites; (iii) the same pulse sequence and reconstruction methods were preferable, but the exact c",
    "authors": [
      "Shonit Punwani",
      "Peder EZ Larson",
      "Christoffer Laustsen",
      "Jan VanderMeulen",
      "Jan Henrik Ardenkjær-Larsen",
      "Adam W. Autry",
      "James A. Bankson",
      "Jenna Bernard",
      "Robert Bok",
      "Lotte Bonde Bertelsen"
    ],
    "published": "2025-04-29",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2504.20440v1",
    "categories": [
      "physics.med-ph"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2011.12216v3",
    "title": "Energy-Based Models for Continual Learning",
    "summary": "We motivate Energy-Based Models (EBMs) as a promising model class for continual learning problems. Instead of tackling continual learning via the use of external memory, growing models, or regularization, EBMs change the underlying training objective to cause less interference with previously learned information. Our proposed version of EBMs for continual learning is simple, efficient, and outperforms baseline methods by a large margin on several benchmarks. Moreover, our proposed contrastive divergence-based training objective can be combined with other continual learning methods, resulting in substantial boosts in their performance. We further show that EBMs are adaptable to a more general continual learning setting where the data distribution changes without the notion of explicitly delineated tasks. These observations point towards EBMs as a useful building block for future continual learning methods.",
    "authors": [
      "Shuang Li",
      "Yilun Du",
      "Gido M. van de Ven",
      "Igor Mordatch"
    ],
    "published": "2020-11-24",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2011.12216v3",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1905.12588v2",
    "title": "Meta-Learning Representations for Continual Learning",
    "summary": "A continual learning agent should be able to build on top of existing knowledge to learn on new data quickly while minimizing forgetting. Current intelligent systems based on neural network function approximators arguably do the opposite---they are highly prone to forgetting and rarely trained to facilitate future learning. One reason for this poor behavior is that they learn from a representation that is not explicitly trained for these two goals. In this paper, we propose OML, an objective that directly minimizes catastrophic interference by learning representations that accelerate future learning and are robust to forgetting under online updates in continual learning. We show that it is possible to learn naturally sparse representations that are more effective for online updating. Moreover, our algorithm is complementary to existing continual learning strategies, such as MER and GEM. Finally, we demonstrate that a basic online updating strategy on representations learned by OML is competitive with rehearsal based methods for continual learning. We release an implementation of our method at https://github.com/khurramjaved96/mrcl .",
    "authors": [
      "Khurram Javed",
      "Martha White"
    ],
    "published": "2019-05-29",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1905.12588v2",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2009.04381v1",
    "title": "Routing Networks with Co-training for Continual Learning",
    "summary": "The core challenge with continual learning is catastrophic forgetting, the phenomenon that when neural networks are trained on a sequence of tasks they rapidly forget previously learned tasks. It has been observed that catastrophic forgetting is most severe when tasks are dissimilar to each other. We propose the use of sparse routing networks for continual learning. For each input, these network architectures activate a different path through a network of experts. Routing networks have been shown to learn to route similar tasks to overlapping sets of experts and dissimilar tasks to disjoint sets of experts. In the continual learning context this behaviour is desirable as it minimizes interference between dissimilar tasks while allowing positive transfer between related tasks. In practice, we find it is necessary to develop a new training method for routing networks, which we call co-training which avoids poorly initialized experts when new tasks are presented. When combined with a small episodic memory replay buffer, sparse routing networks with co-training outperform densely connected networks on the MNIST-Permutations and MNIST-Rotations benchmarks.",
    "authors": [
      "Mark Collier",
      "Efi Kokiopoulou",
      "Andrea Gesmundo",
      "Jesse Berent"
    ],
    "published": "2020-09-09",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2009.04381v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1809.02441v3",
    "title": "StackNet: Stacking Parameters for Continual learning",
    "summary": "Training a neural network for a classification task typically assumes that the data to train are given from the beginning. However, in the real world, additional data accumulate gradually and the model requires additional training without accessing the old training data. This usually leads to the catastrophic forgetting problem which is inevitable for the traditional training methodology of neural networks. In this paper, we propose a continual learning method that is able to learn additional tasks while retaining the performance of previously learned tasks by stacking parameters. Composed of two complementary components, the index module and the StackNet, our method estimates the index of the corresponding task for an input sample with the index module and utilizes a particular portion of StackNet with this index. The StackNet guarantees no degradation in the performance of the previously learned tasks and the index module shows high confidence in finding the origin of an input sample. Compared to the previous work of PackNet, our method is competitive and highly intuitive.",
    "authors": [
      "Jangho Kim",
      "Jeesoo Kim",
      "Nojun Kwak"
    ],
    "published": "2018-09-07",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1809.02441v3",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1903.05202v2",
    "title": "Continual Learning in Practice",
    "summary": "This paper describes a reference architecture for self-maintaining systems that can learn continually, as data arrives. In environments where data evolves, we need architectures that manage Machine Learning (ML) models in production, adapt to shifting data distributions, cope with outliers, retrain when necessary, and adapt to new tasks. This represents continual AutoML or Automatically Adaptive Machine Learning. We describe the challenges and proposes a reference architecture.",
    "authors": [
      "Tom Diethe",
      "Tom Borchert",
      "Eno Thereska",
      "Borja Balle",
      "Neil Lawrence"
    ],
    "published": "2019-03-12",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1903.05202v2",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1705.05172v1",
    "title": "Emotion in Reinforcement Learning Agents and Robots: A Survey",
    "summary": "This article provides the first survey of computational models of emotion in reinforcement learning (RL) agents. The survey focuses on agent/robot emotions, and mostly ignores human user emotions. Emotions are recognized as functional in decision-making by influencing motivation and action selection. Therefore, computational emotion models are usually grounded in the agent's decision making architecture, of which RL is an important subclass. Studying emotions in RL-based agents is useful for three research fields. For machine learning (ML) researchers, emotion models may improve learning efficiency. For the interactive ML and human-robot interaction (HRI) community, emotions can communicate state and enhance user investment. Lastly, it allows affective modelling (AM) researchers to investigate their emotion theories in a successful AI agent class. This survey provides background on emotion theory and RL. It systematically addresses 1) from what underlying dimensions (e.g., homeostasis, appraisal) emotions can be derived and how these can be modelled in RL-agents, 2) what types of emotions have been derived from these dimensions, and 3) how these emotions may either influence the learning efficiency of the agent or be useful as social signals. We also systematically compare evaluation criteria, and draw connections to important RL sub-domains like (intrinsic) motivation and model-based RL. In short, this survey provides both a practical overview for engineers wanting to implem",
    "authors": [
      "Thomas M. Moerland",
      "Joost Broekens",
      "Catholijn M. Jonker"
    ],
    "published": "2017-05-15",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1705.05172v1",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "cs.RO",
      "stat.ML"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2210.03869v2",
    "title": "TAME: Task Agnostic Continual Learning using Multiple Experts",
    "summary": "The goal of lifelong learning is to continuously learn from non-stationary distributions, where the non-stationarity is typically imposed by a sequence of distinct tasks. Prior works have mostly considered idealistic settings, where the identity of tasks is known at least at training. In this paper we focus on a fundamentally harder, so-called task-agnostic setting where the task identities are not known and the learning machine needs to infer them from the observations. Our algorithm, which we call TAME (Task-Agnostic continual learning using Multiple Experts), automatically detects the shift in data distributions and switches between task expert networks in an online manner. At training, the strategy for switching between tasks hinges on an extremely simple observation that for each new coming task there occurs a statistically-significant deviation in the value of the loss function that marks the onset of this new task. At inference, the switching between experts is governed by the selector network that forwards the test sample to its relevant expert network. The selector network is trained on a small subset of data drawn uniformly at random. We control the growth of the task expert networks as well as selector network by employing online pruning. Our experimental results show the efficacy of our approach on benchmark continual learning data sets, outperforming the previous task-agnostic methods and even the techniques that admit task identities at both training and testing",
    "authors": [
      "Haoran Zhu",
      "Maryam Majzoubi",
      "Arihant Jain",
      "Anna Choromanska"
    ],
    "published": "2022-10-08",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2210.03869v2",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1810.03880v3",
    "title": "Continual State Representation Learning for Reinforcement Learning using Generative Replay",
    "summary": "We consider the problem of building a state representation model in a continual fashion. As the environment changes, the aim is to efficiently compress the sensory state's information without losing past knowledge. The learned features are then fed to a Reinforcement Learning algorithm to learn a policy. We propose to use Variational Auto-Encoders for state representation, and Generative Replay, i.e. the use of generated samples, to maintain past knowledge. We also provide a general and statistically sound method for automatic environment change detection. Our method provides efficient state representation as well as forward transfer, and avoids catastrophic forgetting. The resulting model is capable of incrementally learning information without using past data and with a bounded system size.",
    "authors": [
      "Hugo Caselles-Dupré",
      "Michael Garcia-Ortiz",
      "David Filliat"
    ],
    "published": "2018-10-09",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1810.03880v3",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "1810.10612v1",
    "title": "Continual Classification Learning Using Generative Models",
    "summary": "Continual learning is the ability to sequentially learn over time by accommodating knowledge while retaining previously learned experiences. Neural networks can learn multiple tasks when trained on them jointly, but cannot maintain performance on previously learned tasks when tasks are presented one at a time. This problem is called catastrophic forgetting. In this work, we propose a classification model that learns continuously from sequentially observed tasks, while preventing catastrophic forgetting. We build on the lifelong generative capabilities of [10] and extend it to the classification setting by deriving a new variational bound on the joint log likelihood, $\\log p(x; y)$.",
    "authors": [
      "Frantzeska Lavda",
      "Jason Ramapuram",
      "Magda Gregorova",
      "Alexandros Kalousis"
    ],
    "published": "2018-10-24",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/1810.10612v1",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2006.10974v3",
    "title": "Optimization and Generalization of Regularization-Based Continual Learning: a Loss Approximation Viewpoint",
    "summary": "Neural networks have achieved remarkable success in many cognitive tasks. However, when they are trained sequentially on multiple tasks without access to old data, their performance on early tasks tend to drop significantly. This problem is often referred to as catastrophic forgetting, a key challenge in continual learning of neural networks. The regularization-based approach is one of the primary classes of methods to alleviate catastrophic forgetting. In this paper, we provide a novel viewpoint of regularization-based continual learning by formulating it as a second-order Taylor approximation of the loss function of each task. This viewpoint leads to a unified framework that can be instantiated to derive many existing algorithms such as Elastic Weight Consolidation and Kronecker factored Laplace approximation. Based on this viewpoint, we study the optimization aspects (i.e., convergence) as well as generalization properties (i.e., finite-sample guarantees) of regularization-based continual learning. Our theoretical results indicate the importance of accurate approximation of the Hessian matrix. The experimental results on several benchmarks provide empirical validation of our theoretical findings.",
    "authors": [
      "Dong Yin",
      "Mehrdad Farajtabar",
      "Ang Li",
      "Nir Levine",
      "Alex Mott"
    ],
    "published": "2020-06-19",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2006.10974v3",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2512.11668v1",
    "title": "Bridging Streaming Continual Learning via In-Context Large Tabular Models",
    "summary": "In streaming scenarios, models must learn continuously, adapting to concept drifts without erasing previously acquired knowledge. However, existing research communities address these challenges in isolation. Continual Learning (CL) focuses on long-term retention and mitigating catastrophic forgetting, often without strict real-time constraints. Stream Learning (SL) emphasizes rapid, efficient adaptation to high-frequency data streams, but typically neglects forgetting. Recent efforts have tried to combine these paradigms, yet no clear algorithmic overlap exists. We argue that large in-context tabular models (LTMs) provide a natural bridge for Streaming Continual Learning (SCL). In our view, unbounded streams should be summarized on-the-fly into compact sketches that can be consumed by LTMs. This recovers the classical SL motivation of compressing massive streams with fixed-size guarantees, while simultaneously aligning with the experience-replay desiderata of CL. To clarify this bridge, we show how the SL and CL communities implicitly adopt a divide-to-conquer strategy to manage the tension between plasticity (performing well on the current distribution) and stability (retaining past knowledge), while also imposing a minimal complexity constraint that motivates diversification (avoiding redundancy in what is stored) and retrieval (re-prioritizing past information when needed). Within this perspective, we propose structuring SCL with LTMs around two core principles of data sel",
    "authors": [
      "Afonso Lourenço",
      "João Gama",
      "Eric P. Xing",
      "Goreti Marreiros"
    ],
    "published": "2025-12-12",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2512.11668v1",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2504.10561v2",
    "title": "Self-Controlled Dynamic Expansion Model for Continual Learning",
    "summary": "Continual Learning (CL) epitomizes an advanced training paradigm wherein prior data samples remain inaccessible during the acquisition of new tasks. Numerous investigations have delved into leveraging a pre-trained Vision Transformer (ViT) to enhance model efficacy in continual learning. Nonetheless, these approaches typically utilize a singular, static backbone, which inadequately adapts to novel tasks, particularly when engaging with diverse data domains, due to a substantial number of inactive parameters. This paper addresses this limitation by introducing an innovative Self-Controlled Dynamic Expansion Model (SCDEM), which orchestrates multiple distinct trainable pre-trained ViT backbones to furnish diverse and semantically enriched representations. Specifically, by employing the multi-backbone architecture as a shared module, the proposed SCDEM dynamically generates a new expert with minimal parameters to accommodate a new task. A novel Collaborative Optimization Mechanism (COM) is introduced to synergistically optimize multiple backbones by harnessing prediction signals from historical experts, thereby facilitating new task learning without erasing previously acquired knowledge. Additionally, a novel Feature Distribution Consistency (FDC) approach is proposed to align semantic similarity between previously and currently learned representations through an optimal transport distance-based mechanism, effectively mitigating negative knowledge transfer effects. Furthermore, ",
    "authors": [
      "Runqing Wu",
      "Kaihui Huang",
      "Hanyi Zhang",
      "Fei Ye"
    ],
    "published": "2025-04-14",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2504.10561v2",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2410.19925v2",
    "title": "Improving Multimodal Large Language Models Using Continual Learning",
    "summary": "Generative large language models (LLMs) exhibit impressive capabilities, which can be further augmented by integrating a pre-trained vision model into the original LLM to create a multimodal LLM (MLLM). However, this integration often significantly decreases performance on natural language understanding and generation tasks, compared to the original LLM. This study investigates this issue using the LLaVA MLLM, treating the integration as a continual learning problem. We evaluate five continual learning methods to mitigate forgetting and identify a technique that enhances visual understanding while minimizing linguistic performance loss. Our approach reduces linguistic performance degradation by up to 15% over the LLaVA recipe, while maintaining high multimodal accuracy. We also demonstrate the robustness of our method through continual learning on a sequence of vision-language tasks, effectively preserving linguistic skills while acquiring new multimodal capabilities. Project webpage: https://shikhar-srivastava.github.io/cl-for-improving-mllms",
    "authors": [
      "Shikhar Srivastava",
      "Md Yousuf Harun",
      "Robik Shrestha",
      "Christopher Kanan"
    ],
    "published": "2024-10-25",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2410.19925v2",
    "categories": [
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2308.10328v3",
    "title": "A Comprehensive Empirical Evaluation on Online Continual Learning",
    "summary": "Online continual learning aims to get closer to a live learning experience by learning directly on a stream of data with temporally shifting distribution and by storing a minimum amount of data from that stream. In this empirical evaluation, we evaluate various methods from the literature that tackle online continual learning. More specifically, we focus on the class-incremental setting in the context of image classification, where the learner must learn new classes incrementally from a stream of data. We compare these methods on the Split-CIFAR100 and Split-TinyImagenet benchmarks, and measure their average accuracy, forgetting, stability, and quality of the representations, to evaluate various aspects of the algorithm at the end but also during the whole training period. We find that most methods suffer from stability and underfitting issues. However, the learned representations are comparable to i.i.d. training under the same computational budget. No clear winner emerges from the results and basic experience replay, when properly tuned and implemented, is a very strong baseline. We release our modular and extensible codebase at https://github.com/AlbinSou/ocl_survey based on the avalanche framework to reproduce our results and encourage future research.",
    "authors": [
      "Albin Soutif--Cormerais",
      "Antonio Carta",
      "Andrea Cossu",
      "Julio Hurtado",
      "Hamed Hemati",
      "Vincenzo Lomonaco",
      "Joost Van de Weijer"
    ],
    "published": "2023-08-20",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2308.10328v3",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2206.07932v1",
    "title": "Lifelong Wandering: A realistic few-shot online continual learning setting",
    "summary": "Online few-shot learning describes a setting where models are trained and evaluated on a stream of data while learning emerging classes. While prior work in this setting has achieved very promising performance on instance classification when learning from data-streams composed of a single indoor environment, we propose to extend this setting to consider object classification on a series of several indoor environments, which is likely to occur in applications such as robotics. Importantly, our setting, which we refer to as online few-shot continual learning, injects the well-studied issue of catastrophic forgetting into the few-shot online learning paradigm. In this work, we benchmark several existing methods and adapted baselines within our setting, and show there exists a trade-off between catastrophic forgetting and online performance. Our findings motivate the need for future work in this setting, which can achieve better online performance without catastrophic forgetting.",
    "authors": [
      "Mayank Lunayach",
      "James Smith",
      "Zsolt Kira"
    ],
    "published": "2022-06-16",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2206.07932v1",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  },
  {
    "id": "2312.00276v3",
    "title": "Metalearning Continual Learning Algorithms",
    "summary": "General-purpose learning systems should improve themselves in open-ended fashion in ever-changing environments. Conventional learning algorithms for neural networks, however, suffer from catastrophic forgetting (CF), i.e., previously acquired skills are forgotten when a new task is learned. Instead of hand-crafting new algorithms for avoiding CF, we propose Automated Continual Learning (ACL) to train self-referential neural networks to metalearn their own in-context continual (meta)learning algorithms. ACL encodes continual learning (CL) desiderata -- good performance on both old and new tasks -- into its metalearning objectives. Our experiments demonstrate that ACL effectively resolves \"in-context catastrophic forgetting,\" a problem that naive in-context learning algorithms suffer from; ACL-learned algorithms outperform both hand-crafted learning algorithms and popular meta-continual learning methods on the Split-MNIST benchmark in the replay-free setting, and enables continual learning of diverse tasks consisting of multiple standard image classification datasets. We also discuss the current limitations of in-context CL by comparing ACL with state-of-the-art CL methods that leverage pre-trained models. Overall, we bring several novel perspectives into the long-standing problem of CL.",
    "authors": [
      "Kazuki Irie",
      "Róbert Csordás",
      "Jürgen Schmidhuber"
    ],
    "published": "2023-12-01",
    "updated": "",
    "pdf_url": "https://arxiv.org/pdf/2312.00276v3",
    "categories": [
      "cs.LG"
    ],
    "primary_category": "",
    "embedding": null
  }
]