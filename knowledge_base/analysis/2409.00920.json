{
  "paper_id": "2409.00920",
  "title": "Toolace",
  "category": "mini_program_service",
  "year": 2024,
  "timestamp": "2026-03-01T14:03:33.742495",
  "summary": "ToolACE is a data generation pipeline for improving LLM function calling by automatically synthesizing tool definitions and multi-turn tool-use dialogs that are accurate, diverse, and appropriately complex for a target model. It introduces three core modules: Tool Self-Evolution Synthesis to build a large and varied API pool, Self-Guided Dialog Generation to create dialogs whose difficulty tracks the learner model, and Dual-Layer Verification to filter invalid or inconsistent samples. The paper reports an API pool of 26,507 APIs across 390 domains and argues that this breadth plus verification enables strong zero-shot generalization for tool use. *Function calling significantly extends the application boundary of large language models LLMs, where high-quality and diverse training data is critical for unlocking this capability.*\n\nThe Tool Self-Evolution Synthesis module generates APIs via a speciation adaptation evolution loop: it builds a hierarchical API context tree from API-related documents, samples subtrees to allocate distinct functionalities to different APIs, then mutates and expands definitions over iterations using diversity indicators like new parameters, new constraints, type mutations, and updated return fields, including nested argument structures. Dialog generation is done by multiple role-play agents user assistant tool, producing four dialog types: single calls, parallel calls, dependent calls, and non-tool dialogs for irrelevance or missing-parameter situations. Complexity is measured using the learner modelâ€™s loss on each sample and is empirically linked to factors such as the number of candidate APIs, the number of APIs used, and the dissimilarity between user queries and API descriptions; generation is adjusted upward or downward based on whether samples fall outside a target complexity band. Verification combines rule checks for schema and call executability with model-based checks decomposed into hallucination detection, consistency validation, and tool response alignment. *ToolACE employs a dual-layer verification system combining rule-based and model-based checks.*\n\nExperiments fine-tune LLaMA-3.1-8B-Instruct with LoRA and evaluate on BFCL and API-Bank, claiming state-of-the-art performance for an 8B model and competitiveness with leading proprietary models on function-calling benchmarks. On the BFCL-v3 leaderboard snapshot cited as updated 09/20/2024, ToolACE-8B is listed with overall 59.22, close to GPT-4-turbo-2024-04-09 at 59.49 and GPT-4o-2024-08-06 at 59.29; on API-Bank it reports 75.94 for Call and 47.41 for Retrieval+Call for ToolACE-8B. Ablations show dual-layer verification outperforms no verification and rule-only verification, medium-complexity subsets slightly outperform easy or hard subsets, and higher API diversity improves accuracy especially relevance and irrelevance discrimination. Removing multi-type data sharply reduces irrelevance accuracy to 6.99 and harms multi-turn behavior, while removing parallel data lowers overall performance; scaling studies with Qwen1.5 chat backbones show fine-tuning substantially boosts smaller models that otherwise struggle with structured tool outputs. The paper also notes limitations around the compute cost and potential bias of loss-based complexity evaluation and that, despite strong tool-use gains, the specialized model still lags GPT-4 on broader reasoning and understanding, leaving multi-capability improvement as an open problem.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/codex/gpt-5.2",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}