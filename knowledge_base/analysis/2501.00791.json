{
  "paper_id": "2501.00791",
  "title": "Generative Ai Chatbot Dataset",
  "category": "ecommerce_evaluation",
  "status": "success",
  "summary": "This paper presents an early step toward building a synthetic human chatbot dialogue dataset for customer service, designed to support emotion aware conversation management and future learning from user interactions. The authors use ChatGPT 3.5 to generate short, multi turn dialogues in a fixed scenario where a customer contacts a hypothetical phone company agent, while controlling two key variables: the users target emotion and the users language proficiency level based on CEFR, focusing on A2, B2, and C2. Dialogues are produced for Ekman style emotions joy, sadness, anger, fear, surprise, and disgust, including both cases where the user explicitly names the emotion and cases where the emotion is conveyed implicitly without direct emotion words, called Implicit Emotion Dialogues.\n\nEach generated dialogue is labeled with an emotion label and a CEFR level, and each turn is additionally tagged with an attitude or emotional stance for the user or agent to capture interaction dynamics. Before storage, dialogues undergo checks for emotional coherence, language complexity coherence, and an overall Quality of Interaction rating with three outcomes: Sufficient, Adequate, or Fail, where Fail dialogues are excluded. The approach also stores inferred chains of attitude labels across turns, aiming to support later discovery of common conversational patterns under specific emotional contexts and to provide a knowledge base for training interactive systems that can learn effective interaction habits.\n\nFor language complexity validation, the study applies automated readability analysis using the ARTE tool and reports multiple established metrics, including Flesch Reading Ease, Flesch Kincaid Grade Level, Automated Readability Index, New Dale Chall, CAREC and its modified variant, an approximated Coh Metrix L2 index, and a Sentence BERT based readability model. Readability is analyzed by CEFR level and by role, separating user and agent sentences, using repeated random sampling to build texts near the tool limit and averaging results with standard deviations; additional analyses compare dialogues with versus without explicit emotion words. The paper includes illustrative dialogue examples for anger and surprise across A2, B2, and C2, and concludes that the pipeline can rapidly generate varied dialogues that align with targeted language levels when paired with quality control, while emphasizing the need to verify output quality and outlining future work on decision support integration, links to big data analytics trends, and adaptive personalization metaphors.\n\n*The primary benefit lies in the accelerated rate of data generation.*\n\n*Of course it is important to verify the quality of generated dialogues.*",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/ecommerce_evaluation/2501.00791_Generative_AI_Chatbot_Dataset.pdf"
}