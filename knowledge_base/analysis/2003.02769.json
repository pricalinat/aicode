{
  "paper_id": "2003.02769",
  "title": "Bayesian Ab",
  "category": "ecommerce_evaluation",
  "year": 2020,
  "timestamp": "2026-03-01T14:01:29.855819",
  "summary": "This paper explains how to use Bayesian inference to analyze A/B tests in a way that maps directly to business decision questions. It argues that common frequentist outputs like p-values and confidence intervals are often hard for stakeholders to interpret, while Bayesian outputs like probability to be best, expected uplift, and expected loss are easier to communicate and act on. The authors frame the core questions as: the probability a treatment is better than control, how much improvement to expect, and the risk of switching.\n\nIt introduces the Bayesian foundations needed for the models: Bayes theorem, the idea of conjugate priors for closed-form posteriors, and the key distributions used. For single conversion events per variant, conversions are modeled with a binomial likelihood and a Beta prior on the conversion rate, yielding a Beta posterior with updated parameters after observing visitors and conversions. For variants with multiple mutually exclusive options (including a none option), outcomes are modeled with a multinomial likelihood and a Dirichlet prior, producing a Dirichlet posterior; revenue or gain per visitor can then be derived by combining posterior samples with option values and possible non-conversion penalties such as ad costs. For cases where only aggregated conversions and aggregated revenue are available, the conversion rate still uses the binomial Beta model, while revenue per purchase is modeled with an exponential likelihood and a Gamma prior, producing a Gamma posterior for average revenue and enabling posterior sampling of revenue and gain.\n\nThe decision layer compares posterior samples to compute three metrics. Probability to be best is estimated by sampling-wise comparisons across variants. Expected uplift is the sampled percent improvement of a treatment over baseline, summarized with a mean and credible interval. Expected loss quantifies downside risk when choosing a variant that is not certainly best, using the positive part of the sampled relative shortfall versus the comparator.\n\nThe paper then demonstrates the approach on three real company experiments around discounting and shows how the metrics drive concrete choices. In a 4-variant single-product discount test run for 53 days, the 40 percent discount variant had the highest probability to be best and the best expected improvement with low loss, leading to a decision to switch from 20 percent to 40 percent discount; results match Google Optimize closely. In a multi-product landing page experiment with ad costs, a progressive discount structure reduced conversions on cheaper options but increased premium-product conversions; revenue per visitor was roughly tied, but gain per visitor favored the progressive variant with low expected loss, so it was deployed. The same multi-product experiment is re-analyzed under the aggregated model using only totals, producing similar conclusions but with more uncertainty in gain due to the exponential revenue assumption.\n\n*Probability to be best (with corresponding credible intervals) provides a natural metric to make business decisions.*\n\n*Decision making is central in running a business with data-driven decisions being the ones having the highest impact on output and productivity.*",
  "llm_info": {
    "provider": "cli",
    "model": "cli/codex/gpt-5.2",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}