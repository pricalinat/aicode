{
  "paper_id": "2502.10050",
  "title": "Paper",
  "category": "mini_program_service",
  "year": 2025,
  "timestamp": "2026-03-01T14:00:56.457793",
  "summary": "This paper surveys how LLM-powered agents are being used to improve recommender systems, motivated by limitations of traditional methods in handling complex user intent, enabling rich interaction, and providing interpretable recommendations. It organizes recent work into a clear taxonomy, then analyzes common system building blocks and how they are implemented across representative methods. *We identify and analyze three key paradigms in current research: (1) Recommender-oriented approaches*.\n\nThe survey groups approaches into three paradigms: recommender-oriented methods that use agent reasoning, memory, and tools to directly produce recommendations; interaction-oriented methods that emphasize multi-turn dialogue, proactive preference elicitation, and explanation; and simulation-oriented methods that use single or multi-agent setups to generate realistic user behavior for evaluation and system analysis. It also proposes a unified agent architecture with four core modules, describing their typical roles and design patterns: Profile for dynamic user and item representations, Memory for storing and retrieving interaction context (sometimes including emotional or hierarchical memory), Planning for multi-step strategy and long-term objective balancing, and Action for executing tool calls and environment interactions to deliver and refine recommendations. *we propose a unified agent architecture consisting of four core modules: Profile, Memory, Planning, and Action*.\n\nA large portion of the paper compiles datasets and evaluation practices used in this area, spanning traditional recommendation benchmarks and conversational recommendation corpora. It highlights frequent use of Amazon Review subsets (for example Books, VideoGames, Beauty), MovieLens at multiple scales, and domain datasets such as Steam, Lastfm, Yelp, and Anime, plus conversational datasets including ReDial, Reddit, and OpenDialKG; it notes that some works sample smaller subsets to control cost because agent systems may require frequent LLM or API calls. Evaluation is summarized across standard ranking and prediction metrics (such as NDCG, Recall, HitRatio, MRR, RMSE), language generation metrics (BLEU, ROUGE) for explanation or summary quality, reinforcement-learning style reward metrics for long-term engagement, and conversational efficiency or task-driven indicators (for example success rate, average turns, proactivity, explainability, consistency), along with simulator believability and memory believability in simulation settings. The paper concludes with future directions centered on better system architecture integration and multi-agent collaboration, more unified and practical evaluation frameworks that also consider privacy and security, and stronger defenses against adversarial attacks on LLM-empowered recommender systems.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/codex/gpt-5.2",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}