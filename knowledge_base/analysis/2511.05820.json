{
  "paper_id": "2511.05820",
  "title": "War-Re Web Api Recommendation",
  "category": "mini_program_service",
  "status": "success",
  "summary": "WAR-Re: Web API Recommendation with Semantic Reasoning proposes an LLM-based approach to Web API recommendation that adapts how many APIs it returns per mashup and explains each recommendation with a semantic justification. The paper frames two main gaps in prior work: fixed top-N outputs that do not match mashup complexity, and opaque ranked lists that provide no reasons, reducing trust and usability. *we propose WAR-Re, an LLM-based model for Web API recommendation with semantic reasoning for justification.*\n\nWAR-Re builds on a TinyLlama backbone and is trained on mashup descriptions paired with the APIs historically used, then augmented with LLM-generated explanations to supply per-API rationales grounded in API function descriptions. It uses special generation delimiters to control output structure and boundaries, including <API_start> and <API_stop> for the recommended API sequence and <REASON_start> and <REASON_stop> for the reasoning section, and it adds each API name as a single token to avoid tokenization fragmentation. Training is two-stage: supervised fine-tuning with standard cross-entropy next-token prediction, followed by online reinforcement learning via GRPO with LoRA to improve both recommendation accuracy and alignment between recommended APIs and their reasons.\n\nExperiments on a ProgrammableWeb-derived dataset with 8217 mashups and 1647 APIs compare WAR-Re to MTFM, BERT-CM, SEHGN, and LLMAR using information retrieval metrics and new reasoning-focused metrics. Key findings include:\n- Recommendation gains: WAR-Re reports improvements over baselines, including up to 21.59% over BERT-CM on Recall@1, and strong ranking quality with NDCG and MAP; under greedy decoding it averages 1.79 APIs per output, with 52.22% exact matches to ground truth and a noted maximum of 31 correct recommended APIs in one case. *Comprehensive experimental evaluations on the ProgrammableWeb dataset demonstrate that WAR-Re achieves a gain of up to 21.59% over the state-of-the-art baseline model in recommendation accuracy*\n- Reasoning quality: 87.88% of recommended APIs have accompanying rationales, with average RP 0.908 and RR 0.912; an LLM-judged Reasoning Score averages 0.790 across DeepSeek-R1, Llama 3.3, and GPT-4.1 Mini evaluators.\n- Ablations: removing GRPO reduces both recommendation and reasoning metrics; removing special tokens increases output length but lowers precision and reasoning coverage; omitting the reasoning task weakens recommendation quality, and recommendations with explanations substantially outperform those without across reported metrics.\n\nThe conclusion argues that variable-cardinality generation plus justification improves both accuracy and accountability, and suggests future work scaling the underlying language model to expand real-world applicability.",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/mini_program_service/2511.05820_WAR-Re_Web_API_Recommendation.pdf"
}