{
  "paper_id": "1707.07835",
  "title": "Semantic Query Segmentation",
  "category": "product_matching",
  "status": "success",
  "summary": "The paper frames query segmentation as a core step for inferring search intent by grouping adjacent tokens into meaningful phrases, improving downstream retrieval and relevance (especially when phrase order matters). It proposes a supervised segmentation method that replaces hand-engineered NLP and heuristic features with low-dimensional query embeddings: for each adjacent token pair in a query, their embedding vectors are concatenated and fed to a binary classifier that predicts whether a boundary should exist between them. *We propose a supervised approach to the segmentation task using low-dimensional feature vectors for queries, getting rid of traditional hand tuned and heuristic NLP features.*\n\nExperiments benchmark on two 50,000-query human-annotated corpora: a web search dataset derived from the AOL query logs (with a 60-20-20 train/val/test split) and a newly annotated eBay eCommerce dataset (80-20 train/test, with train further split for validation). Embeddings are trained on query logs (notably using small context windows around 2â€“3 for short queries), with 300-dimensional vectors and 600-dimensional pairwise features; Logistic Regression and XGBoost perform best among tried classifiers. Key results reported:\n- AOL web queries: naive n-gram baseline reaches segmentation accuracy 0.677 and query accuracy 0.351, while Logistic Regression on learned embeddings reaches 0.731 and 0.418.\n- AOL with pretrained embeddings + XGBoost: best is GloVe web crawl at 0.811 segmentation accuracy and 0.552 query accuracy (other pretrained options like Google News word2vec and FastText Wikipedia are close).\n- eBay queries: naive n-gram gets 0.713 segmentation accuracy and 0.578 query accuracy, while FastText + XGBoost improves to 0.796/0.677 (skip-gram) and 0.799/0.683 (cbow), with cbow best overall.\n\nThe discussion emphasizes annotation ambiguity and domain knowledge as practical challenges, especially for eCommerce where intent can hinge on product, brand, or attribute understanding; annotator agreement on eBay is reported as about 77% for at least 2 of 3 annotators agreeing, but only about 25% unanimous agreement. The authors argue embedding-based methods are less brittle than n-gram frequency approaches to word-order variations (illustrated with reordered product-line queries) and can implicitly tolerate common spelling issues due to contextual training. *We found eCommerce queries are harder for a crowd sourcing annotation task because of the lack of product and domain knowledge.* Future work proposed includes analyzing segmentation quality relative to specific downstream tasks and augmenting learning with structured eCommerce dictionaries (brands, colors, styles, aspects), analogous to prior work that boosted segments using Wikipedia titles.",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/1707.07835_semantic_query_segmentation.pdf"
}