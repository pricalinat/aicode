{
  "paper_id": "2108.06367",
  "title": "Multi Objective Tutorial",
  "category": "ecommerce_evaluation",
  "year": 2021,
  "timestamp": "2026-03-01T14:02:30.156572",
  "summary": "## Summary\n\nThis document is a tutorial-style overview of multi-objective optimization MOO and how it applies to recommender systems, written as supplementary material for a SIGKDD 2021 tutorial. It frames many real decisions and recommendation tasks as inherently multi-objective, where improving one goal often harms another, and it sets up the core MOO language used throughout: decision variables, feasible solution sets, objective vectors, dominance relations, Pareto optimality, Pareto sets, and Pareto fronts. It also distinguishes how the decision maker DM participates in the process, since that determines whether the goal is to output a single Pareto-optimal solution or a whole Pareto set and then choose from it.\n\n*It is required to find a point x, y such that, in whatever direction we take an infinitely small step, P and Î , do not increase together, but that, while one increases, the other decreases.*\n\n## Key MOO concepts and methods\n\nAfter motivating examples from finance and recommendation evaluation metrics, the tutorial formalizes MOO as optimizing multiple objective functions under constraints, then introduces dominance as the way to compare solutions when objectives conflict. A solution is Pareto optimal non-dominated if no other feasible solution is at least as good in all objectives and strictly better in at least one, and the Pareto front is the objective-space image of the Pareto set. It outlines four DM involvement modes: a priori weights fixed up front, a posteriori choose after seeing a Pareto set, interactive preferences expressed during search, and no DM available.\n\nThe tutorial groups MOO algorithms into two main families. Scalarization methods convert multiple objectives into a single objective, often requiring multiple runs with different settings to approximate a Pareto set when preferences are unknown; it discusses weighted-sum and related weighting variants, epsilon-constraint, and NBI or NC methods, emphasizing conditions and pitfalls such as convexity requirements and the possibility of missing parts of a non-convex Pareto front. MOEA methods are population-based heuristics that can generate a diverse Pareto set in one run, and the tutorial explains core evolutionary algorithm mechanics encoding, selection, variation, elitism plus major MOEA approaches including VEGA, MOGA, NSGA, NSGA-II, NPGA, and PAES, along with diversity maintenance via niche counts and fitness sharing.\n\n## Choosing one solution and applying MOO to recommender systems\n\nBecause many applications ultimately need one deployed solution, the tutorial surveys ways to pick a single point from a Pareto set when DM preferences are unavailable or impractical. It highlights knee point selection as a compromise zone, hypervolume-based selection and evaluation, and MCDM approaches such as TOPSIS and PROMETHEE, noting that equal objective preferences can be assumed if needed. It also lists several open-source MOO libraries across Python, Java, Matlab, and C++ and notes that scalarization can often rely on standard single-objective optimizers rather than specialized libraries.\n\nIn the recommender-systems section, the tutorial contrasts traditional single-objective optimization with growing demand for multi-objective formulations, and it organizes multi-objective recommendation work into six contexts: balancing multiple metrics like accuracy, diversity, novelty; user-based collaborative filtering neighborhood selection; preprocessing steps such as clustering or association rule mining; group recommendation balancing individual satisfaction and fairness; multi-stakeholder systems balancing utilities across users, providers, and platforms; and multi-task recommenders jointly optimizing multiple tasks or feedback signals with shared representations. It closes with a suggested workflow: clearly define objectives, use scalarization when preferences exist, otherwise generate a Pareto set via scalarization or MOEA and then apply a principled selection method, while calling out practical challenges such as method choice, selection strategy, defining balance without explicit preferences, and reporting multi-objective effectiveness rather than only single-metric gains.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/codex/gpt-5.2",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}