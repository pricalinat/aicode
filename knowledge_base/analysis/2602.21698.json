{
  "paper_id": "2602.21698",
  "title": "E-Comiq-Zh Poster Benchmark",
  "category": "ecommerce_evaluation",
  "year": 2026,
  "timestamp": "2026-03-01T13:59:10.342912",
  "summary": "E-comIQ-ZH introduces a human-aligned framework for evaluating Chinese e-commerce posters with fine-grained, functional criteria rather than generic aesthetics or low-level distortion metrics. It contributes three linked artifacts: E-comIQ-18k (an 18,000-image dataset with expert scores and expert-verified chain-of-thought rationales), E-comIQ-M (a domain-specific automated evaluator trained to match expert judgment), and E-comIQ-Bench (a scalable benchmark to compare poster-generation systems on realistic cases). The work argues that Chinese poster assessment is especially hard because dense typography and complex characters create subtle but commercially critical text errors that many existing evaluators miss.\n\nE-comIQ-18k scores each poster on four dimensions plus an overall score, emphasizing practical usability: Object (product integrity and visibility), Background (scene compatibility), Text (legibility and correctness of overlaid marketing copy), and Layout (composition and hierarchy). The dataset is sourced from six streams, combining real merchant originals labeled high or low quality with open-source posters, AI-generated posters, AI-edited template-like compositions, and professionally designed posters; it is split into 15k train, 2k validation, and 1k test. Annotation is done by domain experts using a detailed checklist and issue tags, and chain-of-thought rationales are produced via a humanâ€“AI workflow where an MLLM drafts rationales and the original annotator edits to remove hallucinations and add domain detail; reported inter-annotator reliability reaches Krippendorff alpha 0.858 overall, with high loose accuracy within a 0.5 margin.\n\nE-comIQ-M is built by fine-tuning a multimodal model (Qwen2.5-VL-7B-Instruct) to output dimension scores in a structured format, trained in two stages: supervised fine-tuning on expert scores and rationales, then GRPO reinforcement learning on a curated hard subset to improve calibration. On the E-comIQ-18k test set, it outperforms traditional no-reference IQA models, general-purpose MLLMs, and several specialized evaluators in both correlation and accuracy metrics, with particularly notable gains on Text and Layout where fine-grained typography defects matter. E-comIQ-Bench evaluates leading generators on 500 test cases (cutout, original merchant poster, and a Chinese prompt) and finds that backgrounds and layouts are often strong while text rendering remains the main bottleneck; it also reports that OCR-style text metrics can disagree with human judgment because subtle stroke-level corruption may still be OCR-readable but commercially unacceptable.\n\n*We introduce E-comIQ-18k, a framework for evaluating Chinese e-commerce posters.*  \n\n*Text is the bottleneck in 44.8% of cases.*",
  "llm_info": {
    "provider": "cli",
    "model": "cli/codex/gpt-5.2",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}