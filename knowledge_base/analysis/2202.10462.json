{
  "paper_id": "2202.10462",
  "title": "Ctr Advertising",
  "category": "ecommerce_evaluation",
  "year": 2022,
  "timestamp": "2026-03-01T13:50:37.562247",
  "summary": "# Click-Through Rate Prediction in Online Advertising: A Literature Review\n\n## Overview\n\nThis paper presents a comprehensive literature review of click-through rate (CTR) prediction in online advertising, analyzing 132 articles published from 2007 to 2021. CTR prediction estimates the probability that a user will click on a specific advertisement, making it fundamental to the online advertising ecosystem's sustainable development. The review identifies four major categories of prediction models, compares their performance across benchmark datasets, and outlines future research directions.\n\n## Research Background and Scope\n\nOnline advertising has become a dominant sector in the advertising industry, with the US market growing from $124.6 billion in 2019 to $139.8 billion in 2020, and projected to reach $982.82 billion by 2025. The review covers publications from six major academic databases: Web of Science, ACM, IEEE, EBSCOhost, ScienceDirect, and ABI/Inform Global, focusing specifically on CTR prediction in online advertising contexts rather than recommender systems or web search.\n\n*Publications on CTR prediction have been increasing exponentially since 2007, reaching a peak in the past five years*\n\n## CTR Prediction Models\n\n### Feature Categories\n\nCTR prediction models leverage five types of features: advertising features (ad ID, creative ID, keywords), user features (gender, age, region), context features (device, OS, time), query features (keywords, category), and publisher features (site, section, URL).\n\n### Model Categories\n\n**Multivariate Statistical Models** include logistic regression (LR), which provides interpretable results but fails to capture feature interactions, and degree-2 polynomial (Poly2), which models pairwise feature interactions but struggles with sparse data.\n\n**Factorization Machines (FM) Based Models** address sparse data problems through parameter factorization. Field-aware Factorization Machines (FFMs) consider that features behave differently across fields, while Field-weighted FMs (FwFMs) combine FFM advantages with fewer parameters.\n\n**Deep Learning Models** represent high-order feature interactions through architectures like LSTM for sequential behaviors, CNN for local feature patterns, FNN combining FM with neural networks, and DeepFM unifying low-order and high-order feature learning.\n\n**Tree Models** including GBDT and XGBoost use gradient boosting to handle feature interactions automatically, though they underperform on high-dimensional sparse data.\n\n*High-order models usually perform better than low-order models, although a few inconsistent results exist*\n\n## Performance Evaluation\n\nThe most frequently used public datasets are Criteo-Kaggle Display Advertising Challenge 2014, Avazu, and KDDCUP 2012 Track 2. Evaluation metrics primarily include AUC-ROC, Logloss, RMSE, precision, recall, F1-score, and Relative Information Gain.\n\nPerformance comparisons reveal that FM-based models generally outperform LR and Poly2, deep learning models outperform FM-based approaches, and ensemble methods like DeepFM combining FM and DNN achieve strong results. However, inconsistent findings exist in the literature, particularly regarding DeepFM versus PNN comparisons.\n\n## Challenges and Future Directions\n\n### Current Challenges\n\nFeature engineering remains heavily dependent on manual expertise, making large-scale implementation difficult. Sample imbalance between clicks and non-clicks affects classifier performance. Cold-start problems arise for new advertisements with limited historical data. Data sparsity from high-dimensional categorical features and advertising heterogeneity causing overfitting also present significant challenges.\n\n### Future Research Directions\n\nGraph Neural Networks (GNN) can integrate powerful feature interactions and address cold-start problems through graph structures connecting advertisements. Neural Architecture Search enables adaptive embedding dimensions for each field. Explicit high-order feature interaction models like DCN and CIN require further development. Understanding user behaviors through sequential modeling and attention mechanisms, along with multimedia advertising features, represent promising research avenues.\n\n## Conclusion\n\nThis review provides fundamental knowledge for researchers entering CTR prediction research, covering approximately 175 models evaluated across 9 public datasets. The authors recommend conducting systematic comparison studies to reconcile inconsistent results reported across studies and establishing standardized computational protocols for fair model comparisons.\n\n*This review is expected to provide fundamental knowledge and efficient entry points for IS and marketing scholars who want to engage in this area*",
  "llm_info": {
    "provider": "cli",
    "model": "cli/claude/sonnet",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}