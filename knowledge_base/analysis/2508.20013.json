{
  "paper_id": "2508.20013",
  "title": "Cross Platform Categorization",
  "category": "product_matching",
  "status": "success",
  "summary": "The paper presents an industrial, cross-platform approach to e-commerce product categorization that targets two persistent problems: platform heterogeneity and structural limitations of standard taxonomies, especially uneven depth across branches. It focuses on fashion and uses a large real-world dataset of 271,700 products from 40 international platforms, all mapped into the Google Product Taxonomy under *Apparel and Accessories*, where branches like *Shoes* are comparatively shallow and long-tail imbalance is severe. The work is motivated by deployment needs at EURWEB, where inconsistent breadcrumbs and noisy metadata across retailers degrade downstream analytics such as forecasting and cross-platform category attribution.\n\nMethodologically, it builds a multimodal hierarchical classifier that combines text and images and enforces taxonomic validity during inference. Text signals come from RoBERTa embeddings of titles and brands, visual signals come from ViT embeddings with PCA to reduce cost, and joint representations come from CLIP embeddings; these are evaluated under early fusion, late fusion with MLP transformations, and attention-based fusion. A key architectural element is hierarchical prediction with dynamic masking, which constrains each deeper-level softmax to valid children of the predicted parent category. In reported results, CLIP-based late fusion is the top performer on the full cross-platform setting, reaching hierarchical F1 98.59 and very high macro F1 at Levels 2 to 4, while more complex attention fusion does not consistently beat simpler late fusion despite higher cost.\n\n*Results show that CLIP embeddings combined via an MLP-based late-fusion strategy achieve the highest hierarchicalF1(98.59%), outperforming unimodal baselines.* Beyond classification, the paper introduces a scalable recategorization pipeline to refine underdeveloped branches, using self-supervised visual embeddings with SimCLR, dimensionality reduction via UMAP, and cascade clustering to discover new fine-grained subcategories within a broad node like *Shoes*; reported cluster purities are generally above the mid-80s and remain stable when retraining and testing on noisier data. Cross-platform generalization experiments also surface a deployment-relevant trade-off: models that maximize accuracy with diverse training data can generalize worse to unseen platforms than simpler fusion schemes, with CLIP early fusion showing stronger robustness when trained on a single platform and tested on others.\n\n*This cascading design reduced GPU overhead while improving category standardization, enabling more reliable forecasting and cross-platform analytics.* For production, the paper describes EURWEB integration via a two-stage inference pipeline: a lightweight RoBERTa stage processes most products weekly, and only low-confidence cases are escalated to a GPU-deployed multimodal model, balancing latency and cost with higher fidelity on ambiguous items. The conclusion emphasizes that multimodal hierarchical modeling plus recategorization can improve discoverability, recommendations, inventory analytics, and long-tail handling, and it outlines future extensions such as other retail verticals, multilingual deployment, and combining self-supervised recategorization with LLM-based taxonomy work while strengthening methods for extreme imbalance and multimodal masking.",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2508.20013_cross_platform_categorization.pdf"
}