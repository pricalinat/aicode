{
  "paper_id": "2407.18540",
  "title": "Text To Process Llm",
  "category": "mini_program_service",
  "year": 2024,
  "timestamp": "2026-03-01T13:54:31.797899",
  "summary": "# Summary: LLM-Based Process Information Extraction\n\nThis paper presents a systematic investigation into using Large Language Models (LLMs) for extracting process-relevant information from natural language business process descriptions. The researchers developed a novel prompting strategy that outperforms existing state-of-the-art machine learning and rule-based approaches by up to 8% in F1 score across three benchmark datasets.\n\n## Core Problem and Motivation\n\nBusiness process models are essential tools for enterprise process management, but manually creating them is time-consuming, accounting for approximately 60% of total process management time. The researchers address the challenge of automatically extracting process information from textual sources like process descriptions, rules, and work instructions. The extraction involves three key subtasks: Mention Detection (identifying activities, actors, and business objects in text), Entity Resolution (recognizing when different mentions refer to the same entity), and Relation Extraction (detecting relationships between mentions such as sequential dependencies and actor assignments).\n\nThe motivation stems from limitations in existing approaches. Rule-based systems require extensive understanding of processes and are difficult to transfer across organizations. Machine learning techniques are hampered by data scarcity—the largest available dataset contains only 45 human-annotated process descriptions. While some prior work explored LLMs like GPT-3, it presented only preliminary studies with limited analysis.\n\n## Novel Prompting Strategy\n\nThe researchers designed a modular prompting framework consisting of three components: Context, Task Description, and Restrictions. The Context module employs a persona design pattern, assigning the LLM the role of a business process modeling expert, combined with a context manager that frames the extraction task at a high level. The Task Description module creates a meta-language defining element types to extract and uses chain-of-thought reasoning to break extraction into steps—first extracting mentions, then predicting relations, and finally generating justifications. The Restrictions module provides disambiguation hints, format instructions, and few-shot examples that teach the LLM how to perform the task.\n\nAn ablation study revealed that format examples significantly impact performance, reducing parsing errors by 919 instances for mention detection and improving F1 by 0.22. Chain-of-thought reasoning and disambiguation hints also proved beneficial, while the persona and context manager had minor effects.\n\n## Experimental Results\n\nExperiments were conducted on three datasets: PET (45 documents, the largest available), DECON (17 documents with declarative constraints), and ATDP (18 documents). Using GPT-4o, the approach achieved a 5% absolute F1 improvement for mention detection, 22% for entity resolution, and 17% for relation extraction on the PET dataset compared to machine learning baselines. For the DECON dataset, relation extraction improved by 8% F1 over rule-based systems.\n\nThe prompting strategy was tested across eight LLMs including GPT-4o, GPT-4, Claude 3 Opus, Claude 3 Sonnet, Llama 3 70B Instruct, and Qwen1.5 72B Chat. Claude 3 Opus performed comparably to GPT-4, while Llama 3 70B Instruct showed viability in few-shot settings. Notably, GPT-4o achieved strong results in zero-shot mode without any labeled examples, rivaling machine learning models trained on 36 manually annotated documents.\n\n## Practical Implications and Lessons Learned\n\nThe research demonstrates that LLMs can serve as effective tools for business process information extraction even without training data, enabling organizations to automate model creation without manually annotated examples. Key findings include that one to three examples provide the best cost-value tradeoff, and limiting prompt components like the context manager and persona can reduce tokens without significant accuracy loss. The LLM's ability to provide reflective justifications makes it valuable for human-in-the-loop systems where practitioners need to validate extractions.\n\nLimitations include potential hallucinations in some models (Qwen1.5 and Llama 3 produced 20 and 37 non-existent entity types respectively in worst cases), though this diminished in few-shot settings. The cost of API-based LLMs also prohibits large-scale application, making open-weight alternatives necessary despite their higher data requirements.\n\n*GPT-4o is able to match and outperform the machine learnt baseline without any labeled data*, highlighting the transformative potential for practitioners across business domains who lack manually annotated training examples.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/claude/sonnet",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}