{
  "paper_id": "1806.08211",
  "title": "Cr Prediction",
  "category": "product_matching",
  "year": 2018,
  "timestamp": "2026-03-01T14:53:52.343549",
  "summary": "*Reacting to Variations in Product Demand: An Application for Conversion Rate Prediction in Search Commerce* presents three approaches to make conversion rate prediction more responsive when product demand shifts sharply over time, such as seasonal spikes, new product launches, or price changes. The authors argue that a standard L2-regularized logistic regression baseline can be slow to adapt, leading to underprediction during demand surges and overprediction during demand drops, which can translate into missed revenue or wasted spend. The work is grounded in a real production setting from Criteo Predictive Search, where models must update quickly and score very large catalogs at high volume.\n\nThe paper defines the baseline learning setup and evaluation protocol, then introduces metrics focused on probabilistic fit rather than classification accuracy. It uses Log Likelihood Normalized, abbreviated LLHN, which compares a model against a constant-probability naive predictor, plus LLHN-Uplift to report relative gains over the baseline. For longitudinal evaluation, it simulates daily production retraining by training each dayâ€™s model only on data preceding that day, using click and conversion logs enriched with product, user behavior, context, and cost signals.\n\nThe three proposed models combine demand signals, weighting, and ensembling to react faster to changing conditions:\n- **HCRFM** adds a historic conversion rate feature computed at the seller level from recent calendar days to capture demand movement.\n- **TDWM** applies exponential time-decay importance weights so recent examples count more during training, with a half-life tuned experimentally and an adjusted regularization rule.\n- **MLTSTM** mixes a short-term model and a long-term model, combining their predictions with an average weighting factor to balance recency and stability.\n\nTo quantify demand variation, the authors define a Normalized Variation Index, abbreviated NVI, as the ratio of a 7-day conversion rate to the preceding 30-day conversion rate, then classify periods as moderate, average, or extreme based on how far NVI is from 1. In controlled tests across five selected sellers, the results generally show larger LLHN-Uplift when demand variation is more extreme, with the mixture model often dominating under extreme and average conditions, and occasional small regressions under moderate conditions. A broader study across all US sellers during a 7-day Black Friday period reports positive aggregate uplift for TDWM and MLTSTM, with MLTSTM achieving the largest uplift at 3.2 percent, and the strongest gains concentrating among the highest-variation sellers. The conclusion emphasizes that prioritizing recent data and blending short- and long-term signals improves robustness under sudden demand shifts, and suggests exploring non-linear methods like gradient boosting decision trees and convolutional neural networks under the same production constraints.\n\n*In this work, we proposed three CR prediction models which are robust to variations in product demand.*\n\n*We call this metric the Normalized Variation Index NVI.*",
  "llm_info": {
    "provider": "cli",
    "model": "cli/codex/gpt-5.2",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}