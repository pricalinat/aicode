{
  "paper_id": "2203.00964",
  "title": "Pkgm",
  "category": "product_matching",
  "status": "success",
  "summary": "This paper proposes PKGM, a pre-trained knowledge graph model designed to provide item knowledge services for large-scale e-commerce applications without requiring downstream systems to query raw knowledge graph triples. The motivation is that triple-based knowledge services create heavy manual work for selecting relevant triples and redesigning task models, and they suffer when the product knowledge graph is incomplete, which can mislead downstream tasks. The authors aim to make product knowledge accessible in a uniform vector form and implicitly complete missing facts so downstream tasks can benefit even with limited training data.\n\nPKGM is trained on a billion-scale Product Knowledge Graph built for Taobao and related Alibaba platforms, described as containing on the order of tens to hundreds of billions of triples and millions of rules. The core design includes two query modules that mimic common knowledge graph access patterns in vector space: a Triple Query Module for predicting likely tail entities given a head entity and relation, and a Relation Query Module for judging whether a relation exists or should exist for an entity. The triple module uses a TransE-style translation assumption so that head plus relation approximates tail, while the relation module learns a relation-specific transformation matrix so that transformed head embeddings align with the relation embedding when the relation holds; the relation service vector is near a zero vector to indicate existence. Training uses a margin-based ranking loss with negative sampling, and the paper emphasizes two main advantages: independence from directly serving triple data and the ability to complete missing knowledge implicitly through embedding inference.\n\nAfter pre-training, PKGM produces service vectors per item: predicted tail embeddings for key relations from the triple module, and relation-existence vectors from the relation module. The paper proposes two general integration patterns for downstream models: for sequence-embedding models, append service vectors to the input embedding sequence so the model can attend to them; for single-embedding models, condense or concatenate service vectors with the original item embedding. Experiments cover five tasks: item classification and item resolution using BERT-based text models, item recommendation using Neural Collaborative Filtering, scene detection using image encoders like ResNet and MobileNetV2, and sequential recommendation using a FISSA-style model. Across these tasks, PKGM-enhanced variants generally improve metrics, with gains often larger on smaller or sparser datasets; results repeatedly suggest relation-query service vectors are especially helpful for classification and recommendation, while triple-query vectors can be strongest in some sequential recommendation settings.\n\n*we propose a Pre-trained Knowledge Graph Model PKGM for the billion-scale product knowledge graph*\n\n*PKGM could provide knowledge services to enhance other tasks with item knowledge contained in PKG without accessing triple data*",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2203.00964_pkgm.pdf"
}