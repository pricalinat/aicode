{
  "paper_id": "2412.01378",
  "title": "Dnn Cf Survey",
  "category": "product_matching",
  "status": "success",
  "summary": "This survey reviews how deep neural networks improve collaborative filtering recommender systems, motivated by limits of traditional approaches in scalability, flexibility, and capturing complex user item interactions. It positions collaborative filtering as learning from historical user item interactions, explains matrix factorization as the classic baseline, and highlights a core difficulty with implicit feedback where a 0 may mean unknown rather than dislike. *Deep neural networks have revolutionized collaborative filtering by addressing several critical system challenges.*\n\nThe paper organizes roughly 80 papers from 2020 to 2024 into a structured taxonomy of DNN architectures used for collaborative filtering: MLP, CNN, RNN, GNN, autoencoders, GAN, and RBM. It summarizes how each family is used and what it tends to solve, such as MLP based neural collaborative filtering for nonlinear interaction modeling and variants that target interpretability, sparsity, cross domain explicit plus implicit signals, and privacy via federated learning; CNN approaches for co occurrence pattern extraction, review or context matching, and adversarial robustness; RNN based models such as LSTM and GRU for sequential and context aware recommendation; GNN based methods for user item bipartite graphs with themes like contrastive learning, high order connectivity, denoising unreliable interactions, knowledge graph fusion, and improved interpretability; autoencoders including many VAE variants for implicit Top N recommendation, robustness, and scalable training; GANs for generating or augmenting interaction data and improving one class learning; and RBM variants for rating modeling and faster retraining via parallelization. *Future research on DNN-based collaborative filtering recommendation systems should focus on enhancing scalability and efficiency to handle larger datasets.*\n\nIt also consolidates common experimental practice: frequently used datasets include MovieLens, Amazon reviews subsets, Pinterest, Yelp, Gowalla, and LastFM, and it lists typical statistics like users, items, ratings, and very high sparsity. Evaluation is summarized around ranking metrics such as Recall@k, NDCG@k, and HR@k, plus rating error metrics like RMSE and MAE. The closing discussion frames ongoing challenges and opportunities around sparsity and cold start, robustness to attacks, privacy preserving training, interpretability, and richer personalization using context and multimodal auxiliary information.",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2412.01378_dnn_cf_survey.pdf"
}