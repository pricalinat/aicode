{
  "paper_id": "2509.15858",
  "title": "Multimodal Deduplication",
  "category": "product_matching",
  "status": "success",
  "summary": "This paper presents a scalable product deduplication system for large e-commerce marketplaces, motivated by how duplicate listings confuse customers, inflate operational costs, and disrupt Buy Box management by splitting seller competition across multiple listings. The authors argue that keyword and exact-match approaches miss semantic equivalence in product titles, and that generic pretrained multimodal models can be too slow and memory-heavy at marketplace scale. Their core contribution is an efficiency-first, domain-specific multimodal pipeline that produces compact embeddings and uses a dedicated decision model to classify whether two listings are the same product.\n\nThe approach combines separate lightweight models for text and images, both compressed to 128-dimensional vectors to reduce storage and indexing overhead without large accuracy loss. For text, they build on BERTurk and improve representation quality by aggregating selected intermediate transformer layers with convolutional processing before compression, motivated by evidence that key title information is usually front-loaded and fits within a fixed token budget. For images, they move from an EfficientNetV2 autoencoder to a Masked Autoencoder with a DeiT backbone, adding structured patch selection to preserve central and fine-grained details important in commerce imagery, and they incorporate data augmentation to improve robustness to scale and padding differences.\n\nExperiments use a large internal Hepsiburada dataset and compare against a commercial black-box API baseline, with the final system designed around vector search in Milvus plus a classifier-style decider that consumes two text vectors and two image vectors to output a confidence score. Key reported outcomes include:\n- Macro-average F1: 0.90 vs 0.83 baseline, with the biggest gain in Match recall (0.85 vs 0.73), while keeping strong NotMatch performance\n- Scalability: indexing 10 million 128-d vectors at about 5.5 GB RAM, supporting catalogs in the hundreds of millions of items with modest memory\n- Speed: embedding generation for 1,000 product pairs reported as much faster than larger VLM-style alternatives\n\n*Our model achieves a macro-average F1 score of 0.90, demonstrating a significant and robust improvement over the third-party solutionâ€™s score of 0.83.*  \n\n*the memory footprint for indexing 10 million of our 128-dimensional vectors is a manageable 5.5 GB.*  \n\nThe error analysis highlights a recurring failure mode: visually similar but operationally distinct variants (for example, subtle packaging or minor design changes) can be incorrectly grouped as duplicates. The conclusion emphasizes that compact, domain-adapted multimodal embeddings plus a classifier decider can deliver practical accuracy, latency, and memory tradeoffs in production, and it points to future work such as integrating product attributes, extending to other languages, and developing lighter or more unified multimodal modeling.",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2509.15858_multimodal_deduplication.pdf"
}