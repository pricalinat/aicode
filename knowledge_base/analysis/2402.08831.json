{
  "paper_id": "2402.08831",
  "title": "Ecellm",
  "category": "product_matching",
  "year": 2024,
  "timestamp": "2026-03-01T13:39:23.939255",
  "summary": "# eCeLLM: Generalizing Large Language Models for E-commerce\n\nThis paper presents eCeLLM, a series of e-commerce large language models developed by instruction-tuning general-purpose LLMs on a new benchmark dataset called ECInstruct. The research addresses two key challenges in conventional e-commerce models: limited success in generalist e-commerce modeling and unsatisfactory performance on new users and new products (the cold-start problem).\n\n## ECInstruct Dataset\n\nThe researchers constructed ECInstruct, the first open-sourced, large-scale, and high-quality benchmark instruction dataset for e-commerce. It contains 116,528 samples across 10 real-world e-commerce tasks organized into 4 categories: product understanding, user understanding, query-product matching, and product question answering.\n\nThe 10 tasks include attribute value extraction, product matching, product relation prediction, sentiment analysis, sequential recommendation, multi-class product classification, product substitute identification, query-product ranking, answerability prediction, and answer generation. Each task includes 6 diverse instructions (1 seed instruction, 4 GPT-4 generated variants, and 1 held-out \"unseen\" instruction for testing generalization). The dataset undergoes rigorous quality control including data deduplication between training/test splits, English-only filtering, removal of non-English notations, and manual inspection.\n\n## Model Architecture\n\neCeLLM models were developed by instruction-tuning 6 base models across three size categories: large models (Flan-T5 XXL 11B, Llama-2 13B-chat), medium models (Llama-2 7B-chat, Mistral-7B Instruct), and small models (Flan-T5 XL 3B, Phi-2). Training used LoRA with a learning rate of 1e-4, batch size of 128, cosine scheduler with 5% warm-up over 3 epochs.\n\n## Experimental Results\n\nThe comprehensive evaluation demonstrates that eCeLLM substantially outperforms baseline models across almost all 10 tasks, achieving an average improvement of 10.7% over the best baseline models in in-domain evaluation. In out-of-domain settings with unseen products, eCeLLM shows a 9.3% improvement over baselines, highlighting its superior generalizability for addressing the cold-start problem in e-commerce.\n\n*With instruction tuning using our high-quality ECInstruct, eCeLLM-L could outperform GPT-4 Turbo in distinguishing products, estimating user preferences, and understanding product attributes.*\n\nThe experiments also reveal that training on diverse instructions significantly improves generalization to unseen instructions, and larger training data sizes consistently improve model performance. Generalist eCeLLM models trained on all tasks together perform comparably or better than task-specific models, demonstrating successful knowledge transfer across e-commerce tasks.\n\nThe ECInstruct dataset and eCeLLM models are publicly accessible through the project website.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/claude/sonnet",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}