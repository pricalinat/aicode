{
  "paper_id": "2507.14352",
  "title": "Bundle Fairness",
  "category": "ecommerce_evaluation",
  "year": 2025,
  "timestamp": "2026-03-01T13:54:47.648403",
  "summary": "# Summary: Product-Side Fairness in Bundle Recommendation\n\nThis paper presents the first comprehensive reproducibility study of product-side fairness in bundle recommendation (BR), examining how fairly current BR methods allocate exposure to both bundles and the individual items they contain. The research addresses a critical gap in recommender systems fairness literatureâ€”while fairness has been extensively studied in traditional single-item recommendation, its implications for bundle recommendation remain largely unexplored.\n\n## Research Context and Methodology\n\nBundle recommendation is an emerging task where systems recommend sets of items grouped together as meaningful packages, commonly seen in e-commerce (fashion outfits, electronic kits), digital media (curated playlists), and services (meal packages). Unlike single-item recommendation, BR introduces additional complexity: recommendations are generated at the bundle level, yet user satisfaction and product exposure depend on both the bundle itself and the individual items it contains.\n\nThe researchers implemented a thorough empirical study using four state-of-the-art BR methods (CrossCBR, MultiCBR, EBRec, and BunCa) across three benchmark datasets from diverse domains: Youshu (book lists), NetEase (music playlists), and iFashion (fashion outfits). They employed six widely adopted exposure fairness metrics measuring both bundle-level and item-level disparities, including Expected Exposure Loss (EEL), Expected Exposure Relevance (EER), Expected Exposure Disparity (EED), Demographic Parity (DP), Exposed Utility Ratio (EUR), and Realized Utility Ratio (RUR).\n\n## Key Findings\n\nThe study uncovered several important patterns regarding fairness in bundle recommendation systems.\n\nFirst, exposure patterns differ notably between bundles and items. The distribution of exposure in historical interaction data and in BR outputs differs significantly between these two levels, revealing that fairness interventions cannot rely solely on bundle-level assumptions and must consider item-specific dynamics.\n\n*Exposure patterns in the input data and recommendation outputs often diverge between bundle and item levels, indicating that bundle-level popularity does not necessarily predict item-level popularity.*\n\nSecond, fairness assessments vary considerably depending on the metric used. No single BR method consistently performed best across all fairness metrics, and bundle-level fairness did not necessarily translate to item-level fairness. This reinforces the need for multi-faceted evaluation approaches.\n\nThird, user behavior plays a critical role in fairness outcomes. When users interact more frequently with bundles than with individual items, BR systems tend to yield fairer exposure distributions at both levels. The researchers grouped users into three categories based on their interaction tendencies: bundle-oriented users (g1), neutral users (g2), and item-oriented users (g3). Results showed that bundle-oriented users received fairer exposure distributions according to EEL and EER metrics.\n\n*When users engage more with bundles rather than individual items, BR methods produce more equitable exposure distributions across both bundle and item levels.*\n\nFourth, BR methods typically amplify existing popularity bias from input data. Using Gini Index measurements, the researchers found that BR methods generally decrease the uniformity of exposure compared to input data, with datasets exhibiting less uniform interaction distributions tending to produce less uniform exposure distributions in recommendations.\n\n## Implications and Conclusions\n\nThe findings highlight the complex nature of fairness in bundle recommendation and the need for more targeted strategies. The study establishes that achieving fairness at the bundle level does not automatically ensure fairness at the item level, requiring explicit consideration of both dimensions. The research also demonstrates that different fairness metrics often disagree in their assessments, making it essential to evaluate using multiple perspectives rather than relying on a single metric.\n\nThe authors note that the iFashion dataset (where bundles are more elaborately constructed outfits based on provider strategies) showed more consistent fairness performance across user groups compared to Youshu and NetEase (where bundles are simply grouped by user sessions), suggesting that how bundles are constructed affects fairness outcomes.\n\nThis work provides actionable insights for building fairer bundle recommender systems and establishes a vital foundation for future research in this emerging domain. Future work could explore fairness beyond popularity-based groupings, examining item categories, supplier identities, or sensitive attributes to develop more holistic fairness-aware BR methods.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/claude/sonnet",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}