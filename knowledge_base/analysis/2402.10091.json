{
  "paper_id": "2402.10091",
  "title": "Text Based Matching",
  "category": "product_matching",
  "year": 2024,
  "timestamp": "2026-03-01T14:31:36.429250",
  "summary": "The paper proposes treating product matching across e-commerce product feeds as a semi-supervised clustering problem, aiming to reduce the heavy cost of manual labeling while improving reliability on noisy, inconsistent text descriptions. Instead of inventing a new matcher, it reframes matching as clustering paired records into two groups, match vs no match, then injects limited ground-truth knowledge as pairwise constraints to guide the clustering. The main claim is that this constrained, deep clustering setup can outperform both plain unsupervised baselines and several supervised approaches on realistic, imbalanced matching data.\n\n*The given paper presents a framework that can be utilized for the problem of product matching.*  \nThe framework uses Improved Deep Embedded Clustering, IDEC, as the clustering engine, and derives a compact numeric representation from product titles only. Each product pair becomes a 5-element feature vector built from text similarity and token overlap, emphasizing low-compute fuzzy matching rather than heavier embeddings. The semi-supervised signal is provided through two constraint types, Must Link pairs that should be clustered together and Cant Link pairs that should not, with experiments varying how many constraints are supplied and how Must Link pairs are composed.\n\nKey setup details:\n- Data: Skroutz product matching dataset, using the Compact Cameras category; pairs are created via cross-join and labeled by ID equality, with an imbalanced sample where 25 percent of 20000 pairs are matches\n- Features from titles: fuzzy title ratios based on Levenshtein distance, Jaccard distance over title tokens, and a numbers-only overlap feature to capture model numbers and technical specs\n- Constraints tested: varying Must Link percentage, varying Cant Link percentage, and varying the fraction of match-match vs no match-no match pairs within Must Link constraints\n- Evaluation: F1 Score as the primary metric for imbalanced data, plus accuracy and Rand Index\n\n*Deep clustering approach outperformed the k-means algorithm in every reported metric.*  \nResults show a nuanced impact of constraints: increasing Must Link constraints does not necessarily improve quality and can increase training time, while adding Cant Link constraints tends to help up to a point, after which too many constraints can degrade results consistent with overfitting. In the reported best runs, IDEC with constraints improves F Score by about 0.07 over k-means, and IDEC outperforms mirrored XGBoost runs and the DeepMatcher variants tested. Additional checks on related camera datasets and a WDC cameras dataset show performance drops on more heterogeneous, multilingual feeds, and experiments that synthetically increase the match rate show metrics rising, with a notable lift once the match rate reaches around 10 percent. The conclusion argues the approach is practical because it relies on simple title-derived features and small amounts of constraint information, and suggests extensions such as adding more features like price spread, trying other constrained clustering methods, and exploring multi-parameter constraint tuning.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/codex/gpt-5.2",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}