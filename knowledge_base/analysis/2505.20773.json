{
  "paper_id": "2505.20773",
  "title": "Cold Start Rag",
  "category": "ecommerce_evaluation",
  "year": 2025,
  "timestamp": "2026-03-01T13:47:50.918608",
  "summary": "# Summary: ColdRAG - Adaptive Retrieval-Augmented Framework for Cold-Start Recommendation\n\nColdRAG is a retrieval-augmented generation framework designed to address the critical cold-start problem in real-world recommender systems, where new items lack sufficient interaction data. The paper identifies two key limitations in existing approaches: static knowledge graphs are expensive to construct and quickly become outdated, while LLM-based methods typically operate as re-rankers over pre-filtered candidate sets due to limited context windows. ColdRAG overcomes these constraints by dynamically constructing a knowledge graph from raw item metadata and performing LLM-guided multi-hop reasoning at inference time to retrieve candidates without relying on pre-filtered lists.\n\nThe framework comprises two core modules working in tandem. First, the Dynamic Knowledge Graph Construction module automatically builds and incrementally updates a domain-specific graph from catalog fields such as titles, descriptions, attributes, and reviews. This module uses an LLM to denoise and enrich sparse metadata, then extracts entities and relations to form a structured knowledge graph where each entity includes a name, type, description, and embedding. Second, the Adaptive Candidate Retrieval over Knowledge Graph module performs query-aware multi-hop reasoning, starting from user interaction history as semantic anchors and iteratively traversing the graph to identify relevant candidate items while scoring edges based on their alignment with user preferences.\n\nExperiments conducted across three Amazon Review datasets (Games, Toys, and Office) demonstrate that ColdRAG consistently outperforms both training-based methods (UniSRec, CLCRec, TDRO) and training-free approaches (LLM, LLMRank, TaxRec, KALM4Rec). Using GPT-4o-mini, ColdRAG achieves Recall@10 improvements of 78.22% on Games, 26.76% on Toys, and 123.81% on Office compared to the strongest baselines. The ablation study confirms that both the dynamic knowledge graph construction and adaptive candidate retrieval modules contribute independently to performance gains, with their combination yielding the best results. Notably, ColdRAG exhibits stable generation across multiple runs with low variance and reduces hallucination rates to 3.15% compared to 5-10% for other LLM-based methods, making it more practical for real-world deployment.\n\nThe authors acknowledge several limitations including computational costs from repeated LLM queries during knowledge graph construction and multi-hop reasoning, reliance on closed-source models for reproducibility, and manually tuned hyperparameters such as edge scoring thresholds and candidate pool sizes that remain static across domains. The knowledge graph analysis reveals that item nodes comprise 50% of the graph structure, with feature nodes at 26%, and dense connections between items and features (15,102 edges) enabling nuanced multi-hop reasoning. ColdRAG represents a significant advance in cold-start recommendation by combining structured knowledge representation with flexible LLM reasoning, offering a practical solution for dynamic e-commerce environments where new products are frequently introduced.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/claude/sonnet",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}