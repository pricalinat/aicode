{
  "paper_id": "2003.13230",
  "title": "Alicoco",
  "category": "product_matching",
  "year": 2020,
  "timestamp": "2026-03-01T14:54:32.787726",
  "summary": "AliCoCo is a large scale e-commerce cognitive concept net built and deployed at Alibaba to bridge a semantic gap between what shoppers actually need and how items are organized in platform taxonomies. It defines user needs as explicit shopping scenario concepts that can connect directly to relevant items, enabling more intelligent search and recommendation than keyword matching or purely item similarity based methods. *In this paper, we point out that there is a huge semantic gap between user needs and current ontologies in most e-commerce platforms.*\n\nThe system is organized as a unified framework with four layers: e-commerce concepts for high level needs, primitive concepts as the vocabulary for describing both needs and items, a class taxonomy to structure primitive concepts, and the item layer with large scale associations. Construction is semi-automatic: domain experts define a taxonomy with 20 top level domains and schema relations, primitive concepts are enlarged by aligning multiple knowledge sources and mining from e-commerce text, and isA links are expanded via a mix of pattern rules and supervised projection learning guided by active learning to reduce labeling cost. E-commerce concept candidates are produced both by mining phrases from corpora and by composing patterns over primitive concept classes, then filtered by a knowledge enhanced deep classifier that injects external semantic information such as Wikipedia glosses; good concepts are further interpreted by short text tagging modeled as NER with a text augmented encoder and fuzzy CRF to handle ambiguity. Finally, concept to item association is cast as semantic matching over short concept text and item titles, using a knowledge aware deep matching model with attention and matching pyramid style interactions to combat limited context and semantic drift.\n\nThe paper reports scale and coverage at the time of writing: about 2.85 million primitive concepts, 5.26 million e-commerce concepts, more than 3 billion items, and more than 400 billion relations, with 98 percent of items linked to the graph and large average fanout between concepts and items. Offline and online evaluations show that the proposed models and knowledge injection improve multiple tasks, including concept generation quality, concept tagging F1, and concept item matching metrics, and the graph improves search relevance and reduces bad relevance cases in online testing. *AliCoCo covers over 75% of shopping needs on average in continuous 30 days* and is described as already supporting production applications such as semantic search concept cards, cognitive recommendation with higher novelty and satisfaction, and clearer recommendation reasons, with future work aimed at mining more commonsense relations, adding probabilistic relations, and expanding applications beyond current deployments.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/codex/gpt-5.2",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}