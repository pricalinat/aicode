{
  "paper_id": "2403.04656",
  "title": "Cot Dialog State Tracking",
  "category": "mini_program_service",
  "year": 2024,
  "timestamp": "2026-03-01T13:53:57.157260",
  "summary": "# Chain-of-Thought Explanation for Dialogue State Tracking\n\nThis paper addresses a critical challenge in Dialogue State Tracking (DST): the need for multi-step reasoning across non-adjacent dialogue turns. The authors demonstrate that approximately 40% of samples in established DST benchmarks require reasoning across multiple conversation turns, yet existing models struggle with such instances. Through statistical analysis of MultiWOZ2.2, M2M, and WOZ2.0 datasets, the paper reveals that current approaches excel at single-step reasoning but degrade significantly when handling two or more reasoning steps.\n\n## Problem and Approach\n\nThe core issue identified is that existing DST models treat slot value prediction opaquely, without explicit reasoning about how values are derived from dialogue history. Humans naturally adopt a deliberate approach by collecting relevant information and reasoning through logical steps to determine appropriate slot values. The paper proposes Chain-of-Thought-Explanation (CoTE), which generates detailed step-by-step explanations after determining slot values, leading to more accurate and reliable predictions.\n\nTwo variants are introduced: CoTE-Coarse extracts relevant system-user utterance pairs that contribute to slot value changes and concatenates them chronologically as explanations; CoTE-Refined further improves these by using GPT-3 to paraphrase coarse explanations into more fluent, narrative-style third-person text. The framework converts DST samples into a question-answering format, where the model generates both the slot value and its corresponding explanation simultaneously.\n\n## Key Findings and Results\n\nExperimental results on three widely-recognized DST benchmarks demonstrate the effectiveness of CoTE. On MultiWOZ2.2, CoTE-Refined achieves 57.5% Joint Goal Accuracy (JGA) compared to SDP's 56.4% and D3ST's 56.1%, while on WOZ2.0 it reaches 91.6% versus DS2's 92.5% in the full-data setting. The performance gains are particularly pronounced in low-resource scenarios: with only 5% of training data, CoTE-Refined outperforms DS2 by significant margins across multiple datasets.\n\nFine-grained analysis reveals that CoTE variants show larger improvement margins on complex samples characterized by longer dialogue turns, longer utterances, and more reasoning steps. For instance, CoTE-Refined's average improvement over SDP on reasoning steps 1, 2, and 3 are 1.55%, 1.9%, and 1.675% respectively for MultiWOZ2.2, and 16.5%, 23.4%, 17.4% for M2M-R+M, demonstrating increasingly better performance as reasoning complexity grows.\n\n## Contributions\n\nThe paper makes three primary contributions: first, it identifies and analyzes the under-discussed problem of multi-step reasoning in DST, showing that nearly 40% of samples require reasoning across multiple turns; second, it proposes CoTE-Coarse and CoTE-Refined to address poor performance on multi-step reasoning samples through chain-of-thought explanations; third, it designs a fine-grained evaluation framework that analyzes model performance across reasoning steps, dialogue turn counts, and utterance lengths, providing deeper insights into where CoTE excels and why it generalizes better than summary-based approaches like DS2. The code is available at https://github.com/cathyxl/CoTE-DST.\n\n*The slot value of hotel-stars at turn 3 depends on the logical deduction from the dialogue contents of turn 1, turn 2, and turn 3*",
  "llm_info": {
    "provider": "cli",
    "model": "cli/claude/sonnet",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}