{
  "paper_id": "2310.19394",
  "title": "Lightsage",
  "category": "product_matching",
  "status": "success",
  "summary": "The paper describes LightSAGE, a graph neural network system Shopee uses for large scale item to item retrieval in an e commerce recommendation setting, focusing on practical success factors beyond just model architecture. It frames three core challenges in production: building a high precision item graph from noisy user behavior, choosing an architecture that is accurate but efficient at scale, and covering sparse cold start and long tail items that lack interaction history.\n\nGraph construction is designed as a homogeneous directed item graph where edges encode strong behavioral signals: when a user is on the Product Detail Page for item B and clicks item A, the system adds an edge B to A with weights from aggregated counts, after filtering spam users and very weak edges. To densify the graph without sacrificing too much precision, it adds supplemental links from high precision item to item collaborative filtering methods, specifically Swing and a search based co click method, with confidence scores converted into click like weights with penalties. *We construct high-quality item graphs by combining strong-signal user behaviors with high-precision collaborative filtering algorithm.*\n\nLightSAGE training uses sampled subgraphs with PinSAGE style random walk neighbor sampling over k layers, and a contrastive style setup with one positive neighbor plus both degree based random negatives and in batch hard negatives. The architecture borrows LightGCN style propagation and aggregation while removing feature transformation and nonlinear activations, and learns by optimizing cross entropy over cosine similarities. For long tail coverage, it populates embeddings for non seed items using two complementary inference time approaches: content similarity averaging from nearby seed items using item features, and a daily rebuilt inference graph with relaxed criteria that propagates seed embeddings to neighbors via weighted averaging. *The graph is rebuilt daily to capture the latest items pool and user behaviors.*\n\nExperiments use 30 days of click data from one market (30M users, 30M products, 3B clicks; long tail defined as the bottom 90 percent by clicks) and evaluate both link prediction AUC and a future click based unique recall metric plus a tail unique recall variant. LightSAGE outperforms Node2vec, PinSAGE, and GAT on AUC and recall in the main comparison, and ablations attribute the largest gains to switching from click sequence graphs to direct click graphs, then further improvements from adding collaborative filtering links and the long tail handling logic; the paper also notes CF links substantially increase graph size (node count +66 percent, edge count +177 percent). In an online A B test on the Product Detail Page module, adding LightSAGE to an existing retrieval stack improves orders by 1 percent and revenue by 5 percent, while increasing the number of unique items that receive exposure and clicks by 10 percent and 3 percent, leading to deployment across markets.",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2310.19394_lightsage.pdf"
}