{
  "paper_id": "2310.02294",
  "title": "Paper",
  "category": "mini_program_service",
  "year": 2023,
  "timestamp": "2026-03-01T13:52:49.390164",
  "summary": "# Beyond-Accuracy Metrics in GNN-Based Recommender Systems: A Comprehensive Review\n\nThis survey paper examines how Graph Neural Network (GNN) based recommender systems can be optimized for diversity, serendipity, and fairness—dimensions that significantly impact user satisfaction beyond traditional accuracy metrics. The authors review 21 publications from relevant journals and conferences, analyzing approaches that address these beyond-accuracy objectives at various stages of GNN model development.\n\n## Core Findings\n\n**The Accuracy- Diversity Trade-off Problem**\n\nWhile GNN-based collaborative filtering has achieved exceptional recommendation accuracy, most research has focused solely on this metric, neglecting equally important aspects like diversity (variety within recommendation lists), serendipity (surprising yet relevant recommendations), and fairness (equitable treatment of users and items). The paper argues that these dimensions are interconnected—increasing diversity often leads to more serendipitous recommendations, and both can promote fairness by ensuring a more equitable distribution of recommendations across items rather than consistently favoring popular items.\n\n**Model Development Stages for Beyond-Accuracy Optimization**\n\nThe authors identify seven key stages in GNN-based recommender system development where beyond-accuracy metrics can be addressed: data preprocessing, graph construction, embedding initialization, propagation layers, embedding fusion, score computation, and training methodologies. Their analysis reveals that graph construction, propagation layers, and training methodologies have seen the most innovation for tackling diversity, serendipity, and fairness, while embedding initialization, embedding fusion, and score computation remain relatively underutilized and represent promising avenues for future research.\n\n## Key Approaches for Diversity\n\n**Neighbor-Based Mechanisms**\n\nSeveral approaches leverage neighbor aggregation to improve diversity. The DGRec method diversifies embedding generation through submodular neighbor selection, layer attention, and loss reweighting. DGCN captures collaborative effects in the user-item bipartite graph through rebalanced neighbor discovery. These methods aggregate information from neighboring nodes to enhance representation diversity while maintaining accuracy.\n\n**Disentangling and Contrastive Learning**\n\nThe DGCF framework diversifies recommendations by disentangling user intents in collaborative filtering using intent-aware graphs. The Contrastive Co-training method employs an iterative pipeline that augments recommendation and contrastive graph views with pseudo edges, addressing popularity and category biases through diversified contrastive learning.\n\n**Dynamic Graph Construction and Adversarial Learning**\n\nThe DDGraph approach dynamically constructs user-item graphs to capture both interactions and non-interactions, applying novel candidate item selection to choose items from different sub-regions. Adversarial learning techniques, as seen in DTGCF and DGCN, improve accuracy-diversity trade-offs through personalized category-boosted negative sampling and category-independent embeddings.\n\n## Key Approaches for Serendipity\n\nResearch on serendipity in GNN-based systems is notably less extensive than diversity research. The Boo et al. approach enhances session-based recommendations by incorporating serendipitous session embeddings that leverage user preferences to enable explore-exploit tradeoffs. The TailNet architecture focuses on long-tail recommendations by classifying items based on click frequency and integrating preference mechanisms to balance niche item recommendations with overall accuracy. The r-AdjNorm method improves accuracy-novelty trade-offs by controlling normalization strength in neighborhood aggregation. Notably, some GNN models like LightGCN and ImprovedGCN, while primarily focused on accuracy, inadvertently boost serendipity and novelty through their architectural simplifications.\n\n## Key Approaches for Fairness\n\n**User Fairness Mechanisms**\n\nThe Navip method debiases neighbor aggregation using inverse propensity weighting to address user fairness. UGRec employs an information aggregation component and multihop mechanism to ensure fairness across demographic groups. SKIPHOP captures both direct interactions and latent knowledge graph interests, using fairness regularization to ensure balanced recommendations for users with similar profiles.\n\n**Item Fairness and Long-Tail Recommendations**\n\nThe NISER method addresses popularity bias by normalizing item and session representations to improve recommendations for less popular items. Long-tail recommendation approaches focus on suggesting less popular or niche items, which inherently promotes item fairness by giving more exposure to underrepresented items.\n\n**Advanced Techniques**\n\nContrastive learning approaches like DCRec counteract popularity bias by disentangling user conformity from genuine interest. Self-training mechanisms, as in Self-Fair, leverage unlabeled data to iteratively refine predictions while incorporating fairness constraints. Adversarial learning eliminates gender-specific features while preserving common ones for fairer recommendations.\n\n## Practical Challenges\n\nThe authors identify several practical challenges in optimizing GNN-based systems for beyond-accuracy metrics. Data sparsity and the need for auxiliary data like demographic information complicate the optimization of high-quality node representations. An overemphasis on past preferences can limit novel discoveries, while addressing popularity bias might inadvertently inject noise and reduce accuracy. Balancing multiple objectives—fairness, accuracy, and diversity—is nuanced since optimizing one can compromise another.\n\n## Future Research Directions\n\nThe paper highlights underexplored areas including personalized diversity, which tailors diversity levels to individual user preferences rather than applying uniform diversity. This concept extends to personalized serendipity and novelty, where unexpected or novel recommendations are customized to user preferences. The underutilized stages of embedding initialization, embedding fusion, and score computation offer novel ways to balance accuracy with diversity, serendipity, and fairness in recommendations.\n\n*DGRec method diversifies embedding generation through submodular neighbor selection, layer attention, and loss reweighting.*\n\n*The r-AdjNorm method improves accuracy-novelty trade-offs by controlling normalization strength in neighborhood aggregation.*",
  "llm_info": {
    "provider": "cli",
    "model": "cli/claude/sonnet",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}