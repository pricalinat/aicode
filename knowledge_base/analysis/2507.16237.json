{
  "paper_id": "2507.16237",
  "title": "Llm Reranking",
  "category": "product_matching",
  "status": "success",
  "summary": "This paper proposes a model agnostic way to improve complementary product recommendation by using an LLM only at reranking time, after any existing recommender retrieves a candidate list. The core motivation is the accuracy diversity tradeoff seen in GNN based complementary recommenders, especially their tendency to over recommend highly connected popular items and under serve long tail relevance and novelty. *our method applies LLM-based prompting strategies directly to rerank candidate items retrieved from existing recommendation models, eliminating the need for model retraining.*\n\nMethodologically, a baseline graph recommendation model acts as a retriever that scores item pairs and returns a top K candidate set, then two prompting based agents rerank in sequence. A diversity agent reranks the retrieved list to prioritize complementary relationships while pulling more varied product types toward the top, and an accuracy agent reranks the diversity refined subset to maximize precise complementarity. The prompts constrain output to only ranked candidate IDs and define complementarity as items used or purchased together rather than substitutes, with few shot examples like accessories, co accessories, or items used in the same activity.\n\nExperiments use Amazon product review data across four categories (Electronics, Cell Phones, Grocery, Home), with GraphSAGE, GAT, and SComGNN as baseline retrievers trained on the same graphs using node features from product categories and pricing, and with Llama3.3-70B powering both agents. Results report large lifts in Hit and NDCG at small cutoffs, plus modest gains in entropy and vocabulary size diversity metrics at K=1, while showing that diversity gains can turn negative as K grows, reflecting the tradeoff; ablations attribute most joint gains at small K to the diversity agent, and show the accuracy agent adds further accuracy while reducing diversity. *accuracy agent can further increase both hit rate and NDCG by at least 5% on average across models in all datasets.* The paper concludes by framing this as a simple two agent system with one interaction, and suggests extending it to iterative multi round agent collaboration in future work.",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2507.16237_llm_reranking.pdf"
}