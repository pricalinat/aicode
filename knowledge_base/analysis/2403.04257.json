{
  "paper_id": "2403.04257",
  "title": "Robustness Ecommerce Ranking",
  "category": "product_matching",
  "status": "success",
  "summary": "This paper presents a large-scale measurement study of robustness in a commercial e-commerce ranking system, defining robustness as whether semantically identical queries return consistent ranked results. *We define robustness as the consistency of ranking outcomes for semantically identical queries.* The authors argue this ground-truth-orthogonal framing fits real e-commerce settings where reliable relevance labels are hard or undesirable, and they show motivating examples where simple rephrasings can produce totally different top results.\n\nMethodologically, the study builds semantically identical query pairs in two ways: rule-based normalization via tokenization, filtering, stemming, and token sorting (TPS), and an in-house query-to-query similarity model (Q2Q). Using weekly historical ranking logs, they compute ranking-list disparity with a new metric, RDS (Ranking Distance Score), designed to (1) penalize disagreements near the top more than near the bottom via logarithmic position decay and (2) explicitly handle items that appear in one list but not the other, which breaks common correlation metrics like Kendall tau, tauAP, and Spearman in this setting. At scale, they report that many semantically identical query pairs still yield divergent rankings, that robustness is largely stable over April 15, 2023 to August 15, 2023, and that Q2Q similarity is only weakly correlated with ranking robustness, implying robustness is not a primary objective in Q2Q training or evaluation. *Our findings suggest that robustness factors are generally not incorporated into the training or evaluation of in-house Q2Q models in e-commerce ranking systems.*\n\nTo validate semantic identity, they run a user study with 50 participants, where results indicate most sampled TPS pairs are perceived as semantically identical and expected to return the same results, reinforcing that observed ranking divergence reflects non-robustness rather than semantic drift. They also propose a taxonomy of worst-case non-robust pairs (RDS 1.0), highlighting common triggers:\n- Prepositions and phrase rewrites\n- Abbreviations and unit variants\n- Singular vs plural switches\n- Word-order changes\n- Articles such as the\n- Punctuation changes (notably for media titles)\n- Spacing variants such as 1 mm vs 1mm\n- Word-connection characters such as plus or x\n\nFinally, the paper outlines solution directions: using LLMs to improve semantic understanding (with preliminary GPT-3.5 and GPT-4.0 checks for semantic equivalence and additional tests showing larger in-house models improve robustness), model ensembling at inference time across monthly system versions to smooth rankings and improve favorable RDS bins, and improving user-behavior feature pipelines to avoid feedback loops that reinforce non-robustness. It also situates these ideas within broader robustness research (adversarial training and certified robustness), noting practical constraints like latency and cost, and closes with limitations including focus on US English data from one retailer, residual bias risks despite filtering, and the use of hashed item IDs without semantic item-level similarity in the metric.",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2403.04257_robustness_ecommerce_ranking.pdf"
}