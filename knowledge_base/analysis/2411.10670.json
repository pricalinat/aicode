{
  "paper_id": "2411.10670",
  "title": "Intentgpt",
  "category": "mini_program_service",
  "year": 2024,
  "timestamp": "2026-03-01T13:55:25.086035",
  "summary": "# IntentGPT: Few-shot Intent Discovery with Large Language Models\n\nIntentGPT is a training-free method that leverages Large Language Models like GPT-4 for Few-Shot Intent Discovery in dialogue systems. The paper addresses the challenge of identifying new user intents in an open-world setting, where traditional methods require substantial labeled data and multi-stage training. The proposed approach uses in-context learning to discover novel intents with minimal supervision, requiring only a small number of examples rather than extensive domain-specific data.\n\n## Core Architecture\n\nIntentGPT consists of three main components working together. The In-Context Prompt Generator uses GPT-4 to automatically design task-specific prompts by analyzing training examples and understanding the domain context, eliminating the need for manual prompt engineering. The Semantic Few-Shot Sampler retrieves relevant examples using Sentence-BERT embeddings and cosine similarity, ensuring the LLM receives semantically similar demonstrations to the test queries. The Intent Predictor processes the constructed prompt along with known intents and test examples to classify or discover new intents, with a Known Intent Feedback mechanism that injects discovered intents back into the prompt during inference, enabling the model to learn on the fly.\n\n## Experimental Results\n\nThe method was evaluated on popular benchmarks including CLINC (150 intents across 10 domains) and BANKING (77 intents in finance), using metrics like Normalized Mutual Information (NMI), Adjusted Rand Index (ARI), and Clustering Accuracy (ACC). IntentGPT-4 with 50-shot examples achieved state-of-the-art performance, outperforming both unsupervised methods like DeepCluster and semi-supervised approaches like DSSCC and SCL. Notably, even the zero-shot setting demonstrated competitive results, surpassing all previous unsupervised baselines. The ablation studies showed that each component contributes meaningfully: Known Intent Feedback prevents excessive intent discovery, Semantic Few-Shot Sampling improves example selection, and the automatic prompt generation module significantly boosts performance.\n\n## Key Findings and Insights\n\nThe research reveals several important insights about using LLMs for intent discovery. GPT-4 consistently outperforms GPT-3.5 and Llama-2-70B across all settings, with performance scaling correlated to model capability. Experiments on multilingual data (MTOP dataset) demonstrated that the automatic prompt generation adapts to different languages without additional intervention. The study also explored hyperparameters like the number of clusters (K) in K-Means and LLM temperature, finding that lower temperatures (around 0.0-0.2) produce more consistent results. Analysis using Fr√©chet Bert Distance confirmed that generated intents are sufficiently different from training data, indicating the model creates novel intents rather than memorizing them.\n\n## Limitations and Ethical Considerations\n\nThe paper acknowledges several limitations. Context length restrictions of LLMs impose computational and monetary costs that increase with batch size. The approach requires API access for models like GPT-4, raising data privacy and security concerns, though Llama-2 offers a local alternative. The authors note potential biases in user utterances could be amplified, and mitigating these concerns represents crucial work for responsible AI development. Future directions include exploring the method for other open-set classification scenarios in computer vision and improving robustness for low-resource languages where GPT models struggle, such as Hindi and Thai in the MTOP benchmark.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/claude/sonnet",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}