{
  "paper_id": "2601.01997",
  "title": "Chatgpt Diversity",
  "category": "ecommerce_evaluation",
  "year": 2026,
  "timestamp": "2026-03-01T13:48:31.113439",
  "summary": "# Exploring Diversity, Novelty, and Popularity Bias in ChatGPT's Recommendations\n\nThis paper investigates how ChatGPT performs as a recommendation system beyond traditional accuracy metrics, examining diversity, novelty, and popularity bias across three datasets (MovieLens, Last.FM, Facebook Books). The authors compare ChatGPT-3.5 and ChatGPT-4 against various collaborative filtering and content-based baselines, finding that GPT-4 consistently outperforms GPT-3.5 and achieves competitive or superior results in most beyond-accuracy dimensions. The study also explores cold-start scenarios where users have minimal interaction history, demonstrating ChatGPT's strong performance in these challenging conditions.\n\n## Background and Research Questions\n\nRecommender systems have evolved significantly from matrix factorization to deep learning approaches, with the research community increasingly emphasizing beyond-accuracy dimensions like diversity, novelty, and popularity bias. These factors critically impact user satisfaction, long-term engagement, and fairness in recommendations. The emergence of Large Language Models like ChatGPT has opened new possibilities for recommendation pipelines, though most existing studies focus primarily on accuracy metrics.\n\nThe researchers address four key questions: whether ChatGPT generates diverse recommendations (RQ1), novel recommendations (RQ2), exhibits popularity bias (RQ3), and performs effectively in cold-start scenarios across accuracy and beyond-accuracy dimensions (RQ4). The authors note that while some studies examine ChatGPT for re-ranking or serendipity, comprehensive analysis of diversity, novelty, and popularity bias remains largely unexplored.\n\n## Methodology and Experimental Design\n\nThe researchers tested four prompting techniques: zero-shot, few-shot, Chain-of-Thought, and Role-Playing prompting. After evaluating 30 hand-crafted prompts, Role-Playing proved most effective at eliminating duplicate recommendations, where ChatGPT impersonates a Recommender System. The input format presents user history as a list of items, and the system generates Top-50 recommendations subsequently evaluated at a cutoff of 10.\n\nThe experimental setup uses three datasets filtered to 10-core interactions: MovieLens (603 users, 1,862 items), Last.FM (1,797 users, 1,507 items), and Facebook Books (1,398 users, 2,234 items). Baselines include Random, Most Popular, collaborative filtering methods (RP3Œ≤, LightGCN, ItemKNN, EASEùëÖ, NeuMF), and content-based methods (VSM, AttributeItemKNN). The evaluation metrics encompass accuracy measures (nDCG, Recall, Precision), diversity metrics (Gini index, Item Coverage), novelty metrics (EPC, EFD), and popularity bias metrics (ARP, APLT).\n\nTo handle ChatGPT's tendency to suggest items outside the dataset (hallucinations), the authors employed Gestalt pattern matching with a 90% similarity threshold, noting that out-of-catalogue items consistently appeared beyond position 10, preserving rank-sensitive metric validity.\n\n## Key Findings on Beyond-Accuracy Performance\n\nRegarding diversity (RQ1), ChatGPT demonstrates moderate diversity for Facebook Books and Last.FM while showing limited diversity on MovieLens, with GPT-4 consistently outperforming GPT-3.5. On Facebook Books, GPT-4 achieves a Gini of 0.1050 and covers 1,004 items, while on Last.FM it covers 944 items with a Gini of 0.2023. Although ChatGPT does not match the highest-diversity baselines like ItemKNN or RP3Œ≤, it surpasses several CF and CBF approaches.\n\nFor novelty (RQ2), ChatGPT exhibits high novelty in Facebook Books and Last.FM, with above-average performance in MovieLens. GPT-4 consistentlyÊé®Ëçê more novel items than GPT-3.5 across all datasets. On Facebook Books, GPT-4 achieves EPC of 0.0353 and EFD of 0.3486, exceeding most baselines including all CF and CBF algorithms.\n\nOn popularity bias (RQ3), ChatGPT shows some inclination toward popular items but remains far from MostPop baselines. GPT-4 demonstrates lower ARP than GPT-3.5, suggesting better capability for recommending less popular items. On MovieLens, ChatGPT shows ARP around 90-95 compared to MostPop's 182, indicating moderate but not extreme popularity bias.\n\n## Cold-Start Scenario Results\n\nIn user cold-start scenarios with maximum ten interactions, ChatGPT demonstrates remarkable effectiveness. For accuracy, GPT-4 achieves the highest nDCG on Facebook Books (0.0538) and MovieLens (0.1405), surpassing both CF and CBF baselines. On Last.FM, GPT-4 maintains robust performance with nDCG of 0.2791, outperforming MostPop significantly.\n\nFor beyond-accuracy dimensions in cold-start, GPT-4 again surpasses GPT-3.5 in Gini and item coverage across all datasets. ChatGPT's EPC and EFD values exceed those of CF and CBF baselines across all datasets, indicating strong novelty even with minimal user history. The popularity bias remains moderate, far from MostPop levels but comparable to other baselines.\n\nThe findings suggest that ChatGPT can effectively infer user interests from limited interactions, making it particularly valuable for new users in cold-start scenarios.\n\n## Conclusions and Limitations\n\nThe study demonstrates that ChatGPT models achieve strong beyond-accuracy performance, balancing novelty and diversity optimally in the books domain, comparably in music, and suboptimally in movies. While ChatGPT exhibits some tendency toward popular items, this bias is far less pronounced than MostPop or other strongly popularity-biased methods.\n\nThe authors acknowledge limitations around LLM memorization, noting that models trained on internet-scale corpora may have memorized portions of benchmark datasets. The reported memorization rate reaches 80.76% for GPT-4 on MovieLens-1M, suggesting future research should examine the correlation between recommendation quality improvements and memorization capacity.\n\n*ChatGPT models exhibit strong beyond-accuracy performance, achieving an optimal balance of novelty and diversity in the books domain*",
  "llm_info": {
    "provider": "cli",
    "model": "cli/claude/sonnet",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}