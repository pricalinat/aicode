{
  "paper_id": "2409.13738",
  "title": "Nlp4Pbm Process Extraction",
  "category": "mini_program_service",
  "status": "success",
  "summary": "This paper presents a PRISMA-guided systematic review of NLP-enabled automated process extraction, meaning transforming natural language process descriptions into structured process models for Business Process Management. It searches five major databases in June 2023 and synthesizes studies published from 2011 to 2023, applying explicit inclusion and exclusion criteria and a classification scheme spanning natural language analysis, process model generation, evaluation methods, evaluation datasets, and publication metadata. *We performed a systematic review of the literature based on the PRISMA guidelines.* *In the end, 20 articles were found to fully meet our inclusion/exclusion criteria.*\n\nAcross the reviewed work, the NLP component is increasingly implemented with ML and deep learning, especially after Transformer models like BERT, with 2023 showing an even split across rule-based, ML, and DL paradigms. The review details common pipeline tasks (tokenization, POS tagging, dependency parsing, NER, coreference resolution, semantic analysis) and catalogs both models used for specific tasks (for example CRF, Bi-LSTM, CNN, BERT variants, gradient boosting) and off-the-shelf NLP tools (for example spaCy, Stanford CoreNLP, NLTK, WordNet, FrameNet, GloVe). In contrast, process model generation itself is still most often knowledge-based, using rules, templates, patterns, or custom algorithms, with only one reviewed study using ML to generate the process structure directly; intermediary representations include graphs, tables, and dependency tuples. Target outputs are dominated by imperative control-flow models such as BPMN and UML activity diagrams, with fewer works on declarative constraints and decision models like DMN.\n\nEvaluation is summarized along two orthogonal dimensions: component-based versus holistic, and systematic comparison versus expert-based judgment, with many studies relying on element-by-element precision, recall, and F1, and some using graph similarity measures or behavioral profiles. A central conclusion is that evaluation is constrained by dataset problems: inconsistent reuse, broken links to published datasets, small dataset sizes, and a shortage of gold-standard resources, with PET identified as the main reference dataset for control-flow extraction but limited in scope. The discussion highlights early peer-reviewed LLM work on process extraction up to August 2024, describing prompt design patterns and mixed results on relation extraction and determinism, and argues that approaches like data augmentation, retrieval-augmented generation, and multi-agent LLM setups are promising ways to improve accuracy, robustness, and scalability while keeping attention on risks like inherited bias from pretraining data.",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/mini_program_service/2409.13738_NLP4PBM_Process_Extraction.pdf"
}