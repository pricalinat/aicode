{
  "paper_id": "2310.04878",
  "title": "Hybrid Gnn Bert",
  "category": "product_matching",
  "year": 2023,
  "timestamp": "2026-03-01T13:35:59.623903",
  "summary": "# Hybrid Recommendation System Using Graph Neural Network and BERT Embeddings\n\n## Overview\n\nThis paper presents a novel hybrid recommendation system that combines Graph Neural Networks (GNNs) with BERT sentence transformer embeddings to predict anime recommendations for users. The model leverages link prediction to create recommendations based on both anime features and user interaction patterns, while also predicting ratings users would give to specific anime.\n\n## Key Contributions\n\nThe research addresses a fundamental limitation in traditional recommendation approaches: content-based filtering using only genres fails to capture the nuanced differences between anime with identical genre labels. For instance, two anime sharing the \"Comedy\" genre could range from light-hearted slice-of-life to dark psychological thrillers.\n\nThe proposed solution combines one-hot encoded genre information with semantic embeddings generated from anime synopses using sentence transformers. This hybrid approach captures both categorical genre information and the contextual meaning of plot descriptions, enabling more differentiated recommendations.\n\n## Technical Architecture\n\nThe model utilizes GraphSAGE from the PyTorch Geometric library as its GNN backbone. The architecture consists of three encoder classes: SequenceEncoder for generating BERT-based synopsis embeddings, IdentityEncoder for converting raw IDs to tensors, and GenresEncoder for processing categorical genre data. These encoders feed into a heterogeneous GNN that processes user-anime interaction graphs, followed by an edge decoder that outputs rating predictions.\n\nThe evaluation methodology involves generating predicted ratings for anime a user has not watched, sorting these predictions, and recommending the top 10 highest-rated anime. Performance is measured using Root Mean Square Error (RMSE) against ground truth ratings.\n\n## Dataset and Results\n\nThe system was trained on the Anime Recommendation Database 2020 from Kaggle, containing 78 million user-anime interactions from 320,000 users across 16,000 anime titles. The final model used 800 users and 3,534 anime for computational feasibility.\n\nExperimental results showed a training loss of 0.659 and test loss of 0.667, with training accuracy at 52% and test accuracy at 37%. The authors note that while accuracy is moderate, the model demonstrates functionality with limited data, though significant compute resources would be required for larger datasets.\n\n## Future Directions\n\nThe paper outlines several paths for improvement, including incorporating user features as additional graph nodes, expanding to larger datasets, and experimenting with alternative GNN architectures beyond GraphSAGE.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/claude/sonnet",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}