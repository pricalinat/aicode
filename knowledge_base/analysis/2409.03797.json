{
  "paper_id": "2409.03797",
  "title": "Nestful",
  "category": "mini_program_service",
  "status": "success",
  "summary": "NESTFUL introduces a benchmark for evaluating tool and function calling in large language models when calls must be made as nested sequences, where outputs from earlier API calls become inputs to later ones. The paper argues that existing benchmarks mainly test isolated or shallow multi-call behavior and miss this core real-world complexity, then provides NESTFUL as a way to measure planning, argument filling, variable passing, and execution correctness end to end on executable tool libraries.\n\nThe dataset contains over 1,800 instances across two domains, pairing each natural-language query with an API catalog, a gold nested call sequence with arguments, and the expected final answer, plus Python implementations so sequences can be executed and checked. Key elements include:\n- A data schema that supports variable assignment and referencing for both sequential and parallel calls, enabling deeper data dependencies within a sequence\n- Curation from MathQA plus a coding-oriented collection derived from StarCoder2-Instruct style Python functions, with validation and filtering to keep tools executable and outputs reproducible\n- An evaluation pipeline that can run direct prompting and a ReAct-style agent, then scores predictions with function and parameter F1, partial versus full sequence match accuracy, and win rate based on reaching the correct final answer\n\n*GPT-4o and DeepSeek-V3 achieve the highest win-rate of 60%, which is significantly below the acceptable numbers for real-world applications in general.* Results over 19 models show that full-sequence correctness remains low even for top systems, and analysis ties performance drops to increasing nesting depth and the number and structure of data dependencies, especially patterns that combine outputs from multiple earlier calls into one later call. *the performance drops sharply with depths of two or more suggesting that long nested sequences present difficult scenarios for current models.* The paper highlights recurring failure modes such as datatype mismatches across chained calls, incorrect variable assignment or reuse, and not leveraging output-parameter details from tool specifications, and concludes that releasing NESTFUL aims to accelerate progress on robust nested sequencing for tool-augmented LLMs.",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/mini_program_service/2409.03797_NESTful.pdf"
}