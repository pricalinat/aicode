{
  "paper_id": "2412.03446",
  "title": "Text2Workflow",
  "category": "mini_program_service",
  "year": 2024,
  "timestamp": "2026-03-01T14:01:13.852168",
  "summary": "The paper proposes Text2Workflow, a prompt layered method that converts natural language business process requests into executable, structured workflows represented as JSON, positioning it as a more general alternative to traditional RPA that depends on expert implementation and struggles with complex decision making. It introduces a standardized JSON schema with a process level section for metadata and a steps section that encodes unit actions and control flow, aiming to make workflows readable, visualizable, and editable while remaining suitable as an execution blueprint. *This paper introduces Text2Workflow, a novel method that automatically generates workflows from natural language user requests.*\n\nText2Workflow is organized as a master and experts pipeline built from seven prompt layers: an initial logic and ambiguity screening that can request clarifications, skeleton creation via a general process prompt plus a master prompt that decomposes the request into ordered steps, and a human feedback loop that summarizes the workflow in plain language and iteratively applies user edits. After validation, type specific expert prompts fill step parameters and maintain a shared context of variables; an additional parameter expert layer handles certain API style steps; a final pass detects missing essential parameters and generates user questions; and a last modification stage applies any post hoc edits, optionally reinvoking experts. The workflow step taxonomy includes Decision, Loop, Calculation, DataExtraction, API oriented steps spanning tools such as Outlook, Excel, File, Web, and Desktop, plus Exception and Unknown, each with a predefined JSON structure documented in appendices alongside the full prompts.\n\nFor evaluation, the authors create Process2JSON, a 60 request dataset split evenly across easy, medium, and complex categories, and compare two single prompt baselines using gpt-3.5-turbo-0125 and gpt-4o-mini-2024-07-18 against Text2Workflow variants that remove or add user aids like logic screening and the feedback loop. They measure generation time, token usage, and a graded JSON accuracy score that distinguishes minor errors from major structural or semantic failures; Text2Workflow uses substantially more tokens and time on average but improves accuracy on complex requests, reaching 57.5 percent on hard examples versus 30 percent for the gpt-4o-mini baseline and achieving the top overall score of 71.3 percent across experiments. *Text2Workflow achieves the highest performance across experiments, with a 71.3% accuracy.* The discussion highlights recurring failure modes such as incorrect nextStepId links in Decision and Loop steps, weak variable context usage, confusion about DataExtraction requirements, and difficulty with Exception steps, especially TryBlock, and concludes with limitations around prompt maintenance, cloud model security concerns, and single evaluator bias, alongside future work to make prompting more robust and evaluation more objective.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/codex/gpt-5.2",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}