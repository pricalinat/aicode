{
  "paper_id": "2306.06624",
  "title": "Restgpt",
  "category": "mini_program_service",
  "year": 2023,
  "timestamp": "2026-03-01T14:02:10.606932",
  "summary": "## Summary\n\nThis paper proposes RestGPT, a framework for connecting large language models with real-world RESTful APIs to complete complex, multi-step user instructions. The core idea is an online, coarse-to-fine planning loop that decomposes an instruction into natural-language sub-tasks, maps each sub-task to concrete API calls using OpenAPI Specification information, executes those calls, and uses API feedback to adjust the plan until completion.\n\n*Experiments show that RestGPT is able to achieve impressive results in complex tasks and has strong robustness*  \n*RestGPT comprises three main modules: a Planner, an API Selector, and an Executor.*\n\nRestGPT is designed around three LLM-driven modules with different slices of API documentation to fit context limits and improve reliability:\n- Planner: generates the next natural-language sub-task from the user instruction plus prior plans and execution results, and can emit a continue signal when a step is incomplete or an end decision when the task is done  \n- API Selector: reads endpoint descriptions to choose one or more endpoints that satisfy the current sub-task, producing a finer-grained API plan  \n- Executor: runs the plan via a Caller that formats parameters and requests, plus a schema-guided Parser that generates and executes Python code to extract required fields from JSON using the OpenAPI response schema, with direct LLM parsing as a fallback on errors\n\nTo evaluate real-world REST usage, the paper introduces RestBench, a human-annotated benchmark with two scenarios: TMDB movie database and Spotify music player. It filters to 54 TMDB APIs and 40 Spotify APIs, collects instructions that often require multiple calls, and labels gold solution paths; the test sets include 100 TMDB instructions and 57 Spotify instructions, with average gold path lengths around 2 to 3 steps and some longer cases. Because many instructions are time-dependent, evaluation emphasizes path quality and completion: Correct Path Rate checks whether the predicted API path contains the gold path as a subsequence, and Success Rate is judged by humans; planning efficiency is measured by additional calls beyond the gold path.\n\nExperiments compare RestGPT to offline plan-then-execute, DEPS, ReAct, and Reflexion, using text-davinci-003 as the main LLM, plus variants with ChatGPT, Llama2-13B, and Vicuna-13B. RestGPT reports 75.0 percent success on TMDB and 72.7 percent success on Spotify, with Correct Path Rate 79.0 and 74.5 and small average extra-call overhead of +0.55 and +0.25. Ablations show large drops without the coarse-to-fine planner or without the schema-based parser, and error analysis finds most failures occur in planning and API selection, including losing the goal over many steps, picking wrong endpoints, or hallucinating in-path parameters. Scaling studies show success decreases as gold path length grows for all methods, but RestGPT remains substantially stronger on harder tasks and is comparatively robust as the number of available APIs grows with added noise.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/codex/gpt-5.2",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}