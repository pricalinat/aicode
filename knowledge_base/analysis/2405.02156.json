{
  "paper_id": "2405.02156",
  "title": "Diversity Recommendation",
  "category": "ecommerce_evaluation",
  "year": 2024,
  "timestamp": "2026-03-01T13:52:50.647370",
  "summary": "# User-Centric Pre-Processing for Diversifying Recommender Systems\n\nThis paper presents a novel approach to improve diversity in personalized recommendations while maintaining accuracy. The method employs a user-centric pre-processing strategy that selectively adds and removes interactions from user profiles, exposing users to a wider range of content categories. The approach is designed to be algorithm-agnostic, meaning it can be integrated with any personalized recommender system architecture.\n\n## Core Approach\n\nThe researchers developed two variants of their pre-processing method. The one-step variant adds a percentage of interactions to user profiles based on a parameter λ (ranging from 1% to 10%). The two-step variant both adds and removes interactions to keep the profile size approximately equal to the original. Items added to user profiles are selected based on two principles: they should be sufficiently different from what the user has previously interacted with, and they should closely align with the user's existing preferences.\n\nThe pre-processing pipeline works in three stages. First, logistic regression identifies categories representative of each user based on their past interactions. Second, userKNN generates an initial list of potentially relevant items. Third, items from categories not already in the user's profile are selected for addition, ensuring exposure to new content areas while maintaining relevance.\n\n## Experimental Results\n\nThe researchers tested their approach on two public datasets: MIND for news recommendations (17 categories) and GoodBooks for book recommendations (31 genres). They combined the pre-processing with seven different recommendation algorithms, including neural network models (NRMS, NPA, LSTUR) for news and collaborative filtering methods (MostPop, ItemKNN, ImplicitMF, BPR) for books.\n\nAccuracy results showed that pre-processed data led to recommender systems achieving comparable or improved performance compared to those trained on original data. The maximum accuracy increase was 0.002 for GoodBooks using BPR, while the maximum decrease was 0.034 for the same dataset and algorithm. Many observed differences were not statistically significant, indicating that performance remains relatively stable when applying the approach.\n\nFor diversity, calibration metrics consistently improved for certain algorithms, while coverage and Gini index results were mixed across different λ values. Provider fairness, measured through fair-nDCG, showed consistent improvement across all algorithms when using pre-processed data, indicating enhanced exposure for minority categories.\n\n## Key Findings and Implications\n\nThe discrepancy between normative diversity metrics (calibration) and descriptive metrics (coverage, Gini) reveals an important insight. Normative metrics focus on ideal distributions while descriptive metrics capture observed variations in user preferences, meaning relying solely on one type could lead to overestimating or underestimating true diversity. This finding suggests practitioners should evaluate multiple dimensions when assessing recommendation diversity.\n\nThe approach also raises ethical considerations around user autonomy and transparency. Users should have the ability to opt in or out of profile modifications, and the explainable nature of this approach opens opportunities for research into how users might benefit from understanding and controlling their altered profiles.\n\nThe code and supplementary materials are available at: https://github.com/SlokomManel/How-to-Diversify-any-Personalized-Recommender-",
  "llm_info": {
    "provider": "cli",
    "model": "cli/claude/sonnet",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}