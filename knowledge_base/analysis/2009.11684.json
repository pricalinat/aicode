{
  "paper_id": "2009.11684",
  "title": "Alime Kg",
  "category": "product_matching",
  "year": 2020,
  "timestamp": "2026-03-01T14:43:09.699470",
  "summary": "AliMe KG presents a domain knowledge graph built to improve pre-sales customer service in Alibaba e-commerce, aiming to narrow the gap between how customers express needs as problems and how products are organized as categories, properties, and values. The graph is designed to help a chatbot recognize user problems, infer user needs, answer detailed product property questions, and generate explanatory recommendation reasons. Its key contribution is modeling *Problem* and *POI* as central concepts that bridge users to items, with relations that capture what a problem needs and what item properties can cause or satisfy a POI.\n\n- **Core ontology and layers:** Uses classic buying-process concepts User, Item, Scenario, plus IPV for item property values, and introduces Problem and POI; it organizes knowledge into User, POI, and Item layers and links them via need and cause relations.\n- **Knowledge sources and construction:** Mines nodes and links from free text using item detail pages and articles for POIs, and pre-sales chat logs for user problems and some relational knowledge; imports CPV and large parts of item knowledge from an existing product knowledge graph and complements missing property values.\n- **Main modeling components:** Phrase mining produces candidate phrases and prunes low-quality phrases using segmentation and a BERT masked language model step; binary BERT classifiers decide whether phrases are POIs or user problems; NER extracts property values using a BERT plus BiLSTM plus CRF architecture with lexicon and dictionary features; relation extraction predicts links using a BERT-based classifier with concept markers and optional knowledge injection from external graphs like HowNet and CN-DBpedia.\n- **Quality control and scale:** Conceptual knowledge is fully checked via crowdsourcing, while some instance-level knowledge is spot-checked due to volume; reported scale includes hundreds of thousands of POIs, tens of thousands of CPVs, hundreds of thousands of items, and millions of IPV and inferred I-PV-POI triples.\n- **Reported evaluation highlights:** Phrase mining reaches 88 percent precision in a tested setup; NER improves with lexicon and dictionary features; relation extraction AUC is already high and gains slightly with external knowledge injection.\n\n*Our model is able to achieve a precision of 88% without any manual annotation, which is practically usable in industrial settings.*\n\n*We have accumulated 365K POIs, 1K user prpblems and 29K CPVs, 8.6K Userproblem-POI triples, and 113K C-PV-POI triples.*\n\nIn deployment, AliMe KG is used for shopping guidance via query rewriting and item recall, property-focused question answering via KBQA over the graph, and recommendation reason generation via graph-to-sequence text generation. The paper reports positive online results, including improved conversion rate in tested domains and measurable coverage of pre-sales conversations for shopping guide and reason generation. It closes by emphasizing practical lessons for industrial KG building around clear objectives, a simple scalable schema, and strict data quality control, and points to multimodal item content and multimodal knowledge graphs as a next direction.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/codex/gpt-5.2",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}