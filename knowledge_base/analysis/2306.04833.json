{
  "paper_id": "2306.04833",
  "title": "Etsy Unified Embedding",
  "category": "product_matching",
  "status": "success",
  "summary": "This paper describes UEPPR, a unified embedding based personalized retrieval system deployed in Etsy Search to close two gaps at once: semantic mismatch for tail queries and lack of context for broad, high frequency queries where user history helps. It uses a two tower architecture with a product encoder and a joint query user encoder, optimized for low latency ANN retrieval while still incorporating richer signals than text alone. The authors report that the system improved organic search purchase rate by 5.58 percent and site wide conversion rate by 2.63 percent, aggregated across multiple online A B tests.\n\nUEPPR builds a single embedding space by pooling several complementary encoders end to end, then scoring candidates with cosine similarity so product vectors can be indexed offline and served efficiently. Key representation pieces include:\n- Token and ID embeddings over multiple token field groups to reduce noise from fields like description keywords\n- A transformer signal via a docT5query style pre training setup, after direct fine tuning of distilBERT and T5 encoders did not improve offline metrics under their asymmetric latency constraints\n- A bipartite query product graph embedding learned from more than a year of search logs, with specific steps to avoid leakage and overfitting when sharing parameters\n- Location features for both user and listing, including zip prefixes and K means geo buckets at multiple granularities, plus in session and historical engagement features modeled with lightweight attention and a 1 layer transformer at the event level\n\nTraining and serving focus heavily on practical retrieval constraints. Positives come from mined search log interactions, while negatives combine in batch hard negatives, uniform corpus negatives, and dynamic hard negatives selected from a large sampled pool, with a schedule that shifts weight toward harder negatives for convergence and top rank quality. They introduce a multi part hinge loss with thresholds per interaction type to better align training with threshold based pruning in candidate generation, and they add ANN based product boosting by hydrating vectors with query independent quality features whose weights are tuned via black box optimization rather than learned directly to avoid overfitting to sampling artifacts. At serving time they describe Faiss ANN choices, including moving to a 4 bit product quantizer fastscan index with a reranking step to keep P99 latency in the tens of milliseconds while limiting recall loss.\n\n*On aggregate, our UEPPR system improved CVR by 2.63% and OSPR by 5.58%.*  \n\n*We were able to achieve a recall loss of less than 4% while keeping our P99 latency under 20ms in production.*",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2306.04833_etsy_unified_embedding.pdf"
}