{
  "paper_id": "2012.07553",
  "title": "Paper",
  "category": "mini_program_service",
  "status": "success",
  "summary": "## Summary\n\nThis paper presents an end-to-end named entity recognition system for eCommerce search queries at The Home Depot, focused on extracting two entity types: brand and product type. The central contribution is TripleLearn, an iterative training framework that learns from three complementary datasets rather than relying on a single training set, aiming to bridge common gaps between research NER results and industrial requirements like domain coverage, label quality, and production constraints. Using this approach, the authors report lifting exact-match F1 on holdout test data from 69.5 with a legacy taxonomy matching system to 93.3 with the best TripleLearn model, along with measured online improvements in user engagement and revenue conversion after deployment.\n\nThe system addresses the shortcomings of a legacy greedy exact-match NER that depends on pre-defined brand and product taxonomies and struggles with multiple product types in a query, ambiguity between brands and product types, and new product types absent from taxonomy. TripleLearnâ€™s Phase I builds three datasets from two foundations: product catalog data and customer behavior logs. It combines (1) a very large but noisy auto-generated dataset from catalog plus behavior matching, (2) a small manually annotated golden dataset sampled with stratification by entity-sequence patterns, and (3) a synthetic dataset generated from all catalog brands and products to maximize label-value coverage. Phase II iteratively trains a sequence tagger, uses consensus between noisy labels and model predictions to filter additional training examples, adds synthetic samples to improve coverage, and stops when test-set F1 no longer improves; the process is designed to reduce noise and mitigate self-training drift via stratified sampling by label-sequence patterns.\n\nFor modeling, the paper frames NER as BIO sequence tagging with five labels: B-BRD, I-BRD, B-PRD, I-PRD, and O, evaluated using exact-match micro-F1 on whole entities. After comparing architectures, the production model is a BiGRU-CRF with a character-to-word BiLSTM subgraph for character-based embeddings, implemented in TensorFlow; BiGRU is chosen largely for efficiency, with comparable or better performance and fewer parameters than BiLSTM variants. Experiments also test BERT and BERT-CRF but find them less effective for this domain, suggesting domain mismatch with pretraining corpora and noting that further improvements would require additional fine-tuning effort. The authors also evaluate word embeddings and select custom-trained Word2vec trained on large volumes of Home Depot queries and product titles for better vocabulary coverage and domain semantics.\n\nProductionization centers on speed and cost: the model is served as a real-time web service using TensorFlow Serving on Google Cloud Platform, with optimizations to reduce model size and improve CPU inference performance. They report that the service can handle high query volumes and serve most queries within a tight latency budget, and that it has been live on homedepot.com for more than nine months. Maintenance is treated as a recurring necessity due to frequent catalog changes, and TripleLearn is positioned as making refreshes easier by allowing incremental updates to only parts of the three datasets; an example refresh targets improved performance on short queries by adding a small amount of additional short-query training data. The discussion argues TripleLearn helps when high-quality labels are expensive, explains why three datasets provide collaborative supervision, and suggests the framework is model- and problem-independent, with potential applicability to other industrial sequence labeling problems; future work includes adding more entity types, extending use cases beyond search queries, and testing on public datasets for reproducibility.\n\n*The model has been live on homedepot.com for more than 9 months, boosting search conversions and revenue.*\n\n*the best model lifts the F1 score from 69.5 to 93.3 on the holdout test data.*",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/mini_program_service/2012.07553_paper.pdf"
}