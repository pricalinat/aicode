{
  "paper_id": "1809.03186",
  "title": "Online Offline Ecom",
  "category": "ecommerce_evaluation",
  "year": 2018,
  "timestamp": "2026-03-01T13:49:47.308687",
  "summary": "# Offline vs. Online Evaluation of Recommender Systems in Small E-commerce\n\nThis paper by Ladislav Peska and Peter Vojtas from Charles University addresses a fundamental disconnect in recommender systems research: the gap between academic offline evaluation (using historical data) and industry online evaluation (A/B testing on live systems). The authors focus specifically on small e-commerce enterprises, which present unique challenges including low user loyalty, very short sessions spanning only a single visit, and sparse interaction data. However, they note these contexts also offer advantages such as fewer objects to recommend and reduced \"missing not at random\" data issues compared to large platforms like Amazon.\n\nThe researchers conducted an extensive study on a Czech travel agency website, evaluating 800 variants of recommender systems across 18 different metrics. They combined three base recommending algorithms—word2vec trained on user visit sequences, doc2vec trained on textual descriptions, and cosine similarity on content-based attributes—with nine different user history aggregation methods and various hyperparameters. Offline evaluation covered rating prediction, ranking-based metrics (AUC, MRR, nDCG), novelty (both temporal and user-perceived), and diversity metrics. Twelve selected algorithm variants were then deployed for online A/B testing over one month, measuring click-through rate (CTR) and visit-after-recommendation rate (VRR).\n\nThe results revealed striking differences based on user \"seniority,\" measured by the number of previously visited objects. For novice users (1-2 visited objects), ranking-based offline metrics showed positive correlation with online metrics, while excessive user-perceived novelty actually harmed online performance. However, this relationship reversed for more senior users—ranking metrics became negatively correlated while novelty and diversity became positively correlated with online success. The authors speculate that experienced users may have already encountered straightforward recommendations and therefore benefit from more novel suggestions.\n\nTo test predictability, the researchers trained LASSO regression models to predict online CTR and VRR from offline metrics, achieving R² scores of 0.42 and 0.35 respectively with statistical significance. They recommend word2vec and cosine content-based methods as particularly effective for small e-commerce applications, noting that their prediction models successfully identified good candidate algorithms beyond the initially tested variants. The study provides valuable insights for practitioners seeking to bridge the academic-industry evaluation gap in recommendation systems.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/claude/sonnet",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}