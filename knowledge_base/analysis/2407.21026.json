{
  "paper_id": "2407.21026",
  "title": "Ecommerce Recommendation",
  "category": "product_matching",
  "status": "success",
  "summary": "This PDF describes an e-commerce product recommendation system built with classical machine learning, aiming to personalize recommendations and offers for each customer. The work compares four algorithms, Gaussian Naive Bayes, Decision Tree, Random Forest, and Logistic Regression, and also applies Principal Component Analysis for feature reduction. Across the reported experiments, Random Forest is presented as the best-performing approach, with very high accuracy and strong error metrics relative to the other models.\n\nThe dataset is described as coming from a customer survey conducted via a Google Form for an e-commerce platform, intended to capture consumer preferences, experiences, and satisfaction. It includes 11 fields that mix identifiers and transaction-like attributes such as customer id, name, email, product model, quantity, price, address, phone number, order date, order status, and a customer feedback message. The methodology includes preprocessing and filtering, converting text to numeric values with label encoding, and splitting data into 75 percent training and 25 percent testing, with an architecture diagram of the recommender system referenced.\n\nModel evaluation uses Accuracy, R square, Mean Squared Error, and Mean Absolute Error, with brief explanations and formulas for items like accuracy, entropy and information gain for decision trees, and Bayes theorem for Naive Bayes, plus a description of PCA as an orthogonal transformation to reduce dimensionality. Key comparative outcomes reported include:\n- Random Forest: stated as highest accuracy, commonly around 99.8 percent, with R square around 0.99 and low MSE and MAE, and also reported as 99.6 percent accuracy with R square 0.97, MSE 1.92, MAE 0.087 in one table\n- Decision Tree: high accuracy around 96.3 percent with R square around 0.96, moderate MSE and MAE\n- Gaussian Naive Bayes: much lower accuracy around mid 40 percent with weak or negative R square and higher errors\n- Logistic Regression: lowest accuracy around 22 percent with strongly negative R square and very large errors\n\n*The Random Forest RF algorithm is the most effective in predicting the outcome.*  \n*The Random Forest RF model yields the best results in this observation.*",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2407.21026_ecommerce_recommendation.pdf"
}