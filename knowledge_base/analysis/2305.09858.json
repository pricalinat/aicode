{
  "paper_id": "2305.09858",
  "title": "Kg Completion Ecommerce Llm",
  "category": "product_matching",
  "status": "success",
  "summary": "This paper studies whether large language models can do relation labeling for e-commerce knowledge graphs with very little labeled data, focusing on predicting whether two product types are complementary, substitutable, or irrelevant. It argues that relation labeling is costly and hard to maintain in fast-changing retail catalogs, and tests LLMs as a practical alternative that can leverage natural language descriptions of product types without task-specific training. The authors evaluate PaLM and GPT-3.5 on two product-type datasets and report that with only 1 to 5 examples per relation, LLMs reach performance competitive with human labeling and substantially better than traditional knowledge graph completion models, to the point they could replace human labelers in this setting.\n\nThe experiments use product types from Walmart Electronics and Instacart grocery aisles, with ground truth coming from crowdsourced consensus labeling. Electronics includes 1045 product-type pairs, heavily skewed toward irrelevant (769), with fewer complementary (264) and very few substitutable (12); Instacart includes 400 pairs with a similar skew (244 irrelevant, 166 complementary, 10 substitutable). Models are evaluated by accuracy and by precision and recall for complementary and substitutable; temperature is set to 0.0 for stable outputs. The paper finds that prompt design matters a lot: adding explicit relation definitions and then few-shot examples improves accuracy stepwise over a baseline prompt, and substitutable metrics are generally weaker due to rarity and sensitivity to errors.\n\nA key qualitative result is that LLMs can provide explanations that influence human relabeling. When two individual human labelers re-label while seeing the LLM’s labels and explanations, agreement often increases, especially in the more subjective grocery domain, where cultural habits can affect judgments; the paper describes cases where explanations persuaded a labeler to change labels. It also compares PaLM against multiple knowledge graph embedding and GNN-based baselines (TransE, TransR, DistMult, ComplEx, RESCAL, R-GCN, CompGCN and others) trained with an 80/10/10 split, reporting PaLM’s accuracy is higher on both datasets with at least a 40.6 percent minimum improvement, and arguing LLMs scale better under limited labeled data and unseen product types.\n\n*LLMs significantly outperform existing KG completion models in relation labeling for e-commerce KGs and exhibit performance strong enough to replace human labeling.*\n\n*We observe that PaLM significantly outperforms all knowledge graph models on both datasets, with the minimum improvement being 40.6%.*",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2305.09858_kg_completion_ecommerce_llm.pdf"
}