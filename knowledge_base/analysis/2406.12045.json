{
  "paper_id": "2406.12045",
  "title": "Paper",
  "category": "mini_program_service",
  "year": 2024,
  "timestamp": "2026-03-01T13:54:43.262123",
  "summary": "# τ-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains\n\n## Overview\n\nThis paper presents τ-bench, a novel benchmark designed to evaluate language agents on their ability to interact with human users while following domain-specific policies and rules—a critical capability for real-world deployment that existing benchmarks fail to test.\n\n## Key Contributions\n\n**Benchmark Design**: τ-bench emulates dynamic conversations between a simulated human user (powered by language models) and an agent equipped with domain-specific API tools and policy guidelines. The evaluation compares the final database state against an annotated goal state, enabling objective measurement of agent decision-making while allowing for natural conversation variation.\n\n**Two Initial Domains**: The benchmark includes τ-retail (handling order cancellations, modifications, returns, and exchanges) and τ-airline (managing flight bookings, modifications, and cancellations). Both domains feature realistic databases, Python API tools, markdown policy documents, and diverse task scenarios.\n\n**New Metric**: The paper introduces pass^k, which measures the probability that an agent successfully completes a task across all k independent trials. This captures consistency and robustness—essential qualities for real-world applications where agents must perform reliably across millions of interactions.\n\n## Key Findings\n\n**Poor Performance**: Even state-of-the-art function calling agents achieve less than 50% task success. GPT-4o reaches only 61.2% on τ-retail and 35.2% on τ-airline using function calling.\n\n**Severe Inconsistency**: The chance of reliably solving the same task multiple times drops dramatically with repeated trials. GPT-4o's pass^8 (eight consecutive successes) falls below 25% in retail, revealing fragile handling of stochasticity and partial information.\n\n**Failure Analysis**: Three primary failure modes emerge: (1) wrong arguments or information provided during tool calls, (2) incorrect decision-making due to poor domain understanding and rule following, and (3) partial resolution of compound requests involving multiple user needs.\n\n**Policy Sensitivity**: When domain policies are removed from the system prompt, τ-airline performance drops significantly (-22.4% for GPT-4o), demonstrating that complex domain rules remain a major challenge for current agents.\n\n## Implications\n\nThe results highlight that language agents built on function calling lack sufficient consistency and rule-following ability for reliable real-world deployment. Improvements are needed in long-horizon information tracking, memory, and the ability to focus on relevant context while handling potentially conflicting facts.\n\n*Even state-of-the-art function calling agents succeed on <50% of the tasks, and are quite inconsistent*",
  "llm_info": {
    "provider": "cli",
    "model": "cli/claude/sonnet",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}