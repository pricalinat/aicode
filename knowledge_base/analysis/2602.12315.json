{
  "paper_id": "2602.12315",
  "title": "Agenticshop",
  "category": "ecommerce_evaluation",
  "year": 2026,
  "timestamp": "2026-03-01T13:54:39.588985",
  "summary": "# AgenticShop: Benchmarking Agentic Product Curation for Personalized Web Shopping\n\n## Summary\n\nThis paper introduces AgenticShop, the first benchmark designed to evaluate agentic systems on personalized product curation in open web shopping environments. The research addresses a critical gap in existing e-commerce benchmarks, which fail to capture the exploratory nature of real-world web shopping and overlook personalization evaluation.\n\n## Key Contributions\n\nThe benchmark is built on three core principles. First, it establishes realistic shopping intents based on prior user studies: Target Finding (users seeking specific products), Alternative Selection (users comparing options across categories), and Open Exploration (casual browsing without explicit queries). Second, it constructs diverse user profiles from real Amazon purchase histories and review texts, containing narrative descriptions of shopping preferences, intent-specific queries, and personalized checklists spanning six dimensions: brand preferences, price sensitivity, review sensitivity, functional requirements, aesthetic preferences, and purchase preferences. Third, it employs a checklist-driven evaluation framework using LLM-as-a-judge with extracted product information to verify whether curated outputs meet user requirements.\n\n## Experimental Findings\n\nThe authors evaluated eight agentic systems: four search-augmented LLMs (ChatGPT Search, Claude Sonnet 4 Search, Gemini-2.5 flash-grounding, Perplexity-pro) and four autonomous web agents (Agent-E, SeeAct, Web Voyager, Browser Use). Results reveal substantial room for improvement across all scenarios, with top performers achieving only 30-35% curation scores.\n\nSeveral important patterns emerged from the experiments. Query specificity contributes minimally to personalization, as the open web lacks the structured taxonomies of specialized shopping platforms. Performance varies significantly across product domains, with Fashion (Aesthetic-Driven) tasks proving particularly challenging when subjective visual preferences drive decisions. Search capability does not translate to personalization qualityâ€”agents can locate products but struggle to align them with user preferences. Attribution errors persist, with approximately 20% of product references being hallucinated URLs. Systems effectively address brand preferences but struggle with review sensitivity (due to curating products lacking reviews) and price sensitivity (due to dynamic pricing and incomplete cost aggregation).\n\nThe analysis also shows that exploratory information seeking correlates with better personalization outcomes, suggesting a promising direction for future work.\n\n## Technical Details\n\nThe benchmark contains 350 personalized tasks distributed across shopping scenarios and domains. User contexts are generated using GPT-5-mini based on purchase histories and reviews. Evaluation employs Playwright for robust information extraction across heterogeneous e-commerce layouts, with the LLM-as-a-judge achieving approximately 0.73 correlation with human evaluators. The code and dataset are available on GitHub.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/claude/sonnet",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}