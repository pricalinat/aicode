{
  "paper_id": "2407.03037",
  "title": "Vision Gui Testing",
  "category": "mini_program_service",
  "status": "success",
  "summary": "This paper presents Trident, a vision-driven, multi-agent automated GUI testing approach that targets non-crash functional bugs in mobile apps by treating bug finding as an interactive multimodal question answering problem. It argues that many non-crash bugs have visual cues across sequences of GUI states, but traditional automated testing struggles because reliable oracles are missing and functional correctness often depends on multi-step page transitions and app logic rather than crashes.\n\nTrident is organized around three collaborating agents: Explorer (navigates the app using screenshots plus view-hierarchy text), Monitor (tracks exploration, summarizes history by functionality, and decides when a functionality exploration ends), and Detector (infers expected behavior and flags logical inconsistencies across the executed sequence). Key technical pieces include (1) aligning screenshot visuals with extracted GUI/widget metadata, (2) screenshot annotation with action-typed bounding boxes and a legend to help the model pick actionable widgets, (3) functionality-oriented history abstraction to reduce token pressure and keep exploration purposeful, and (4) a functionality-driven chain-of-thought that first infers an oracle then performs bug detection, reinforced by retrieval-selected in-context examples of non-crash bugs.\n\nEvaluation covers 590 non-crash bugs from three datasets: a reproduced baseline set from prior work, a newer GitHub-derived set collected from popular apps with recent updates, and an injected-bug set to reduce data leakage concerns. Against 12 baselines (including display-issue detectors paired with explorers, logical-bug detectors, static analyzers, and MLLM-based baselines), Trident reports higher activity and code coverage and substantially higher bug-detection precision and recall, while also finding new real-world issues: it reports detecting 43 previously unknown non-crash bugs from Google Play apps, with 31 fixed and 12 confirmed by developers. Ablation results show all sub-modules matter, with the in-context bug examples and the functionality chain-of-thought contributing the largest drops when removed; the paper also reports a sweet spot where adding a few examples helps, but too many examples can degrade performance.\n\n*Trident detects 102 non-crash bugs in 74 apps, of which 43 bugs in 42 apps are never discovered before.*\n\n*Removing the bugs example has the greatest impact on the performance, reducing the bug detection performance by 54% precision and 92% recall.*",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/mini_program_service/2407.03037_Vision_GUI_Testing.pdf"
}