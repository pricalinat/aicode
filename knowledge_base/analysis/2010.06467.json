{
  "paper_id": "2010.06467",
  "title": "Pretrained Transformers Ranking",
  "category": "product_matching",
  "status": "success",
  "summary": "This PDF is a detailed survey of pretrained transformer models for text ranking, focused on how BERT-style models changed information retrieval and how practitioners can deploy them for search and related ranking tasks. It frames ranking as producing an ordered list of texts for a query, then explains modern evaluation under the Cranfield paradigm, including information needs, subjective relevance and qrels, pooling, common metrics like MRR, MAP, nDCG, and practical pitfalls like unjudged documents and score ties. *The goal of text ranking is to generate an ordered list of texts retrieved from a corpus in response to a query for a particular task.*\n\nThe survey then organizes transformer ranking methods into two major families: reranking in multi-stage pipelines and dense retrieval that ranks directly over learned vectors. For reranking it starts with monoBERT as relevance classification and extends to long-document handling via passage or sentence strategies such as Birch and MaxP, interaction and embedding methods such as CEDR, and passage-representation aggregation such as PARADE, alongside multi-stage cascade ideas and efficiency methods like distillation. It also covers query and document representation refinement, emphasizing transformer-era document expansion and term weighting methods including doc2query and doc2query with T5, DeepCT, HDCT, and DeepImpact, plus transformer-assisted pseudo relevance feedback. *Much effort has been devoted to developing ranking models that address the mismatch between document lengths and the length limitations of existing transformers.*\n\nFor dense retrieval it explains nearest neighbor search as the enabling infrastructure and surveys bi-encoder approaches and training schemes, including DPR, ANCE and hard negative mining, multi-vector and late-interaction models like ColBERT, and distillation pipelines that transfer cross-encoder behavior into efficient retrievers. Across both reranking and dense retrieval, two recurring themes are handling long texts beyond typical transformer limits and managing effectiveness versus efficiency tradeoffs such as latency, index size, and model cost, ending with open research questions on generalization, multilingual retrieval, better training with limited labels, and how ranking methods might in turn shape future language model pretraining.",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2010.06467_pretrained_transformers_ranking.pdf"
}