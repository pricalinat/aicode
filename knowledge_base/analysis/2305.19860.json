{
  "paper_id": "2305.19860",
  "title": "Llm Recommendation Survey",
  "category": "product_matching",
  "status": "success",
  "summary": "This survey reviews how large language models are being used in recommendation systems, arguing that their strongest value comes from high-quality text representations plus external knowledge that can link users, items, and context. It proposes a taxonomy that first splits work into discriminative LLMs for recommendation and generative LLMs for recommendation, then organizes methods by how the LLM is adapted, including fine-tuning, prompt tuning, prompting, in-context learning, and instruction tuning. A central framing is three modeling paradigms for applying LLMs in recommender pipelines: using LLMs to produce embeddings that feed a conventional recommender, using LLM-generated tokens as intermediate signals for a recommender, or using an LLM directly as the recommender that outputs recommendations in text.\n\nFor discriminative approaches, the paper mainly describes BERT-style models as strong backbones for understanding text and producing user or item representations, typically via fine-tuning on interaction data and related textual/context features. It also covers prompt-tuning variants that reshape recommendation into cloze-style mask prediction with verbalizers, highlighting uses in conversational recommendation, fairness analysis, and news recommendation via prompt ensembling. For generative approaches, it emphasizes translating recommendation tasks into natural language generation problems and distinguishes non-tuning methods (prompting and in-context learning to elicit zero or few-shot behavior) from tuning methods (fine-tuning, prompt tuning, instruction tuning), including designs that summarize user preferences, retrieve candidates, then generate or rank outputs. It also surveys broader system roles for LLMs, such as agent-style controllers that manage dialogue, memory, retrieval, databases, and tools, plus simulator environments where LLM-based users and recommenders interact to study feedback loops and other dynamics; tables compile representative papers, base models, tasks, and commonly used datasets.\n\nThe findings section consolidates recurring strengths and open challenges: strong zero and few-shot potential and explanation generation, but persistent biases (position, popularity, fairness, and personalization difficulties when collaborative signals are weak), plus practical prompt-design issues around faithful user and item representation under limited context length. It highlights controlled generation and evaluation as major pain points, including output-format instability, difficulty with list-wise ranking under autoregressive generation, and unclear evaluation criteria when models generate novel items beyond historical catalogs; it also cautions that benchmarks may be biased if items are well covered in pretraining corpora. The conclusion positions the area as early-stage, with future work likely to combine better grounding, longer-context modeling, improved fairness and controllability, and more realistic benchmarks for assessing LLM-based recommendation.\n\n*existing work can be roughly divided into the following three categories:*\n\n*LLMs possess impressive zero/few-shot abilities in various recommendation tasks*",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2305.19860_llm_recommendation_survey.pdf"
}