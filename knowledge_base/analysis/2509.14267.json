{
  "paper_id": "2509.14267",
  "title": "Graph Rag Ecommerce",
  "category": "product_matching",
  "year": 2025,
  "timestamp": "2026-03-01T13:44:29.083763",
  "summary": "# Graph-Enhanced Retrieval-Augmented Generation for E-Commerce Customer Support\n\n## Summary\n\nThis paper presents a novel retrieval-augmented generation (RAG) framework that integrates knowledge graphs (KGs) to improve the relevance and factual grounding of answers in e-commerce customer support applications. The authors developed a multi-stage system architecture consisting of an offline knowledge graph construction phase and an online query processing phase. During the offline phase, the system builds a detailed knowledge graph from product catalogs, user reviews, and resolved support tickets, extracting entities such as products, features, issues, and their relationships. When a customer query arrives, the system performs parallel retrieval from both the knowledge graph subgraph and document archives, then combines both sources through a novel answer synthesis algorithm that feeds information to a large language model.\n\nThe experimental evaluation demonstrates significant improvements across multiple metrics. The proposed method achieves 91% factual accuracy compared to 74% for standard RAG and 68% for LLM-only approaches, representing a 23% improvement in accuracy over document-only RAG. The system also shows substantial gains in BLEU-4 scores (0.58 vs 0.42) while maintaining reasonable response times of 1,340 milliseconds. A user study conducted with 50 experienced customer service agents revealed 89% user satisfaction compared to 67% for standard RAG, with statistically significant improvements (p<0.001) across all evaluation dimensions including factual accuracy, response completeness, clarity, relevance, and overall helpfulness.\n\nThe knowledge graph contains 50,000 product entities and 2.3 million relations extracted from vendor catalogs and 500,000 resolved support tickets. The answer synthesis algorithm linearizes subgraphs into structured fact statements, combines them with retrieved document context, and uses GPT-3.5-turbo to generate coherent responses that respect both factual constraints and natural language flow. The authors argue that this hybrid approach reduces hallucinations by enforcing that the LLM cannot readily alter the structured triples it sees in text format, while including document excerpts prevents answers from sounding too terse or disjointed. Future work includes dynamic KG updates from new support cases, personalization using customer purchase history, voice interface integration, and multilingual support expansion.\n\n---\n\n**Core Contribution**: The answer synthesis algorithm that jointly processes structured knowledge graph subgraphs and unstructured text documents to produce responses that are both factually grounded and conversationally natural.\n\n**Key Results**: 23% factual accuracy improvement and 89% user satisfaction versus 67% for standard RAG baseline.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/claude/sonnet",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}