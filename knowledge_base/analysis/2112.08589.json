{
  "paper_id": "2112.08589",
  "title": "Kg Embedding Ecommerce",
  "category": "product_matching",
  "status": "success",
  "summary": "This paper reports lessons from deploying knowledge graph embeddings in a large e-commerce knowledge graph and argues that real production reasoning is task-specific and human-machine collaborative, not generic link prediction over all relations. It defines three desiderata for e-commerce KG reasoning systems: attentive reasoning focused on a small set of target relations, explanations that help users and operators understand predictions, and transferable rules that can be reused to speed up new tasks and new systems. *the key to addressing the three challenges is to properly model the correlations among triples.*\n\nTo meet these desiderata, the authors propose an explainable knowledge graph attention network built on a TransE-style translation assumption, but with scoring driven by weighted neighbor triples rather than only the head, relation, and tail embeddings. Core ideas include:\n- Partial link prediction as the attentive reasoning task, restricting evaluation to triples whose relation is in a target-relation set.\n- A stackable basic layer that aggregates information from one-degree neighbor triples using an attention mechanism derived from shared-entity representations, with multi-layer stacking to incorporate higher-degree neighbors.\n- Explanations produced by selecting top weighted neighbor-triple chains, assigning confidence via products of attention weights across layers, and outputting top k explanations.\n- Transferable rule generation by turning explanation groundings into rules via variable replacement on shared entities, then filtering for frequently generated rules to control quality.\n\nExperiments use a domain subset of an industrial e-commerce KG (72,849 entities, 789 relations; 11 target relations for the main setting), with additional single-target-relation case studies. On partial link prediction, the proposed method (especially a 1-layer variant initialized from TransE embeddings) substantially outperforms TransE, TransH, TransR, and DistMult across MRR and Hit@k, while also demonstrating strong data efficiency in one-relation tasks by training on small fractions of the full triple set. For explanations, both the proposed method and a TransE-derived explanation baseline achieve high recall for valid explanations, but the proposed method yields much higher average support and improves expert checking speed in a manual study, reducing time to 56.9 percent of the no-explanation condition with comparable precision. For rules, generating rules from explanations greatly outperforms an AMIE baseline in this e-commerce setting, and the proposed method produces more high quality rules and infers many more new triples than TransE-based explanations. *explanations from our method significantly improve the efficiency of manually checking which is highly valuable in real life business.*",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2112.08589_kg_embedding_ecommerce.pdf"
}