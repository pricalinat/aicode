{
  "paper_id": "2510.18170",
  "title": "Agentchangebench",
  "category": "mini_program_service",
  "year": 2025,
  "timestamp": "2026-03-01T14:03:00.835379",
  "summary": "## Summary of 2510.18170 AgentChangeBench.pdf\n\nAgentChangeBench proposes a benchmark and evaluation framework for measuring how tool-augmented conversational AI agents handle mid-dialogue goal shifts, arguing that most existing agent benchmarks assume static objectives and therefore miss a core real-world behavior. The paper introduces a dataset spanning three enterprise customer-service domains banking, retail, and airline, and evaluates several major model families to show that high accuracy on standard success metrics does not necessarily translate into robustness when user goals change over multiple turns.\n\nThe benchmark contains 315 curated multi-turn tasks instantiated into 2,835 task sequences by combining domains with five user personas and explicit ordered goal sequences. Personas range from cooperative and confused to businesslike and suspicious, and they are implemented as stable behavioral parameters used by a persona-driven user simulator. Tasks follow a declarative JSON schema that specifies known and unknown user information plus a goal_shifts structure where required_shifts equals the number of transitions in the goal list. Goal shifts are triggered by conversation flow rules and are not marked for the agent, and users never issue tool calls, they only reveal pre-specified known information while the agent performs all API actions.\n\nThe core methodological contribution is a multi-dimensional metric suite designed to capture not just completion but also efficiency, wasted effort, and adaptation latency. Task Success Rate TSR replaces binary success with a weighted combination of three channels communication quality, action execution, and natural-language assertions for policy or behavioral compliance, with action weighted most heavily. Tool Use Efficiency TUE separates tool correctness from parameter validity and combines them into a composite, while also emphasizing that parameter validity is near a ceiling in the dataset so correctness drives most differences. Tool-Call Redundancy Ratio TCRR quantifies duplicate tool calls within a three-turn window or excessive repeated calls to the same function, highlighting cost and coherence issues that success-only scoring can hide. Goal-Shift Recovery Turns GSRT measures recovery time after a shift across acknowledgment, first relevant tool usage, and outcome achievement, and defines recovery based on explicit acknowledgment without transferring to a human agent.\n\n*Goal changes are a defining feature of real world multi-turn interactions, yet current agent benchmarks primarily evaluate static objectives or one-shot tool use.*  \n*These findings demonstrate that high raw accuracy does not imply robustness under dynamic goals, and that explicit measurement of recovery time and redundancy is essential.*\n\nEmpirically, the paper reports sharp cross-model differences that standard passk style metrics obscure, especially on new goal-shifted task sets. In airline tasks, GPT-4o is reported to recover from goal shifts at a high rate on new tasks while another model family drops substantially, demonstrating late shift detection as a key failure mode. Retail tasks show particularly high redundancy rates even when parameter validity is near perfect, indicating repeated lookups and inefficient tool use despite otherwise correct actions. Banking is described as the hardest domain overall, with lower TSR and higher redundancy, reflecting longer multi-step flows and more complex procedures. Persona-level analysis suggests medium-difficulty personas can yield higher TSR and recovery than the hardest persona, while TUE remains high across personas, reinforcing that adaptation and conversation management rather than raw tool schema compliance drives many observed gaps.\n\nThe appendix details how tasks are created and validated, including an LLM-assisted generation pipeline plus manual review to ensure tool parameters align with domain databases and that communication scoring is based on information derived from tool outputs rather than pre-known user facts. An example banking task and run illustrates how goal shifts, tool calls, and transfer-to-human behaviors are judged, and it highlights how a tool error can lead to transfer that affects recovery scoring. The paper also discusses early evaluation of an open-weight baseline under a reduced protocol and reports practical orchestration issues for some open models, such as mismatched function-calling schemas and turn-breaking internal thinking blocks. Limitations include relatively benign personas, reliance on pre-declared and often explicit goal shifts rather than implicit goal drift or overlapping objectives, and domain scope restricted to customer-service APIs, with future plans to broaden domains, harden personas, and add broader tool classes and MCP-compatible adapters while maintaining reproducibility.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/codex/gpt-5.2",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}