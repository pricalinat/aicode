{
  "paper_id": "2510.09347",
  "title": "Llp Llm Pricing",
  "category": "product_matching",
  "status": "success",
  "summary": "This paper proposes LLP, a large language model based system for pricing second-hand products on consumer-to-consumer marketplaces, motivated by the difficulty inexperienced sellers have in setting prices amid fast-changing market conditions. The authors argue prior approaches are largely static regression or clustering pipelines that struggle with fine-grained, colloquial product descriptions and with shifting values over time and across diverse categories. *Under the same 30% product coverage, it raises the static adoption rate SAR from 40% to 72%.*\n\nLLP follows a retrieval then reasoning workflow: it builds a recency-bounded candidate pool of recent listings, filters problematic or low-signal items, and retrieves top similar products using multimodal product representations derived from a Generative Semantic ID embedding and approximate nearest neighbor search. The retrieved set, plus the query listing, is formatted into prompts so an LLM produces a price and optionally a rationale, with additional post-training to improve domain reasoning and reduce distraction from irrelevant retrieved items. Training uses a bidirectional reasoning dataset construction process with backward reasoning to identify a golden subset of true comparables and forward reasoning to generate supervised rationales and prices, then applies supervised fine-tuning followed by Group Relative Policy Optimization that rewards both price accuracy and grounding in the golden subset; a confidence filter based on the average token entropy of the generated price can reject low-confidence suggestions. *LLP employs a confidence-based filtering mechanism to reject unreliable price suggestions.*\n\nExperiments use Xianyu data, including a test set of 80,000 products from 55 high-GMV categories and an additional 210,267 products from 611 unseen categories to measure generalization; evaluation metrics include RMSLE, MALE, Static Adoption Rate, and Dynamic Adoption Rate with a price-dependent error threshold. Across baselines such as KNN, vision-only and multimodal DNNs, a task fine-tuned LLM, and a prior CPV plus GMM industrial system, LLP reports the best results on both standardized and non-standardized products, and shows strong gains from adding retrieval plus post-training in ablations. The paper also reports deployment evidence via traffic replay and online testing, highlighting higher adoption rates at similar coverage and the ability to trade off precision and recall by tuning the entropy threshold.",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2510.09347_llp_llm_pricing.pdf"
}