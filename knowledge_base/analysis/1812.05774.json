{
  "paper_id": "1812.05774",
  "title": "Multilevel Categorization",
  "category": "product_matching",
  "status": "success",
  "summary": "This paper proposes reframing multi-level e-commerce product categorization from a large multi-class classification problem into a machine translation task. Instead of predicting a single leaf category directly, the method translates a product title into a sequence of taxonomy nodes representing a root-to-leaf path, using neural machine translation models. The authors argue this shift leverages existing MT infrastructure at global e-commerce companies, improves robustness to noisy or varied product text, and can do more than assign products to existing paths.\n\nThe work uses two large Rakuten datasets: Rakuten Data Challenge with 800,000 English product titles and 3,008 unique categories, and Rakuten Ichiba with about 100 million Japanese product titles after filtering duplicates and erroneous Others labels, spanning 21,819 unique categories. Both datasets exhibit strong long-tail skew in category sizes, and are split 80/10/10 for train/validation/test. The models are an attentional Seq2Seq system and a Transformer implemented in Fairseq, plus an ensemble averaging their decoder outputs, and they are compared against CUDeep, a state-of-the-art classification baseline composed of a deep belief network, 1-nearest-neighbor retrieval, and their ensemble.\n\nResults use weighted precision, recall, and weighted F-score computed on exact full-path matches, which penalizes translation models when they produce novel paths that still reach correct leaves. Despite this strict evaluation, the Transformer and especially the Seq2Seq+Transformer ensemble outperform CUDeep on both English RDC and Japanese Ichiba, with bootstrap resampling showing the ensemble’s advantage over the best CUDeep ensemble. Additional experiments varying training data size show the MT ensemble degrades less sharply than the classification ensemble under reduced training data, indicating greater robustness.\n\nA distinctive contribution is that translation models can generate root-to-leaf paths that do not exist in the original taxonomy tree, effectively adding new edges and transforming the taxonomy into a directed acyclic graph. The paper counts how many full-path categories are newly created by each model and provides qualitative examples where predicted paths plausibly prune or re-route categories, such as omitting an intuitively unnecessary intermediate node or relocating printers under office supplies rather than electronics. The authors conclude that MT-based categorization can improve predictive performance while also suggesting meaningful taxonomy restructurings, and they propose future work like crowdsourced evaluation of novel paths, trying more models, and automatic taxonomy induction.\n\n*we translate a product’s natural language description into a sequence of tokens representing a root-to-leaf path in a product taxonomy.*\n\n*our machine translation models can propose meaningful new paths between previously unconnected nodes in a taxonomy tree, thereby transforming the taxonomy into a directed acyclic graph DAG.*",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/1812.05774_multilevel_categorization.pdf"
}