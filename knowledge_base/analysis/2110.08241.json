{
  "paper_id": "2110.08241",
  "title": "Intent Based Collections",
  "category": "product_matching",
  "status": "success",
  "summary": "This paper proposes automating intent-based product collections in e-commerce, replacing a largely manual, expert-crafted workflow with a pretrained language model approach that can better match complex shopper intents to products. It frames the task as retrieving a coherent yet diverse set of products that satisfy a single, often long and multi-faceted intent sentence, while handling the rich textual attributes attached to products. The authors highlight three core difficulties:\n- Understanding long, complicated intent sentences\n- Handling rich and diverse product attributes\n- Closing a large semantic gap between intent language and product attribute text\n\nThe method fine-tunes a Sentence-BERT style siamese or triplet network using triplet loss, where the collection query acts as an anchor and products from that collection are positives. Queries are constructed by concatenating product collection title, section name, and the start date of exposure, aiming to capture intent, category hints, and seasonality; products are represented by concatenated attributes such as title, category, price, tags, brand, and description using [SEP] separators. Performance is improved with search-based hard negative sampling using BM25 to find confusable but incorrect products, plus category-wise positive pair augmentation that transforms multi-category collections into single-category variants to encourage categorical correctness. Offline evaluation uses recall at 100 to measure restoring original collection products and precision at 100 to measure retrieving products in the intended category when category information appears in the query, with Faiss used for similarity search.\n\n*Our model significantly outperforms the search-based baseline model for intent-based product matching in offline evaluations.* Offline results show hard negatives substantially improve recall over random negatives, while increasing category-wise augmentation tends to trade off recall for higher categorical precision; the paper selects a balanced configuration for production based on this tradeoff. In online experiments on the authors e-commerce platform, model-generated collections outperform human-crafted collections on key business metrics and diversity, reporting relative gains in click-through rate, conversion rate, and order-diversity, and noting that collections are then reordered with a simple regression-based post step. An ablation comparing a 12-layer and 6-layer SBERT variant finds the larger model generally yields more reliable recall and balanced performance, supporting its production choice, and the conclusion outlines expansion to more categories and exploration of more effective training and personalization.\n\n*the product collections from the model increase the CTR, CVR, order-diversity by 16%, 29%, 60%, respectively, comparing to the product collections made by human experts.*",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2110.08241_intent_based_collections.pdf"
}