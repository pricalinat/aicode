{
  "paper_id": "2505.12524",
  "title": "Hakes Vector Database",
  "category": "product_matching",
  "status": "success",
  "summary": "This paper presents HAKES, a distributed vector database aimed at high throughput and high recall for embedding search under concurrent read write workloads, motivated by retrieval augmented generation and other modern ANN use cases with high dimensional vectors. It argues that popular graph based indexes are expensive to build, suffer from heavy read write contention during updates, and scale poorly when sharded across many servers, especially when high recall forces searching many shards. *Our goal is to build a vector database that achieves high throughput and high recall under concurrent read write workloads.*\n\nAt the core is HAKES Index, a two stage design with a fast filter stage over aggressively compressed representations and a refine stage that reranks candidates using full precision vectors. The filter stage combines dimensionality reduction, coarse IVF partitioning, and 4 bit product quantization, and it introduces a lightweight self supervised training method that fine tunes search time compression parameters by minimizing mismatch between similarity score distributions before and after compression, using approximate nearest neighbors from a base index as training signal. Key mechanisms include:\n- Early termination in the filter stage based on intermediate candidate growth to avoid scanning unnecessary partitions\n- Decoupled parameters for insert versus search so new vectors can be appended cheaply while learned search parameters can be applied immediately without re indexing\n- Tombstones plus periodic compaction for deletions to limit interference with search and inserts  \n*HAKES employs a novel partitioning based index that adopts a two stage process with learned compression parameters.*\n\nHAKES the system exploits the two stages to use a disaggregated architecture: IndexWorkers replicate and serve the compact global filter index, while RefineWorkers shard the full vectors for exact reranking, with the client coordinating parallel refinement across relevant shards. The paper implements the index by extending FAISS and builds a service with HTTP based workers, then evaluates against 12 ANN index baselines and distributed systems including Weaviate, Cassandra, and Milvus on several deep embedding datasets up to 10 million vectors. Results reported show HAKES Index outperforming both partitioning and graph baselines in the high recall region and under concurrent read write workloads, and the full HAKES system scaling close to linearly and achieving up to 16Ã— higher throughput than the compared distributed baselines at high recall, with much lower index build time than large graph construction; the project is also described as open sourced.",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2505.12524_hakes_vector_database.pdf"
}