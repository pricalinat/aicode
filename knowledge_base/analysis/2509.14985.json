{
  "paper_id": "2509.14985",
  "title": "Prism Hybrid",
  "category": "product_matching",
  "status": "success",
  "summary": "This paper presents PRISM, a hybrid product-retrieval pipeline designed for retail images captured by shopping cart mounted cameras, where visually similar products, viewpoint changes, domain shifts, occlusions, and cluttered backgrounds make exact matching difficult. The core claim is that vision language models provide fast, high recall candidate selection but struggle to rank near identical items, while pixel wise local matching is more discriminative but too slow to run against an entire catalog. PRISM combines both to improve fine grained accuracy while staying within practical latency for in store use.\n\n*PRISM consists of three stages:*  \n- Stage 1 semantic retrieval: SigLIP embeds the query and all catalog images, then keeps the top 35 candidates by cosine similarity to shrink the search space.  \n- Stage 2 segmentation: YOLO-E segments the foreground product region in the query and candidate images to reduce background driven mismatches, then crops using the selected mask.  \n- Stage 3 pixel wise matching: ALIKED extracts keypoints and descriptors and LightGlue matches them, then RANSAC filters matches and the system picks the candidate with the most inlier correspondences.\n\nExperiments on the ABV dataset evaluate Top-35, Top-5, and Top-1 accuracy plus per query runtime on an NVIDIA A100, using a multi view gallery setup with six angles per product and treating remaining images as queries. PRISM reports Top-1 accuracy of 0.4279, improving over SigLIP at 0.3858 by 4.21 percent, with an average time of 725 ms per query, and qualitative examples emphasize improvements when differences are limited to subtle attributes like flavor text or package size. Ablations show that removing SigLIP and relying on YOLO-E class level narrowing hurts both accuracy and speed, that YOLO-E segmentation beats SAM on accuracy and is faster, and that LightGlue outperforms LoFTR on both accuracy and runtime in this setting.\n\n*our proposed PRISM outperforms the state-of-the-art image retrieval methods by 4.21% in top-1 accuracy while still remaining within the bounds of real-time processing*",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2509.14985_prism_hybrid.pdf"
}