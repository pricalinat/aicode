{
  "paper_id": "2304.07061",
  "title": "Droidbot Gpt",
  "category": "mini_program_service",
  "year": 2023,
  "timestamp": "2026-03-01T13:47:42.941803",
  "summary": "# DroidBot-GPT: GPT-powered UI Automation for Android\n\nDroidBot-GPT is a novel tool that leverages large language models to automate interactions with Android mobile applications. Given a natural language description of a desired task, the system can automatically generate and execute actions to navigate through an app and complete the task. The core innovation lies in translating the app's graphical user interface state and available actions into natural language prompts that the LLM can understand and respond to with appropriate actions.\n\nThe system works through a multi-step process. First, it extracts structured GUI information using DroidBot and converts it into natural language descriptions. Then it combines the state information, action history, and task description into a prompt sent to ChatGPT. The LLM generates the next action, which DroidBot-GPT then executes on the smartphone. The action space includes both choosing actions (click, scroll, check) and editing actions (typing text into fields), with a two-step solution for text input where the system asks the LLM what text should be entered.\n\nEvaluation was conducted on 17 Android applications from F-Droid spanning 10 categories, with 33 manually designed tasks of varying complexity. The system achieved a 39.39% full task completion rate and an average partial completion progress of 66.76%. Straightforward tasks with 2-3 steps achieved 60% full completion, while complex tasks requiring 6-13 steps achieved only 20% full completion. Tasks in the \"Financing\" category showed the highest average completion progress at 92.86%, while \"Record\" and \"Life\" categories showed the lowest at 41.19% and 50% respectively, primarily due to excessive typing requirements.\n\nThree main types of failures were identified. Unnamed GUI elements lacking text descriptions (like checkmark buttons or search boxes) caused early termination when the system couldn't recognize necessary interactive elements. Obscure GUI relationships between elements and screens led to redundant or incorrect operations. The probabilistic nature of ChatGPT responses also caused instability, where repeating the same task could produce slightly different action sequences. The researchers propose addressing these limitations through LLM fine-tuning and machine learning methods for recognizing unnamed elements.\n\nThis work represents the first investigation into applying pre-trained language models to Android app automation without requiring modifications to either the application or the LLM. The approach demonstrates strong generalization across diverse application categories compared to previous methods that required specific training data or in-depth instruction guidance. The ultimate goal is to enable LLMs to assist users in decision-making and task completion on mobile devices through natural language commands.",
  "llm_info": {
    "provider": "cli",
    "model": "cli/claude/sonnet",
    "maxCompletionTokens": null,
    "strategy": "single"
  }
}