{
  "paper_id": "2303.15870",
  "title": "Multi Granularity Matching",
  "category": "product_matching",
  "status": "success",
  "summary": "This paper presents MMAN, a Multi-granularity Matching Attention Network for query intent classification in e-commerce search, motivated by the mismatch between short, informal user queries and formal product category labels. It argues that many prior approaches either focus on richer query encoders or add external structure like label graphs, but still struggle to capture matching signals at multiple granularities, especially for long-tail and polysemous queries. The core idea is to explicitly incorporate category information and model query category interactions to narrow the expression gap and improve generalization.\n\nMMAN is built around shared BERT-based representations for both queries and categories, where each category input concatenates the category name with selected core product words to strengthen category semantics. It then combines three complementary modules: a self-matching module that uses attention over the query tokens to emphasize intent-bearing words, a char-level matching module that constructs a query category interaction matrix for every category and extracts fine-grained patterns via 2D convolution and max pooling, and a semantic-level matching module that mean-pools category embeddings and applies cross-attention to capture coarse semantic relevance and disambiguate cases where literal overlap is misleading. The model fuses the query self-representation with both matching feature sets and trains with multi-label cross-entropy, treating clicked product categories as intent labels.\n\nExperiments use two large-scale JD datasets derived from click logs: Category Data with 90 labels and Scene Data with 8 domain labels, each with millions of training queries and an expert-annotated test set. MMAN outperforms strong multi-label and intent-classification baselines including BERT, with ablations showing roughly a few percentage points drop in micro and macro F1 when removing any of the three matching components, supporting that they contribute complementary signals. Online A/B testing on JD search reports statistically significant gains, including overall PV and Click lifts across multiple scenes and business metric improvements such as GMV up by 0.351 percent, with the paper stating the model is deployed in production and is practically useful.\n\n*This paper proposes a Multi-granularity Matching Attention Network MMAN, which contains three modules: a self-matching module, a char-level matching module, and a semantic-level matching module*\n\n*MMAN has already been deployed in production at the JD application and brings great commercial value, which confirms that MMAN is a practical and robust solution*",
  "file_path": "/Users/rrp/Documents/aicode/data/papers/product_matching/2303.15870_multi_granularity_matching.pdf"
}